{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6817de-52ff-461b-9ae6-06067db8fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from  torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os, random,sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d59809b-debf-4140-8ce2-9b762e63682c",
   "metadata": {},
   "source": [
    "# Build a Variational Autoencoder (VAE) for a human face dataset\n",
    "\n",
    "We will use a dataset containing images of people and train a variational autoencoder on it. \n",
    "\n",
    "## Step 1\n",
    "\n",
    "Download and unzip the ``lfw.zip`` file . Adjust the ``path`` variable so that it contains the address of the unzipped folder. We will create a dataloader from this folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cd50d1-ccc1-45ea-8762-b11a58807347",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/somyasharma/Desktop/college_stuff/1 Pattern Recognition/PR_final/Pattern_Recognition/HW4/lfw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d165364-c1e8-4f47-8e8c-2e8149b83606",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform    = transforms.Compose([transforms.ToTensor()]) \n",
    "dataloader = DataLoader(ImageFolder(path, transform,),batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a61e3-03f9-42cb-921f-a75b310d4af4",
   "metadata": {},
   "source": [
    "This project is compute intensive. If you have a cuda or mps device on your laptop make sure you use that in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90672057-0317-4f19-a77d-df65c43fd481",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875a48c1-c834-4b95-a0b8-da19d6d293f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 250, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x,y in dataloader:\n",
    "    x = x[0].permute(1, 2, 0)\n",
    "    print(x.shape)\n",
    "    plt.imshow(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da87423-ffb1-4abb-a138-b9ed56ae1101",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "The basis for this project is that you can alter your implementation of AutoEncoders from the previous homework and add the necessary bits for a VAE.  Clearly state what is the difference between AutoEncoders and VAEs in terms of Applications, Architecture and Loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d261e9",
   "metadata": {},
   "source": [
    "# Differences in Terms of Applications:\n",
    "AutoEncoders (AE): Primarily used for dimensionality reduction, feature learning, and data denoising. The latent space does not have a specific structure or distribution.\n",
    "Variational AutoEncoders (VAE): Specifically designed for generating new data points. Introduces a probabilistic approach, modeling the latent space as a probability distribution. This allows generating new samples by sampling from the distribution.\n",
    "# Differences in Terms of Architecture:\n",
    "AutoEncoders (AE): The encoder directly maps input data to a fixed-size latent representation. Deterministic: Given the same input, AE will produce the same latent representation.\n",
    "Variational AutoEncoders (VAE): The encoder maps input data to the parameters of a probability distribution (usually Gaussian) in the latent space. Stochastic: The sampling from the distribution introduces randomness, leading to a continuous and structured latent space.\n",
    "# Differences in Terms of Loss Function:\n",
    "AutoEncoders (AE): Typically use Mean Squared Error (MSE) loss between the input and the reconstructed output. Reconstruction loss focuses on getting a faithful reconstruction of the input.\n",
    "Variational AutoEncoders (VAE): Use a combination of two terms in the loss function: reconstruction loss and KL divergence. Reconstruction loss ensures faithful reconstruction. KL divergence encourages the learned distribution to be close to a predefined distribution (often a standard Gaussian), enforcing a more structured latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38206b5b-becb-4e1e-afc7-fd3234eb3a4d",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "Update your pytorch autoencoder model class to create your VAE. Assume the encoder produces the mean and log variance of the latent space.  \n",
    "\n",
    "**Create separate functions for the encoder and decoder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11357950-d8b8-434f-8170-d543925cafdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VAE,self).__init__()  \n",
    "        self.encoded_images = self.encoder()\n",
    "        self.decoded_images = self.decoder()\n",
    "        \n",
    "    def encoder(self):\n",
    "\n",
    "            return nn.Sequential(nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1), \n",
    "                                 nn.BatchNorm2d(8),  \n",
    "                                 nn.ReLU(True),  \n",
    "                                 nn.MaxPool2d(2, stride=2),  \n",
    "                                 \n",
    "                                 nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1), \n",
    "                                 nn.BatchNorm2d(16), \n",
    "                                 nn.ReLU(True),\n",
    "                                 nn.MaxPool2d(2, stride=2),\n",
    "                                 \n",
    "                                 nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=2),\n",
    "                                 nn.BatchNorm2d(32), \n",
    "                                 nn.ReLU(True), \n",
    "                                 nn.MaxPool2d(2, stride=2) \n",
    "                                ) \n",
    "            \n",
    "\n",
    "    # out =(in −1)×stride[0]−2×padding[0]+dilation[0]×(kernel_size[0]−1)+output_padding[0]+1 \n",
    "    def decoder(self):\n",
    "        return nn.Sequential(nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "                             nn.BatchNorm2d(16),\n",
    "                             \n",
    "                             nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1),\n",
    "                             nn.BatchNorm2d(8),\n",
    "                             \n",
    "                             nn.ConvTranspose2d(8, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                             nn.Tanh()\n",
    "                            )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        encoded_images = self.encoded_images(x)\n",
    "        mu_f, logvar_f = encoded_images.split(encoded_images.size(1)//2, 1)\n",
    "        std_f = torch.exp(0.5 * logvar_f)\n",
    "        encoded_images = torch.randn_like(mu_f) * std_f + mu_f\n",
    "        decoded_images = self.decoded_images(encoded_images)\n",
    "        return decoded_images\n",
    "    # Dummy image, tensor replaces this with the actual image tensor\n",
    "testing_image = torch.randn(1, 3, 250, 250)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    encoded_output, decoded_output, mu, log_var = model.forward(testing_image)\n",
    "\n",
    "# Print the shape of the output of the encoder\n",
    "print(\"Shape of the output of the encoder:\", encoded_output.shape)\n",
    "\n",
    "# Print the shape of the output of the decoder\n",
    "print(\"Shape of the output of the decoder:\", decoded_output.shape)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e2bf3-5f23-47c2-a230-39022e9d24d2",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Create an instance of the new class, pass an image to the model\n",
    "\n",
    "*  print the shape of the output of the **encoder**. Explain how would you generate new samples in the latent space. Your explanation should show that you have understood the concepts. Providing just the formula or code snippet without context will not earn any points.\n",
    "*  use the decoder to create new images. Print the shape of the output and verify that the forward pass is working correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90dabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy image tensor (replace this with your actual image tensor)\n",
    "testing_image = torch.randn(1, 3, 250, 250)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():\n",
    "    encoded_output, decoded_output, mu, log_var = model.forward(testing_image)\n",
    "\n",
    "# To Print the shape of output that we get via encoder\n",
    "print(\"Shape of the output of the encoder:\", encoded_output.shape)\n",
    "\n",
    "# To Print the shape of output that we get via decoder\n",
    "print(\"Shape of the output of the decoder:\", decoded_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2cd5d4",
   "metadata": {},
   "source": [
    "Generating new samples in the latent space involves sampling from the learned distribution within the latent space, as defined by the mean (mu) and log variance (logvar) obtained from the encoder in a Variational AutoEncoder (VAE).\n",
    "\n",
    "Here are the steps to generate new samples:\n",
    "\n",
    "1. **Sampling from the Latent Space:**\n",
    "   - Use the reparameterization trick to sample from a normal distribution using the mean (mu) and standard deviation (std) derived from the encoder's output. The standard deviation is calculated as `std = exp(0.5 * logvar)`. Then, generate random samples (`eps`) from a standard normal distribution and calculate the latent variable (`z`) as `z = mu + eps * std`.\n",
    "\n",
    "   ```python\n",
    "   def reparameterize(mu, logvar):\n",
    "       std = torch.exp(0.5 * logvar)\n",
    "       eps = torch.randn_like(std)\n",
    "       return mu + eps * std\n",
    "   ```\n",
    "\n",
    "2. **Generating New Samples:**\n",
    "   - Pass the sampled latent variable (`z`) through the decoder to generate new samples. The decoder takes the latent variable and transforms it back into the data space.\n",
    "\n",
    "   ```python\n",
    "   latent_samples = reparameterize(mu, logvar)\n",
    "   generated_images = model.decoder(latent_samples)\n",
    "   ```\n",
    "\n",
    "   The `generated_images` now represent new samples that are generated in the latent space and then transformed into the data space by the decoder.\n",
    "\n",
    "3. **Interpretation:**\n",
    "   - The reparameterization trick introduces a stochastic element during sampling, ensuring that the latent space has a continuous and structured distribution. By varying the sampled latent variables, you explore different regions of the latent space, generating diverse and novel samples.\n",
    "\n",
    "Generating new samples in the latent space involves incorporating randomness through the reparameterization trick and using the decoder to transform these latent samples into meaningful data space representations. This process allows the VAE to generate diverse and realistic samples by exploring different regions of the latent distribution.\n",
    "\n",
    "1. **Learning the Latent Space:**\n",
    "   - During the training of the VAE, the encoder part of the network learns to map input data to a distribution in the latent space. This distribution is typically modeled as a Gaussian distribution with a mean (\\(\\mu\\)) and log variance (\\(\\log(\\sigma^2)\\)).\n",
    "\n",
    "2. **Reparameterization Trick:**\n",
    "   - To generate new samples, we use a technique called the reparameterization trick. Instead of directly sampling from the distribution defined by \\(\\mu\\) and \\(\\log(\\sigma^2)\\), we sample from a standard normal distribution (\\(N(0, 1)\\)) and transform the samples to match the learned distribution. This is done using the formula:\n",
    "     \\[ z = \\mu + \\sigma \\cdot \\epsilon \\]\n",
    "     where \\(\\epsilon\\) is a sample from \\(N(0, 1)\\). This trick makes the model differentiable, enabling backpropagation during training.\n",
    "\n",
    "3. **Generating New Samples:**\n",
    "   - During the generation phase (not training), we sample random values from the standard normal distribution and use the learned \\(\\mu\\) and \\(\\sigma\\) to transform them into points in the latent space.\n",
    "\n",
    "4. **Decoding to Data Space:**\n",
    "   - These sampled points (\\(z\\)) are then passed through the decoder part of the network. The decoder reconstructs the original data from these points in the latent space.\n",
    "\n",
    "5. **Interpretation:**\n",
    "   - By sampling different points in the latent space and decoding them, we generate new data samples. The VAE's ability to generate diverse samples comes from the stochasticity introduced during the reparameterization, allowing us to explore various regions of the learned latent distribution.\n",
    "\n",
    "Also, generating new samples in the latent space involves navigating the structured latent space learned by the VAE, introducing randomness through the reparameterization trick, and finally decoding these samples to obtain novel and diverse data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d97cb077-a104-4026-bb3e-8de82f28b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7368281a-fe20-4fd7-b6f1-24fcb6a4b8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 32, 32])\n",
      "torch.Size([32, 3, 250, 250])\n",
      "torch.Size([32, 3, 250, 250])\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataloader:\n",
    "## forward\n",
    "    output_encoder = model.encoded_images(x)\n",
    "    print(output_encoder.shape)\n",
    "    mu_f, logvar_f = output_encoder.split(output_encoder.size(1)//2, 1)\n",
    "    std_f = torch.exp(0.5 * logvar_f)\n",
    "    output_encoder = torch.randn_like(mu_f) * std_f + mu_f\n",
    "    output_decoder = model.decoded_images(output_encoder)\n",
    "    \n",
    "    print(output_decoder.shape)\n",
    "    output_vae = model.forward(x)\n",
    "    print(output_vae.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace2e6fa-e96b-4e31-b95e-4ad5d694c78d",
   "metadata": {},
   "source": [
    "##  Step 5\n",
    "* Print the total number of parameters in the model\n",
    "* Explain what loss should be used here. Describe in your own words the terms of the loss function and what goal each term of the loss function achieves. Your explanation should show that you have understood the concepts. Providing just the formula or code snippet without context will not earn any points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6608f049-23bb-4ad4-b45d-1d686c3fbd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9891\n"
     ]
    }
   ],
   "source": [
    "total_parameters = sum(params.numel() for params in model.parameters())\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1670cb77-129e-4c1d-ad19-3f6813502a48",
   "metadata": {},
   "source": [
    "* create an optimizer for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ca8ac7-7ef8-43de-b284-88320fc79ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.001,\n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0a6f49-795a-4be9-a3ec-4460c93d7a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e130589-0b83-4ef2-8b66-60302df67046",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./generated'):\n",
    "    os.mkdir('./generated')\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 3, 250, 250)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eea30d-bbc3-4145-9522-884a08fa093b",
   "metadata": {},
   "source": [
    "##  Step 6\n",
    "Write a training loop and start training the model for several epochs. Report the loss value at the end of each epoch and monitor it. If your loss is not decreasing what do you have to do to troubleshoot it ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4beda4a",
   "metadata": {},
   "source": [
    "If the loss in your training process is not decreasing as expected, it's crucial to troubleshoot and identify potential issues. Here are some steps you can take:\n",
    "\n",
    "Check Learning Rate:\n",
    "If the learning rate is too high, the model might oscillate or overshoot the minimum. Conversely, if it's too low, the training might be slow, and the model might get stuck in local minima. Experiment with different learning rates to find an optimal value.\n",
    "Evaluate Model Complexity:\n",
    "The model might be too simple or too complex for the given task. If it's too simple, it may struggle to capture the underlying patterns. If it's too complex, it might overfit the training data. Adjust the model architecture and complexity accordingly.\n",
    "Increase Training Epochs:\n",
    "It's possible that the model needs more training epochs to converge. If the loss is not decreasing, training for additional epochs might allow the model to continue learning. Monitor the loss over an extended period.\n",
    "Inspect Data Preprocessing:\n",
    "Incorrect or inadequate data preprocessing can impact training. Ensure that data normalization, scaling, and other preprocessing steps are applied correctly. Check for outliers and anomalies in the dataset.\n",
    "Verify Loss Function:\n",
    "Ensure that the chosen loss function is appropriate for the task. For example, if working with a regression problem, Mean Squared Error (MSE) might be suitable, while for classification, Cross-Entropy loss is common.\n",
    "Check for Overfitting:\n",
    "Overfitting can occur if the model memorizes the training data without generalizing well to unseen data. Introduce regularization techniques such as dropout or weight decay to prevent overfitting.\n",
    "Explore Different Optimizers:\n",
    "Different optimization algorithms might behave differently on your specific task. Experiment with alternative optimizers, such as Adam, SGD, or RMSprop, to see if they yield better results.\n",
    "Inspect Model Initialization:\n",
    "Poor initialization of model weights can hinder convergence. Ensure that the model parameters are initialized appropriately. Techniques like Xavier/Glorot initialization are commonly used.\n",
    "Monitor Loss Components:\n",
    "If your model has multiple components in the loss function (e.g., reconstruction loss and KL divergence for VAE), monitor each component separately. This can help identify which part of the loss is not decreasing.\n",
    "Debug Gradual Changes:\n",
    "Gradually introduce changes to your model or training setup and monitor the effects. This helps pinpoint specific factors contributing to the loss behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9b4141e-9660-4ae6-8408-263d4453e87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "mu_f, logvar_f = output_encoder.split(output_encoder.size(1)//2,1)\n",
    "print(mu_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc1c21-db79-4742-a00a-ceac8fa8bfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  batch  0  loss  tensor(17472.0098, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  1  loss  tensor(14830.7021, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  2  loss  tensor(12685.4863, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  3  loss  tensor(11541.4551, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  4  loss  tensor(10723.3340, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  5  loss  tensor(9812.1055, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  6  loss  tensor(8981.1855, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  7  loss  tensor(8733.5186, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  8  loss  tensor(8248.2422, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  9  loss  tensor(7630.1074, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  10  loss  tensor(7464.9204, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  11  loss  tensor(7145.2847, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  12  loss  tensor(7028.6709, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  13  loss  tensor(6467.2686, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  14  loss  tensor(6411.1265, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  15  loss  tensor(6330.1377, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  16  loss  tensor(6174.8940, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  17  loss  tensor(6112.3853, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  18  loss  tensor(5866.3760, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  19  loss  tensor(5588.1934, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  20  loss  tensor(5678.8896, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  21  loss  tensor(5392.4058, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  22  loss  tensor(5292.3120, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  23  loss  tensor(5283.5195, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  24  loss  tensor(5142.5088, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  25  loss  tensor(4992.3174, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  26  loss  tensor(4997.8481, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  27  loss  tensor(4808.6675, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  28  loss  tensor(4709.9355, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  29  loss  tensor(4492.7749, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  30  loss  tensor(4704.6318, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  31  loss  tensor(4313.0342, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  32  loss  tensor(4538.5200, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  33  loss  tensor(4383.1079, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  34  loss  tensor(4314.7686, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  35  loss  tensor(4378.3940, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  36  loss  tensor(4164.2236, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  37  loss  tensor(4180.5498, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  38  loss  tensor(4257.3335, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  39  loss  tensor(4016.2927, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  40  loss  tensor(3959.1401, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  41  loss  tensor(4006.0742, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  42  loss  tensor(3945.1606, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  43  loss  tensor(3820.9412, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  44  loss  tensor(3708.0840, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  45  loss  tensor(3664.2874, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  46  loss  tensor(3677.7957, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  47  loss  tensor(3625.2651, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  48  loss  tensor(3664.6360, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  49  loss  tensor(3553.2261, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  50  loss  tensor(3406.4204, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  51  loss  tensor(3459.0227, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  52  loss  tensor(3460.0232, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  53  loss  tensor(3465.9275, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  54  loss  tensor(3379.2146, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  55  loss  tensor(3207.4075, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  56  loss  tensor(3340.1240, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  57  loss  tensor(3212.5879, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  58  loss  tensor(3258.5093, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  59  loss  tensor(3070.0317, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  60  loss  tensor(3057.9783, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  61  loss  tensor(3134.5408, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  62  loss  tensor(3158.1284, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  63  loss  tensor(3077.5093, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  64  loss  tensor(3166.2905, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  65  loss  tensor(3169.8984, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  66  loss  tensor(3051.6389, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  67  loss  tensor(2816.6470, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  68  loss  tensor(2903.2607, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  69  loss  tensor(2912.0161, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  70  loss  tensor(2692.5637, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  71  loss  tensor(2810.2095, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  72  loss  tensor(2679.8518, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  73  loss  tensor(2859.5789, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  74  loss  tensor(2806.1858, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  75  loss  tensor(2735.8425, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  76  loss  tensor(2792.7295, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  77  loss  tensor(2741.2305, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  78  loss  tensor(2628.1516, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  79  loss  tensor(2577.9250, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  80  loss  tensor(2378.0879, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  81  loss  tensor(2568.0002, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  82  loss  tensor(2545.5352, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  83  loss  tensor(2501.2075, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  84  loss  tensor(2448.4707, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  85  loss  tensor(2297.8350, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  86  loss  tensor(2454.6382, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  87  loss  tensor(2420.1560, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  88  loss  tensor(2334.5430, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  89  loss  tensor(2440.0139, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  90  loss  tensor(2396.2493, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  91  loss  tensor(2283.9854, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  92  loss  tensor(2415.0029, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  93  loss  tensor(2455.8298, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  94  loss  tensor(2368.8062, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  95  loss  tensor(2211.2258, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  96  loss  tensor(2360.4065, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  97  loss  tensor(2249.9126, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  98  loss  tensor(2279.0144, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  99  loss  tensor(2233.6079, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  100  loss  tensor(2163.4775, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  101  loss  tensor(2243.1287, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  102  loss  tensor(2209.9604, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  103  loss  tensor(2250.4600, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  104  loss  tensor(1956.1709, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  105  loss  tensor(2134.5540, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  106  loss  tensor(2087.9075, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  107  loss  tensor(2009.1648, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  108  loss  tensor(2047.5447, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  109  loss  tensor(1959.9871, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  110  loss  tensor(2044.4266, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  111  loss  tensor(1989.1545, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  112  loss  tensor(1906.0573, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  113  loss  tensor(1942.6893, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  114  loss  tensor(1881.8815, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  115  loss  tensor(1904.5129, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  116  loss  tensor(1894.9440, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  117  loss  tensor(1892.5350, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  118  loss  tensor(1827.4889, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  batch  119  loss  tensor(1902.6267, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  120  loss  tensor(1709.9154, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  121  loss  tensor(1789.0023, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  122  loss  tensor(1833.2760, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  123  loss  tensor(1801.5952, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  124  loss  tensor(1795.6621, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  125  loss  tensor(1832.2941, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  126  loss  tensor(1696.2606, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  127  loss  tensor(1695.1393, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  128  loss  tensor(1681.5472, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  129  loss  tensor(1655.1333, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  130  loss  tensor(1668.7921, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  131  loss  tensor(1795.8944, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  132  loss  tensor(1712.0773, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  133  loss  tensor(1687.4862, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  134  loss  tensor(1611.8745, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  135  loss  tensor(1529.9288, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  136  loss  tensor(1489.7502, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  137  loss  tensor(1604.6509, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  138  loss  tensor(1613.2396, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  139  loss  tensor(1601.7239, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  140  loss  tensor(1499.1124, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  141  loss  tensor(1509.2246, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  142  loss  tensor(1553.3766, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  143  loss  tensor(1486.1229, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  144  loss  tensor(1561.0453, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  145  loss  tensor(1531.2908, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  146  loss  tensor(1551.7427, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  147  loss  tensor(1406.3075, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  148  loss  tensor(1563.1648, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  149  loss  tensor(1514.8574, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  150  loss  tensor(1400.3512, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  151  loss  tensor(1393.2181, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  152  loss  tensor(1317.7776, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  153  loss  tensor(1365.6042, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  154  loss  tensor(1382.3275, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  155  loss  tensor(1243.8568, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  156  loss  tensor(1409.6238, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  157  loss  tensor(1450.9427, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  158  loss  tensor(1425.0940, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  159  loss  tensor(1236.4923, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  160  loss  tensor(1371.1207, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  161  loss  tensor(1291.9938, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  162  loss  tensor(1253.8248, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  163  loss  tensor(1242.5039, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  164  loss  tensor(1464.3958, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  165  loss  tensor(1312.0292, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  166  loss  tensor(1363.5580, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  167  loss  tensor(1278.8342, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  168  loss  tensor(1312.9600, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  169  loss  tensor(1269.6241, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  170  loss  tensor(1373.5599, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  171  loss  tensor(1282.1040, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  172  loss  tensor(1300.1990, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  173  loss  tensor(1344.4622, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  174  loss  tensor(1239.1466, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  175  loss  tensor(1164.9259, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  176  loss  tensor(1254.3707, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  177  loss  tensor(1166.5339, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  178  loss  tensor(1200.8252, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  179  loss  tensor(1167.0093, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  180  loss  tensor(1157.1705, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  181  loss  tensor(1215.0564, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  182  loss  tensor(1153.3141, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  183  loss  tensor(1143.3810, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  184  loss  tensor(1268.3218, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  185  loss  tensor(1162.9580, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  186  loss  tensor(1102.5137, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  187  loss  tensor(1051.9749, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  188  loss  tensor(1182.1917, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  189  loss  tensor(1055.3374, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  190  loss  tensor(1035.8704, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  191  loss  tensor(1044.3608, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  192  loss  tensor(1027.3871, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  193  loss  tensor(1044.1270, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  194  loss  tensor(1042.0382, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  195  loss  tensor(1067.5299, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  196  loss  tensor(1108.7789, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  197  loss  tensor(1109.7566, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  198  loss  tensor(903.7363, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  199  loss  tensor(964.6340, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  200  loss  tensor(1109.7511, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  201  loss  tensor(957.7151, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  202  loss  tensor(1035.1527, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  203  loss  tensor(969.5861, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  204  loss  tensor(1022.2597, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  205  loss  tensor(995.4139, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  206  loss  tensor(999.2939, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  207  loss  tensor(1100.2130, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  208  loss  tensor(925.6020, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  209  loss  tensor(854.7642, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  210  loss  tensor(868.0804, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  211  loss  tensor(913.2878, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  212  loss  tensor(913.8644, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  213  loss  tensor(1024.4082, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  214  loss  tensor(958.7906, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  215  loss  tensor(917.0016, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  216  loss  tensor(875.2444, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  217  loss  tensor(884.6407, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  218  loss  tensor(941.5399, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  219  loss  tensor(890.9311, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  220  loss  tensor(856.9194, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  221  loss  tensor(834.9986, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  222  loss  tensor(912.0960, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  223  loss  tensor(836.9127, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  224  loss  tensor(918.7457, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  225  loss  tensor(910.7794, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  226  loss  tensor(851.8321, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  227  loss  tensor(763.8377, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  228  loss  tensor(876.3442, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  229  loss  tensor(792.8015, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  230  loss  tensor(788.6038, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  231  loss  tensor(801.8839, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  232  loss  tensor(803.0037, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  233  loss  tensor(872.4808, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  234  loss  tensor(768.0373, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  235  loss  tensor(873.2116, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  236  loss  tensor(775.4089, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  batch  237  loss  tensor(731.7927, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  238  loss  tensor(777.5319, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  239  loss  tensor(794.9918, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  240  loss  tensor(729.0894, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  241  loss  tensor(743.5171, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  242  loss  tensor(707.1451, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  243  loss  tensor(731.1139, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  244  loss  tensor(795.4767, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  245  loss  tensor(788.5951, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  246  loss  tensor(733.8497, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  247  loss  tensor(798.3601, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  248  loss  tensor(715.5913, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  249  loss  tensor(748.2258, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  250  loss  tensor(723.0584, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  251  loss  tensor(724.6391, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  252  loss  tensor(641.6732, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  253  loss  tensor(784.2948, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  254  loss  tensor(743.0414, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  255  loss  tensor(694.5803, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  256  loss  tensor(717.6746, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  257  loss  tensor(669.4827, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  258  loss  tensor(647.0702, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  259  loss  tensor(671.7282, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  260  loss  tensor(595.4279, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  261  loss  tensor(717.6995, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  262  loss  tensor(595.1252, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  263  loss  tensor(624.0547, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  264  loss  tensor(578.7933, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  265  loss  tensor(615.7772, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  266  loss  tensor(640.6124, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  267  loss  tensor(650.2273, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  268  loss  tensor(604.8380, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  269  loss  tensor(617.4197, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  270  loss  tensor(612.3685, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  271  loss  tensor(643.7438, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  272  loss  tensor(600.7001, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  273  loss  tensor(671.1359, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  274  loss  tensor(653.1957, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  275  loss  tensor(624.2309, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  276  loss  tensor(581.8256, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  277  loss  tensor(629.6518, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  278  loss  tensor(589.1937, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  279  loss  tensor(577.4088, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  280  loss  tensor(569.6102, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  281  loss  tensor(571.9143, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  282  loss  tensor(642.6528, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  283  loss  tensor(531.0278, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  284  loss  tensor(570.0630, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  285  loss  tensor(586.7211, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  286  loss  tensor(545.8641, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  287  loss  tensor(528.5102, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  288  loss  tensor(506.7012, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  289  loss  tensor(635.5770, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  290  loss  tensor(534.9025, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  291  loss  tensor(573.4920, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  292  loss  tensor(586.3382, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  293  loss  tensor(548.1436, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  294  loss  tensor(598.2380, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  295  loss  tensor(516.6246, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  296  loss  tensor(504.2863, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  297  loss  tensor(566.9189, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  298  loss  tensor(525.7388, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  299  loss  tensor(460.6670, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  300  loss  tensor(490.4921, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  301  loss  tensor(480.2863, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  302  loss  tensor(477.3479, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  303  loss  tensor(480.3231, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  304  loss  tensor(466.6458, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  305  loss  tensor(438.6067, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  306  loss  tensor(466.0322, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  307  loss  tensor(454.2780, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  308  loss  tensor(483.1382, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  309  loss  tensor(503.8292, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  310  loss  tensor(411.7303, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  311  loss  tensor(471.4717, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  312  loss  tensor(462.9339, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  313  loss  tensor(495.3316, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  314  loss  tensor(412.9924, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  315  loss  tensor(452.0578, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  316  loss  tensor(435.6819, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  317  loss  tensor(428.6832, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  318  loss  tensor(402.0940, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  319  loss  tensor(385.1413, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  320  loss  tensor(471.6199, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  321  loss  tensor(472.3685, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  322  loss  tensor(394.0533, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  323  loss  tensor(415.6092, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  324  loss  tensor(388.3106, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  325  loss  tensor(348.5363, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  326  loss  tensor(384.3444, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  327  loss  tensor(389.1261, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  328  loss  tensor(436.9679, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  329  loss  tensor(438.4051, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  330  loss  tensor(410.1335, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  331  loss  tensor(407.4702, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  332  loss  tensor(363.1386, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  333  loss  tensor(412.2856, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  334  loss  tensor(416.8611, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  335  loss  tensor(412.8317, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  336  loss  tensor(375.3383, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  337  loss  tensor(334.7655, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  338  loss  tensor(386.9861, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  339  loss  tensor(381.0461, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  340  loss  tensor(383.4107, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  341  loss  tensor(407.0462, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  342  loss  tensor(396.4122, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  343  loss  tensor(357.2498, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  344  loss  tensor(411.3488, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  345  loss  tensor(379.6681, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  346  loss  tensor(338.9997, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  347  loss  tensor(327.0089, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  348  loss  tensor(374.3084, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  349  loss  tensor(360.3681, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  350  loss  tensor(354.1729, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  351  loss  tensor(311.7249, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  352  loss  tensor(374.2724, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  353  loss  tensor(354.7751, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  354  loss  tensor(297.1722, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  355  loss  tensor(338.5146, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  batch  356  loss  tensor(335.7712, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  357  loss  tensor(341.0003, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  358  loss  tensor(338.1331, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  359  loss  tensor(339.6974, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  360  loss  tensor(303.4608, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  361  loss  tensor(267.3463, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  362  loss  tensor(340.1385, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  363  loss  tensor(292.2149, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  364  loss  tensor(349.1254, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  365  loss  tensor(298.2785, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  366  loss  tensor(318.5885, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  367  loss  tensor(254.2822, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  368  loss  tensor(314.4489, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  369  loss  tensor(285.1714, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  370  loss  tensor(294.5528, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  371  loss  tensor(278.0003, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  372  loss  tensor(289.2585, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  373  loss  tensor(284.8567, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  374  loss  tensor(307.5538, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  375  loss  tensor(296.7309, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  376  loss  tensor(318.2132, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  377  loss  tensor(261.5491, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  378  loss  tensor(306.5961, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  379  loss  tensor(284.6711, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  380  loss  tensor(287.5035, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  381  loss  tensor(237.1758, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  382  loss  tensor(250.7230, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  383  loss  tensor(285.3889, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  384  loss  tensor(287.7981, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  385  loss  tensor(257.6390, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  386  loss  tensor(301.2717, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  387  loss  tensor(248.1455, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  388  loss  tensor(307.1674, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  389  loss  tensor(254.3853, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  390  loss  tensor(265.2618, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  391  loss  tensor(287.5901, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  392  loss  tensor(272.3278, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  393  loss  tensor(245.4082, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  394  loss  tensor(255.8942, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  395  loss  tensor(295.1547, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  396  loss  tensor(213.8046, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  397  loss  tensor(270.9793, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  398  loss  tensor(215.5232, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  399  loss  tensor(241.1612, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  400  loss  tensor(227.4124, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  401  loss  tensor(256.1170, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  402  loss  tensor(232.4067, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  403  loss  tensor(247.4293, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  404  loss  tensor(299.5419, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  405  loss  tensor(223.9951, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  406  loss  tensor(224.0872, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  407  loss  tensor(198.7090, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  408  loss  tensor(255.7064, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  409  loss  tensor(235.8236, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  410  loss  tensor(223.7762, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  411  loss  tensor(242.4955, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  412  loss  tensor(274.6749, grad_fn=<AddBackward0>)\n",
      "epoch  0  batch  413  loss  tensor(257.6718, grad_fn=<AddBackward0>)\n",
      "epoch [1/100], loss:708559.0625\n",
      "epoch  1  batch  0  loss  tensor(194.9503, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  1  loss  tensor(258.8984, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  2  loss  tensor(224.7650, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  3  loss  tensor(196.1632, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  4  loss  tensor(207.0134, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  5  loss  tensor(203.8381, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  6  loss  tensor(255.0694, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  7  loss  tensor(182.0068, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  8  loss  tensor(194.3622, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  9  loss  tensor(180.7153, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  10  loss  tensor(213.5020, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  11  loss  tensor(188.5169, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  12  loss  tensor(171.1105, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  13  loss  tensor(216.5459, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  14  loss  tensor(156.1324, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  15  loss  tensor(200.2677, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  16  loss  tensor(177.7186, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  17  loss  tensor(197.2124, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  18  loss  tensor(169.9135, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  19  loss  tensor(202.5954, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  20  loss  tensor(208.4274, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  21  loss  tensor(181.8581, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  22  loss  tensor(194.3977, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  23  loss  tensor(201.9562, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  24  loss  tensor(151.2087, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  25  loss  tensor(141.0885, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  26  loss  tensor(173.8643, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  27  loss  tensor(171.1744, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  28  loss  tensor(199.1522, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  29  loss  tensor(171.1599, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  30  loss  tensor(184.3676, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  31  loss  tensor(199.4473, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  32  loss  tensor(177.9999, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  33  loss  tensor(179.8372, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  34  loss  tensor(166.4255, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  35  loss  tensor(175.3764, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  36  loss  tensor(158.6692, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  37  loss  tensor(170.3685, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  38  loss  tensor(163.3941, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  39  loss  tensor(182.3794, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  40  loss  tensor(127.1580, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  41  loss  tensor(145.7010, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  42  loss  tensor(182.9174, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  43  loss  tensor(193.7619, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  44  loss  tensor(189.0589, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  45  loss  tensor(165.4994, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  46  loss  tensor(145.2752, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  47  loss  tensor(129.8177, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  48  loss  tensor(145.5453, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  49  loss  tensor(178.1276, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  50  loss  tensor(180.6131, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  51  loss  tensor(157.7036, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  52  loss  tensor(151.3651, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  53  loss  tensor(143.2161, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  54  loss  tensor(151.2018, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  55  loss  tensor(150.5650, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  56  loss  tensor(172.4995, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  57  loss  tensor(188.9300, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  58  loss  tensor(157.9576, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  59  loss  tensor(143.9365, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  60  loss  tensor(156.5447, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  61  loss  tensor(155.5416, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1  batch  62  loss  tensor(156.0654, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  63  loss  tensor(134.9075, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  64  loss  tensor(151.1609, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  65  loss  tensor(107.4185, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  66  loss  tensor(122.3466, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  67  loss  tensor(155.5103, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  68  loss  tensor(133.6392, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  69  loss  tensor(149.3484, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  70  loss  tensor(162.7978, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  71  loss  tensor(124.3253, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  72  loss  tensor(150.7591, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  73  loss  tensor(133.1445, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  74  loss  tensor(139.9537, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  75  loss  tensor(133.1877, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  76  loss  tensor(119.4820, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  77  loss  tensor(133.6071, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  78  loss  tensor(139.4618, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  79  loss  tensor(160.5809, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  80  loss  tensor(166.4037, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  81  loss  tensor(94.7635, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  82  loss  tensor(132.4035, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  83  loss  tensor(139.7339, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  84  loss  tensor(129.1030, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  85  loss  tensor(142.5081, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  86  loss  tensor(125.3759, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  87  loss  tensor(137.2899, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  88  loss  tensor(106.7388, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  89  loss  tensor(111.2412, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  90  loss  tensor(123.2073, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  91  loss  tensor(118.1551, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  92  loss  tensor(121.3773, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  93  loss  tensor(121.2941, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  94  loss  tensor(102.3291, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  95  loss  tensor(99.2352, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  96  loss  tensor(122.0120, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  97  loss  tensor(93.6046, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  98  loss  tensor(130.1404, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  99  loss  tensor(116.2191, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  100  loss  tensor(120.4340, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  101  loss  tensor(106.4125, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  102  loss  tensor(124.1198, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  103  loss  tensor(98.7480, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  104  loss  tensor(84.9957, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  105  loss  tensor(101.7372, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  106  loss  tensor(110.8507, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  107  loss  tensor(110.2637, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  108  loss  tensor(107.0901, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  109  loss  tensor(107.8694, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  110  loss  tensor(89.4956, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  111  loss  tensor(94.4546, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  112  loss  tensor(101.5346, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  113  loss  tensor(93.8458, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  114  loss  tensor(92.9504, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  115  loss  tensor(88.8393, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  116  loss  tensor(94.8732, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  117  loss  tensor(94.4123, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  118  loss  tensor(92.5845, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  119  loss  tensor(106.0761, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  120  loss  tensor(94.5609, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  121  loss  tensor(61.9527, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  122  loss  tensor(84.7208, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  123  loss  tensor(97.0002, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  124  loss  tensor(91.8845, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  125  loss  tensor(107.6223, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  126  loss  tensor(111.2078, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  127  loss  tensor(106.6131, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  128  loss  tensor(95.2475, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  129  loss  tensor(88.4770, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  130  loss  tensor(108.8993, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  131  loss  tensor(74.6300, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  132  loss  tensor(105.3472, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  133  loss  tensor(97.4473, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  134  loss  tensor(75.6966, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  135  loss  tensor(107.2720, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  136  loss  tensor(80.1238, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  137  loss  tensor(61.8549, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  138  loss  tensor(76.4958, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  139  loss  tensor(79.7734, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  140  loss  tensor(105.8493, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  141  loss  tensor(101.7212, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  142  loss  tensor(93.1941, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  143  loss  tensor(78.3840, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  144  loss  tensor(85.6251, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  145  loss  tensor(71.3293, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  146  loss  tensor(92.1482, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  147  loss  tensor(76.1713, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  148  loss  tensor(81.6129, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  149  loss  tensor(65.6254, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  150  loss  tensor(63.1151, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  151  loss  tensor(68.1769, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  152  loss  tensor(76.6019, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  153  loss  tensor(64.3776, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  154  loss  tensor(71.0135, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  155  loss  tensor(92.1403, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  156  loss  tensor(65.9121, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  157  loss  tensor(77.4031, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  158  loss  tensor(67.3471, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  159  loss  tensor(62.0640, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  160  loss  tensor(61.7476, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  161  loss  tensor(72.2250, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  162  loss  tensor(68.4407, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  163  loss  tensor(82.2581, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  164  loss  tensor(62.2557, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  165  loss  tensor(64.0351, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  166  loss  tensor(64.0145, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  167  loss  tensor(76.0646, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  168  loss  tensor(75.7433, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  169  loss  tensor(66.3594, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  170  loss  tensor(86.1087, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  171  loss  tensor(73.3162, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  172  loss  tensor(54.9651, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  173  loss  tensor(64.0858, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  174  loss  tensor(64.5464, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  175  loss  tensor(61.8054, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  176  loss  tensor(59.0981, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  177  loss  tensor(60.0254, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  178  loss  tensor(67.1009, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  179  loss  tensor(63.0593, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  180  loss  tensor(87.3196, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  181  loss  tensor(54.9423, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  182  loss  tensor(48.9653, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1  batch  183  loss  tensor(67.0593, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  184  loss  tensor(62.5900, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  185  loss  tensor(61.7141, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  186  loss  tensor(50.6915, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  187  loss  tensor(51.2531, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  188  loss  tensor(60.2645, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  189  loss  tensor(78.1916, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  190  loss  tensor(58.8708, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  191  loss  tensor(60.9541, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  192  loss  tensor(70.9245, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  193  loss  tensor(85.1901, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  194  loss  tensor(57.6890, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  195  loss  tensor(56.0009, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  196  loss  tensor(48.4839, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  197  loss  tensor(33.1307, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  198  loss  tensor(54.8241, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  199  loss  tensor(62.3159, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  200  loss  tensor(66.6315, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  201  loss  tensor(43.8927, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  202  loss  tensor(39.9983, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  203  loss  tensor(57.9358, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  204  loss  tensor(92.0611, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  205  loss  tensor(70.3688, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  206  loss  tensor(47.1980, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  207  loss  tensor(42.4965, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  208  loss  tensor(44.6624, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  209  loss  tensor(66.1307, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  210  loss  tensor(47.2110, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  211  loss  tensor(55.0801, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  212  loss  tensor(76.9957, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  213  loss  tensor(45.9666, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  214  loss  tensor(47.3795, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  215  loss  tensor(55.0824, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  216  loss  tensor(63.6564, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  217  loss  tensor(58.6083, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  218  loss  tensor(101.9752, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  219  loss  tensor(52.8169, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  220  loss  tensor(39.7236, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  221  loss  tensor(64.8264, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  222  loss  tensor(50.0318, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  223  loss  tensor(68.5973, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  224  loss  tensor(37.7406, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  225  loss  tensor(52.5555, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  226  loss  tensor(50.6575, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  227  loss  tensor(51.9990, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  228  loss  tensor(61.3445, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  229  loss  tensor(39.2295, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  230  loss  tensor(43.4508, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  231  loss  tensor(32.9230, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  232  loss  tensor(38.5880, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  233  loss  tensor(42.5491, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  234  loss  tensor(32.2263, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  235  loss  tensor(31.4309, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  236  loss  tensor(42.1349, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  237  loss  tensor(50.8101, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  238  loss  tensor(31.4814, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  239  loss  tensor(44.4667, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  240  loss  tensor(36.4972, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  241  loss  tensor(43.5211, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  242  loss  tensor(30.6207, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  243  loss  tensor(39.1857, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  244  loss  tensor(40.3084, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  245  loss  tensor(44.4366, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  246  loss  tensor(36.8360, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  247  loss  tensor(36.3489, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  248  loss  tensor(29.3383, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  249  loss  tensor(38.2499, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  250  loss  tensor(32.3821, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  251  loss  tensor(35.5698, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  252  loss  tensor(26.9447, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  253  loss  tensor(32.3758, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  254  loss  tensor(48.8710, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  255  loss  tensor(35.3205, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  256  loss  tensor(44.3040, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  257  loss  tensor(37.2934, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  258  loss  tensor(37.8367, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  259  loss  tensor(19.0822, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  260  loss  tensor(43.7460, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  261  loss  tensor(41.4309, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  262  loss  tensor(34.0278, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  263  loss  tensor(20.0196, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  264  loss  tensor(38.8502, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  265  loss  tensor(38.2655, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  266  loss  tensor(27.0633, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  267  loss  tensor(28.5162, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  268  loss  tensor(30.5319, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  269  loss  tensor(32.3123, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  270  loss  tensor(35.7795, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  271  loss  tensor(37.2464, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  272  loss  tensor(31.8893, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  273  loss  tensor(42.5448, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  274  loss  tensor(21.2400, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  275  loss  tensor(37.2228, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  276  loss  tensor(46.9230, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  277  loss  tensor(43.6314, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  278  loss  tensor(21.6083, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  279  loss  tensor(31.9992, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  280  loss  tensor(40.8809, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  281  loss  tensor(26.5592, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  282  loss  tensor(32.1550, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  283  loss  tensor(37.7566, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  284  loss  tensor(38.6986, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  285  loss  tensor(37.6694, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  286  loss  tensor(42.9189, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  287  loss  tensor(42.6071, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  288  loss  tensor(31.0509, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  289  loss  tensor(36.8054, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  290  loss  tensor(32.4632, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  291  loss  tensor(31.5562, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  292  loss  tensor(30.7571, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  293  loss  tensor(39.4535, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  294  loss  tensor(29.5743, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  295  loss  tensor(18.4655, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  296  loss  tensor(33.2006, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  297  loss  tensor(28.4456, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  298  loss  tensor(26.4348, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  299  loss  tensor(32.0126, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  300  loss  tensor(30.0139, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  301  loss  tensor(27.3386, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  302  loss  tensor(36.9770, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  303  loss  tensor(22.4383, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1  batch  304  loss  tensor(28.6934, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  305  loss  tensor(30.7762, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  306  loss  tensor(35.3815, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  307  loss  tensor(25.8917, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  308  loss  tensor(37.7597, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  309  loss  tensor(33.3362, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  310  loss  tensor(36.5645, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  311  loss  tensor(36.0645, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  312  loss  tensor(31.8713, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  313  loss  tensor(22.0683, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  314  loss  tensor(40.0471, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  315  loss  tensor(26.2990, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  316  loss  tensor(16.8627, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  317  loss  tensor(43.4323, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  318  loss  tensor(21.9470, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  319  loss  tensor(27.2008, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  320  loss  tensor(24.2768, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  321  loss  tensor(22.2743, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  322  loss  tensor(21.2506, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  323  loss  tensor(26.5200, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  324  loss  tensor(24.8530, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  325  loss  tensor(18.4208, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  326  loss  tensor(24.1958, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  327  loss  tensor(17.2827, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  328  loss  tensor(34.5365, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  329  loss  tensor(28.9895, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  330  loss  tensor(26.1827, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  331  loss  tensor(12.7623, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  332  loss  tensor(23.6343, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  333  loss  tensor(14.6955, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  334  loss  tensor(22.4983, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  335  loss  tensor(28.8319, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  336  loss  tensor(26.8280, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  337  loss  tensor(18.9450, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  338  loss  tensor(19.6675, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  339  loss  tensor(22.2095, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  340  loss  tensor(18.8253, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  341  loss  tensor(15.0018, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  342  loss  tensor(20.3120, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  343  loss  tensor(16.4073, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  344  loss  tensor(19.5511, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  345  loss  tensor(24.7689, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  346  loss  tensor(23.5277, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  347  loss  tensor(21.5000, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  348  loss  tensor(25.6301, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  349  loss  tensor(16.0005, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  350  loss  tensor(16.3413, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  351  loss  tensor(20.2427, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  352  loss  tensor(20.5094, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  353  loss  tensor(16.8903, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  354  loss  tensor(17.4574, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  355  loss  tensor(21.8789, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  356  loss  tensor(20.4122, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  357  loss  tensor(28.9995, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  358  loss  tensor(22.6485, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  359  loss  tensor(9.9572, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  360  loss  tensor(20.8172, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  361  loss  tensor(14.2706, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  362  loss  tensor(22.1727, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  363  loss  tensor(27.3663, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  364  loss  tensor(8.7955, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  365  loss  tensor(24.5791, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  366  loss  tensor(19.6274, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  367  loss  tensor(16.6521, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  368  loss  tensor(29.6442, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  369  loss  tensor(18.9159, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  370  loss  tensor(16.3220, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  371  loss  tensor(15.7404, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  372  loss  tensor(13.8953, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  373  loss  tensor(15.7990, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  374  loss  tensor(21.2064, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  375  loss  tensor(13.0702, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  376  loss  tensor(16.7681, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  377  loss  tensor(33.9064, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  378  loss  tensor(15.7520, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  379  loss  tensor(17.4582, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  380  loss  tensor(20.8451, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  381  loss  tensor(17.3954, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  382  loss  tensor(15.8871, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  383  loss  tensor(16.8074, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  384  loss  tensor(12.0882, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  385  loss  tensor(9.3911, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  386  loss  tensor(14.8991, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  387  loss  tensor(22.0282, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  388  loss  tensor(14.8693, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  389  loss  tensor(26.3602, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  390  loss  tensor(24.1392, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  391  loss  tensor(11.5822, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  392  loss  tensor(14.6061, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  393  loss  tensor(14.4461, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  394  loss  tensor(18.1108, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  395  loss  tensor(20.2260, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  396  loss  tensor(21.0053, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  397  loss  tensor(15.8850, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  398  loss  tensor(13.4880, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  399  loss  tensor(11.6311, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  400  loss  tensor(16.6116, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  401  loss  tensor(10.9970, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  402  loss  tensor(16.4962, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  403  loss  tensor(9.9963, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  404  loss  tensor(16.5796, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  405  loss  tensor(18.8704, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  406  loss  tensor(12.1384, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  407  loss  tensor(18.8995, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  408  loss  tensor(15.9080, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  409  loss  tensor(19.7686, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  410  loss  tensor(11.8821, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  411  loss  tensor(6.5748, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  412  loss  tensor(10.9070, grad_fn=<AddBackward0>)\n",
      "epoch  1  batch  413  loss  tensor(17.9283, grad_fn=<AddBackward0>)\n",
      "epoch [2/100], loss:30495.7051\n",
      "epoch  2  batch  0  loss  tensor(11.2637, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  1  loss  tensor(18.4291, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  2  loss  tensor(15.6580, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  3  loss  tensor(10.9108, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  4  loss  tensor(10.0912, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  5  loss  tensor(15.9703, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  6  loss  tensor(12.7022, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  7  loss  tensor(15.8962, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  8  loss  tensor(14.8622, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  9  loss  tensor(16.4570, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  10  loss  tensor(15.5225, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2  batch  11  loss  tensor(15.3166, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  12  loss  tensor(8.7921, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  13  loss  tensor(17.7690, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  14  loss  tensor(9.4308, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  15  loss  tensor(11.9869, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  16  loss  tensor(9.1149, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  17  loss  tensor(15.6813, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  18  loss  tensor(9.6906, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  19  loss  tensor(8.3281, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  20  loss  tensor(7.0595, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  21  loss  tensor(13.7764, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  22  loss  tensor(11.6581, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  23  loss  tensor(12.6641, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  24  loss  tensor(13.5387, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  25  loss  tensor(6.7002, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  26  loss  tensor(19.2429, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  27  loss  tensor(12.8936, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  28  loss  tensor(10.0230, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  29  loss  tensor(19.1432, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  30  loss  tensor(13.7860, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  31  loss  tensor(14.1208, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  32  loss  tensor(10.5630, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  33  loss  tensor(15.6824, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  34  loss  tensor(6.9228, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  35  loss  tensor(15.9590, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  36  loss  tensor(9.8324, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  37  loss  tensor(10.0883, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  38  loss  tensor(14.5290, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  39  loss  tensor(11.3852, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  40  loss  tensor(11.3141, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  41  loss  tensor(14.2756, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  42  loss  tensor(5.9122, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  43  loss  tensor(12.8451, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  44  loss  tensor(12.8492, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  45  loss  tensor(15.6956, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  46  loss  tensor(14.8025, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  47  loss  tensor(12.6765, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  48  loss  tensor(9.7639, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  49  loss  tensor(5.5701, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  50  loss  tensor(17.4693, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  51  loss  tensor(6.9271, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  52  loss  tensor(11.2350, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  53  loss  tensor(7.2313, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  54  loss  tensor(20.1096, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  55  loss  tensor(7.6363, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  56  loss  tensor(14.6782, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  57  loss  tensor(5.0521, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  58  loss  tensor(9.2037, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  59  loss  tensor(8.6991, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  60  loss  tensor(12.6840, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  61  loss  tensor(6.0570, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  62  loss  tensor(6.9433, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  63  loss  tensor(9.4665, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  64  loss  tensor(13.4948, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  65  loss  tensor(9.2653, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  66  loss  tensor(7.4143, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  67  loss  tensor(6.5186, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  68  loss  tensor(10.6407, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  69  loss  tensor(8.9164, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  70  loss  tensor(9.9732, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  71  loss  tensor(13.6046, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  72  loss  tensor(9.6093, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  73  loss  tensor(14.2465, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  74  loss  tensor(4.7592, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  75  loss  tensor(8.8231, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  76  loss  tensor(10.5673, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  77  loss  tensor(9.2255, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  78  loss  tensor(7.9997, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  79  loss  tensor(5.4339, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  80  loss  tensor(16.5498, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  81  loss  tensor(9.4285, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  82  loss  tensor(9.0270, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  83  loss  tensor(11.7434, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  84  loss  tensor(8.4650, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  85  loss  tensor(18.9112, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  86  loss  tensor(15.9712, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  87  loss  tensor(8.9944, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  88  loss  tensor(6.0319, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  89  loss  tensor(10.4290, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  90  loss  tensor(9.7679, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  91  loss  tensor(7.4258, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  92  loss  tensor(5.8620, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  93  loss  tensor(12.6902, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  94  loss  tensor(9.4116, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  95  loss  tensor(9.7569, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  96  loss  tensor(16.3330, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  97  loss  tensor(10.1718, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  98  loss  tensor(30.6467, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  99  loss  tensor(8.6236, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  100  loss  tensor(5.9391, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  101  loss  tensor(7.1677, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  102  loss  tensor(14.9641, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  103  loss  tensor(6.7209, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  104  loss  tensor(9.7697, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  105  loss  tensor(12.5533, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  106  loss  tensor(7.1034, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  107  loss  tensor(8.0637, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  108  loss  tensor(3.8660, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  109  loss  tensor(4.2768, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  110  loss  tensor(10.7091, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  111  loss  tensor(5.6191, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  112  loss  tensor(7.1764, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  113  loss  tensor(7.0106, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  114  loss  tensor(9.6602, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  115  loss  tensor(6.7052, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  116  loss  tensor(5.3629, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  117  loss  tensor(7.4670, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  118  loss  tensor(6.2551, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  119  loss  tensor(5.7938, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  120  loss  tensor(9.9967, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  121  loss  tensor(4.7231, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  122  loss  tensor(6.5634, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  123  loss  tensor(4.9292, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  124  loss  tensor(9.6488, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  125  loss  tensor(5.8895, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  126  loss  tensor(6.0607, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  127  loss  tensor(10.8168, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  128  loss  tensor(4.4393, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  129  loss  tensor(8.2124, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  130  loss  tensor(5.4904, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  131  loss  tensor(15.0047, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  132  loss  tensor(10.3457, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  133  loss  tensor(6.7768, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2  batch  134  loss  tensor(4.5184, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  135  loss  tensor(8.2495, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  136  loss  tensor(6.9651, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  137  loss  tensor(8.5368, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  138  loss  tensor(8.1409, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  139  loss  tensor(9.1825, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  140  loss  tensor(9.8111, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  141  loss  tensor(6.0603, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  142  loss  tensor(4.5611, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  143  loss  tensor(10.7106, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  144  loss  tensor(4.2240, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  145  loss  tensor(4.2162, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  146  loss  tensor(6.1815, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  147  loss  tensor(6.6379, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  148  loss  tensor(7.2585, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  149  loss  tensor(10.1173, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  150  loss  tensor(13.1940, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  151  loss  tensor(4.4709, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  152  loss  tensor(4.5097, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  153  loss  tensor(6.2723, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  154  loss  tensor(4.0059, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  155  loss  tensor(5.9054, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  156  loss  tensor(4.8922, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  157  loss  tensor(3.9905, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  158  loss  tensor(6.0774, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  159  loss  tensor(3.0164, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  160  loss  tensor(21.4768, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  161  loss  tensor(7.2269, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  162  loss  tensor(4.3166, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  163  loss  tensor(5.7196, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  164  loss  tensor(8.8581, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  165  loss  tensor(4.8682, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  166  loss  tensor(5.8899, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  167  loss  tensor(10.5328, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  168  loss  tensor(4.3492, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  169  loss  tensor(4.4931, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  170  loss  tensor(13.7398, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  171  loss  tensor(9.8649, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  172  loss  tensor(12.2549, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  173  loss  tensor(3.9619, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  174  loss  tensor(2.8834, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  175  loss  tensor(3.9102, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  176  loss  tensor(5.5231, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  177  loss  tensor(5.5180, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  178  loss  tensor(6.5687, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  179  loss  tensor(4.0112, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  180  loss  tensor(6.5239, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  181  loss  tensor(12.9633, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  182  loss  tensor(5.4347, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  183  loss  tensor(4.3263, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  184  loss  tensor(8.3595, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  185  loss  tensor(4.4539, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  186  loss  tensor(2.7244, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  187  loss  tensor(6.7135, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  188  loss  tensor(2.5742, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  189  loss  tensor(5.0946, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  190  loss  tensor(5.2560, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  191  loss  tensor(4.6149, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  192  loss  tensor(3.7268, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  193  loss  tensor(4.3957, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  194  loss  tensor(5.8725, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  195  loss  tensor(6.1297, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  196  loss  tensor(9.8129, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  197  loss  tensor(4.3726, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  198  loss  tensor(3.9237, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  199  loss  tensor(7.6414, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  200  loss  tensor(5.7226, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  201  loss  tensor(8.3875, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  202  loss  tensor(3.3921, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  203  loss  tensor(5.6599, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  204  loss  tensor(9.1127, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  205  loss  tensor(5.1419, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  206  loss  tensor(4.8511, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  207  loss  tensor(3.5352, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  208  loss  tensor(3.6838, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  209  loss  tensor(4.0828, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  210  loss  tensor(2.6063, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  211  loss  tensor(5.5652, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  212  loss  tensor(4.0303, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  213  loss  tensor(8.3955, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  214  loss  tensor(4.1402, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  215  loss  tensor(3.2525, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  216  loss  tensor(6.2149, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  217  loss  tensor(3.3043, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  218  loss  tensor(4.5822, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  219  loss  tensor(3.2428, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  220  loss  tensor(2.6409, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  221  loss  tensor(3.5078, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  222  loss  tensor(3.3216, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  223  loss  tensor(3.5047, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  224  loss  tensor(11.4597, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  225  loss  tensor(2.9401, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  226  loss  tensor(3.6444, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  227  loss  tensor(9.7630, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  228  loss  tensor(4.9614, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  229  loss  tensor(2.8740, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  230  loss  tensor(2.1363, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  231  loss  tensor(2.7926, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  232  loss  tensor(3.5699, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  233  loss  tensor(2.2698, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  234  loss  tensor(1.9664, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  235  loss  tensor(5.1601, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  236  loss  tensor(3.5747, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  237  loss  tensor(3.6182, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  238  loss  tensor(8.3465, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  239  loss  tensor(3.2614, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  240  loss  tensor(9.0324, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  241  loss  tensor(7.1040, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  242  loss  tensor(3.5133, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  243  loss  tensor(4.8226, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  244  loss  tensor(6.1771, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  245  loss  tensor(3.8617, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  246  loss  tensor(5.4248, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  247  loss  tensor(4.2843, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  248  loss  tensor(6.1868, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  249  loss  tensor(13.4258, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  250  loss  tensor(7.7688, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  251  loss  tensor(3.6992, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  252  loss  tensor(5.0057, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  253  loss  tensor(2.7636, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  254  loss  tensor(2.4641, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  255  loss  tensor(3.6036, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  256  loss  tensor(3.3257, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2  batch  257  loss  tensor(5.6899, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  258  loss  tensor(6.1309, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  259  loss  tensor(4.5528, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  260  loss  tensor(2.2993, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  261  loss  tensor(4.6920, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  262  loss  tensor(2.6060, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  263  loss  tensor(4.7840, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  264  loss  tensor(3.7220, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  265  loss  tensor(6.3080, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  266  loss  tensor(3.2805, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  267  loss  tensor(2.8884, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  268  loss  tensor(3.0312, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  269  loss  tensor(3.4383, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  270  loss  tensor(3.2264, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  271  loss  tensor(3.3524, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  272  loss  tensor(2.4022, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  273  loss  tensor(4.4440, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  274  loss  tensor(7.5738, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  275  loss  tensor(14.0364, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  276  loss  tensor(4.5951, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  277  loss  tensor(4.7862, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  278  loss  tensor(1.9489, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  279  loss  tensor(3.3832, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  280  loss  tensor(1.7388, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  281  loss  tensor(3.2190, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  282  loss  tensor(1.9179, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  283  loss  tensor(4.7055, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  284  loss  tensor(4.0472, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  285  loss  tensor(4.2591, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  286  loss  tensor(4.6866, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  287  loss  tensor(1.4633, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  288  loss  tensor(2.0419, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  289  loss  tensor(3.5790, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  290  loss  tensor(12.3973, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  291  loss  tensor(3.1100, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  292  loss  tensor(3.0239, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  293  loss  tensor(2.0163, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  294  loss  tensor(2.6624, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  295  loss  tensor(3.7951, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  296  loss  tensor(3.9184, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  297  loss  tensor(2.3805, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  298  loss  tensor(5.0272, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  299  loss  tensor(3.9911, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  300  loss  tensor(7.1981, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  301  loss  tensor(2.6107, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  302  loss  tensor(2.3098, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  303  loss  tensor(1.9147, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  304  loss  tensor(2.3613, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  305  loss  tensor(4.6855, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  306  loss  tensor(1.4605, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  307  loss  tensor(4.7935, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  308  loss  tensor(2.8708, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  309  loss  tensor(2.1150, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  310  loss  tensor(6.0252, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  311  loss  tensor(1.4297, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  312  loss  tensor(6.1020, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  313  loss  tensor(3.3407, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  314  loss  tensor(1.7149, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  315  loss  tensor(5.0829, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  316  loss  tensor(8.3013, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  317  loss  tensor(2.1724, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  318  loss  tensor(6.8705, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  319  loss  tensor(4.2781, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  320  loss  tensor(1.7064, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  321  loss  tensor(4.3701, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  322  loss  tensor(7.4551, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  323  loss  tensor(1.9001, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  324  loss  tensor(6.5680, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  325  loss  tensor(2.7910, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  326  loss  tensor(1.8663, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  327  loss  tensor(1.1969, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  328  loss  tensor(1.9720, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  329  loss  tensor(4.8657, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  330  loss  tensor(4.0105, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  331  loss  tensor(5.0900, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  332  loss  tensor(2.6396, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  333  loss  tensor(5.8969, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  334  loss  tensor(2.1348, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  335  loss  tensor(4.0980, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  336  loss  tensor(5.7335, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  337  loss  tensor(2.3537, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  338  loss  tensor(2.8517, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  339  loss  tensor(6.2544, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  340  loss  tensor(1.4920, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  341  loss  tensor(1.6936, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  342  loss  tensor(5.0358, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  343  loss  tensor(7.3553, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  344  loss  tensor(1.9310, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  345  loss  tensor(4.7281, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  346  loss  tensor(2.7601, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  347  loss  tensor(3.4321, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  348  loss  tensor(1.6348, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  349  loss  tensor(1.5265, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  350  loss  tensor(1.4342, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  351  loss  tensor(12.8076, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  352  loss  tensor(4.6468, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  353  loss  tensor(1.3470, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  354  loss  tensor(3.7008, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  355  loss  tensor(2.0712, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  356  loss  tensor(1.2173, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  357  loss  tensor(5.9274, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  358  loss  tensor(1.0168, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  359  loss  tensor(5.3843, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  360  loss  tensor(2.0265, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  361  loss  tensor(2.8891, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  362  loss  tensor(2.6889, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  363  loss  tensor(2.4698, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  364  loss  tensor(1.5102, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  365  loss  tensor(1.4417, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  366  loss  tensor(5.5748, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  367  loss  tensor(5.8860, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  368  loss  tensor(2.8818, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  369  loss  tensor(3.3968, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  370  loss  tensor(4.1783, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  371  loss  tensor(1.9082, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  372  loss  tensor(2.8768, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  373  loss  tensor(9.2531, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  374  loss  tensor(1.8821, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  375  loss  tensor(2.5736, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  376  loss  tensor(2.7557, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  377  loss  tensor(3.2184, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  378  loss  tensor(1.1831, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  379  loss  tensor(2.1541, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2  batch  380  loss  tensor(1.5099, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  381  loss  tensor(4.9776, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  382  loss  tensor(9.5132, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  383  loss  tensor(3.9015, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  384  loss  tensor(1.6376, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  385  loss  tensor(1.5517, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  386  loss  tensor(3.8102, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  387  loss  tensor(5.1762, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  388  loss  tensor(0.9164, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  389  loss  tensor(3.1628, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  390  loss  tensor(2.8225, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  391  loss  tensor(2.5194, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  392  loss  tensor(3.4828, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  393  loss  tensor(1.4369, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  394  loss  tensor(3.8096, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  395  loss  tensor(1.7751, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  396  loss  tensor(1.1555, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  397  loss  tensor(1.9044, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  398  loss  tensor(1.7293, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  399  loss  tensor(1.4278, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  400  loss  tensor(6.3385, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  401  loss  tensor(3.5525, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  402  loss  tensor(1.4193, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  403  loss  tensor(1.4851, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  404  loss  tensor(1.6264, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  405  loss  tensor(1.5598, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  406  loss  tensor(1.9380, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  407  loss  tensor(2.2726, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  408  loss  tensor(1.1142, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  409  loss  tensor(6.5508, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  410  loss  tensor(2.9569, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  411  loss  tensor(1.9054, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  412  loss  tensor(4.0606, grad_fn=<AddBackward0>)\n",
      "epoch  2  batch  413  loss  tensor(2.7956, grad_fn=<AddBackward0>)\n",
      "epoch [3/100], loss:2691.8562\n",
      "epoch  3  batch  0  loss  tensor(2.2601, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  1  loss  tensor(3.4486, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  2  loss  tensor(2.1578, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  3  loss  tensor(1.1182, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  4  loss  tensor(2.8506, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  5  loss  tensor(1.2088, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  6  loss  tensor(3.6114, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  7  loss  tensor(5.7248, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  8  loss  tensor(4.8871, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  9  loss  tensor(1.1448, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  10  loss  tensor(2.1767, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  11  loss  tensor(3.5525, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  12  loss  tensor(2.5972, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  13  loss  tensor(4.5071, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  14  loss  tensor(11.6122, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  15  loss  tensor(9.5872, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  16  loss  tensor(1.3093, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  17  loss  tensor(1.4107, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  18  loss  tensor(2.3595, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  19  loss  tensor(3.8856, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  20  loss  tensor(4.1957, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  21  loss  tensor(1.4721, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  22  loss  tensor(0.8351, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  23  loss  tensor(1.6328, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  24  loss  tensor(2.6157, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  25  loss  tensor(2.2109, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  26  loss  tensor(1.7530, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  27  loss  tensor(1.5094, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  28  loss  tensor(2.6183, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  29  loss  tensor(4.4484, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  30  loss  tensor(2.1451, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  31  loss  tensor(5.6080, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  32  loss  tensor(0.8120, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  33  loss  tensor(1.8873, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  34  loss  tensor(0.8023, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  35  loss  tensor(3.2104, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  36  loss  tensor(1.6552, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  37  loss  tensor(1.6954, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  38  loss  tensor(0.5953, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  39  loss  tensor(2.7903, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  40  loss  tensor(3.4648, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  41  loss  tensor(2.6011, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  42  loss  tensor(2.7024, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  43  loss  tensor(1.8926, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  44  loss  tensor(4.3910, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  45  loss  tensor(1.1374, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  46  loss  tensor(1.9702, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  47  loss  tensor(1.2417, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  48  loss  tensor(9.8260, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  49  loss  tensor(3.2174, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  50  loss  tensor(3.6158, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  51  loss  tensor(1.3935, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  52  loss  tensor(2.1010, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  53  loss  tensor(1.1521, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  54  loss  tensor(2.7149, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  55  loss  tensor(1.8091, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  56  loss  tensor(1.0459, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  57  loss  tensor(7.4468, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  58  loss  tensor(0.7938, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  59  loss  tensor(3.2544, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  60  loss  tensor(2.5034, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  61  loss  tensor(0.9311, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  62  loss  tensor(0.7241, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  63  loss  tensor(1.1949, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  64  loss  tensor(0.9750, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  65  loss  tensor(1.9983, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  66  loss  tensor(5.1828, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  67  loss  tensor(4.0226, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  68  loss  tensor(1.0693, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  69  loss  tensor(1.2077, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  70  loss  tensor(1.0011, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  71  loss  tensor(1.3482, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  72  loss  tensor(3.3169, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  73  loss  tensor(0.7748, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  74  loss  tensor(1.6891, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  75  loss  tensor(1.5767, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  76  loss  tensor(2.3108, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  77  loss  tensor(0.9124, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  78  loss  tensor(2.8976, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  79  loss  tensor(3.3929, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  80  loss  tensor(1.0440, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  81  loss  tensor(1.7983, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  82  loss  tensor(4.0124, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  83  loss  tensor(1.5523, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  84  loss  tensor(2.8753, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  85  loss  tensor(0.7381, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  86  loss  tensor(5.3025, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  87  loss  tensor(1.9500, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  88  loss  tensor(3.2066, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  89  loss  tensor(1.3592, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3  batch  90  loss  tensor(1.4579, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  91  loss  tensor(1.3474, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  92  loss  tensor(1.4298, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  93  loss  tensor(1.7081, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  94  loss  tensor(0.6254, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  95  loss  tensor(3.3034, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  96  loss  tensor(1.6444, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  97  loss  tensor(0.9182, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  98  loss  tensor(1.4904, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  99  loss  tensor(2.8294, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  100  loss  tensor(0.9663, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  101  loss  tensor(2.9490, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  102  loss  tensor(1.6728, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  103  loss  tensor(0.9965, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  104  loss  tensor(0.8799, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  105  loss  tensor(1.7605, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  106  loss  tensor(1.6757, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  107  loss  tensor(1.5294, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  108  loss  tensor(1.2462, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  109  loss  tensor(1.9234, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  110  loss  tensor(2.1143, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  111  loss  tensor(4.1674, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  112  loss  tensor(1.4827, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  113  loss  tensor(0.6892, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  114  loss  tensor(2.0945, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  115  loss  tensor(2.0925, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  116  loss  tensor(0.7851, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  117  loss  tensor(1.1965, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  118  loss  tensor(2.1861, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  119  loss  tensor(1.0612, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  120  loss  tensor(5.7821, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  121  loss  tensor(1.4370, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  122  loss  tensor(1.2452, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  123  loss  tensor(4.0593, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  124  loss  tensor(2.0401, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  125  loss  tensor(1.0021, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  126  loss  tensor(1.9425, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  127  loss  tensor(0.8507, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  128  loss  tensor(1.1029, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  129  loss  tensor(3.8379, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  130  loss  tensor(0.7694, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  131  loss  tensor(0.6832, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  132  loss  tensor(2.0789, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  133  loss  tensor(1.5072, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  134  loss  tensor(1.7333, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  135  loss  tensor(6.1386, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  136  loss  tensor(1.4938, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  137  loss  tensor(3.1097, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  138  loss  tensor(1.0992, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  139  loss  tensor(3.9534, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  140  loss  tensor(3.0640, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  141  loss  tensor(0.6738, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  142  loss  tensor(0.9195, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  143  loss  tensor(2.5264, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  144  loss  tensor(1.4091, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  145  loss  tensor(2.0213, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  146  loss  tensor(0.9061, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  147  loss  tensor(0.7160, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  148  loss  tensor(4.0301, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  149  loss  tensor(0.5040, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  150  loss  tensor(1.2675, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  151  loss  tensor(0.9711, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  152  loss  tensor(0.6747, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  153  loss  tensor(6.8036, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  154  loss  tensor(0.9222, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  155  loss  tensor(0.8600, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  156  loss  tensor(1.2856, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  157  loss  tensor(2.7104, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  158  loss  tensor(5.0154, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  159  loss  tensor(0.6590, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  160  loss  tensor(0.6040, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  161  loss  tensor(1.1943, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  162  loss  tensor(1.0062, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  163  loss  tensor(1.0598, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  164  loss  tensor(2.0149, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  165  loss  tensor(0.8919, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  166  loss  tensor(1.1855, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  167  loss  tensor(0.4673, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  168  loss  tensor(1.7172, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  169  loss  tensor(0.6241, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  170  loss  tensor(0.9206, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  171  loss  tensor(0.7993, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  172  loss  tensor(0.9584, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  173  loss  tensor(0.5446, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  174  loss  tensor(1.4961, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  175  loss  tensor(0.4771, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  176  loss  tensor(2.8531, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  177  loss  tensor(1.5729, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  178  loss  tensor(2.5569, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  179  loss  tensor(0.4184, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  180  loss  tensor(0.7565, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  181  loss  tensor(0.8594, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  182  loss  tensor(1.2309, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  183  loss  tensor(1.1345, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  184  loss  tensor(2.0372, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  185  loss  tensor(4.2344, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  186  loss  tensor(2.1322, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  187  loss  tensor(2.2488, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  188  loss  tensor(0.5317, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  189  loss  tensor(0.6029, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  190  loss  tensor(0.9221, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  191  loss  tensor(0.3028, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  192  loss  tensor(1.3906, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  193  loss  tensor(1.0159, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  194  loss  tensor(0.5116, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  195  loss  tensor(0.9563, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  196  loss  tensor(0.5324, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  197  loss  tensor(1.3386, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  198  loss  tensor(1.2118, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  199  loss  tensor(4.4719, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  200  loss  tensor(0.6570, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  201  loss  tensor(1.5325, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  202  loss  tensor(0.5544, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  203  loss  tensor(0.5085, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  204  loss  tensor(0.9204, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  205  loss  tensor(0.8465, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  206  loss  tensor(0.5670, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  207  loss  tensor(1.1380, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  208  loss  tensor(3.3479, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  209  loss  tensor(1.9581, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  210  loss  tensor(0.6966, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  211  loss  tensor(0.4850, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  212  loss  tensor(0.4112, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3  batch  213  loss  tensor(0.7015, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  214  loss  tensor(1.4743, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  215  loss  tensor(1.2204, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  216  loss  tensor(0.9645, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  217  loss  tensor(1.7378, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  218  loss  tensor(0.5019, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  219  loss  tensor(1.2120, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  220  loss  tensor(0.8616, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  221  loss  tensor(1.3988, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  222  loss  tensor(1.5081, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  223  loss  tensor(1.0069, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  224  loss  tensor(2.9094, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  225  loss  tensor(0.6317, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  226  loss  tensor(1.0469, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  227  loss  tensor(0.7705, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  228  loss  tensor(2.1984, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  229  loss  tensor(0.3271, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  230  loss  tensor(2.9354, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  231  loss  tensor(0.6831, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  232  loss  tensor(1.2120, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  233  loss  tensor(1.4232, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  234  loss  tensor(0.8356, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  235  loss  tensor(0.6809, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  236  loss  tensor(0.9084, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  237  loss  tensor(1.8274, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  238  loss  tensor(1.0153, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  239  loss  tensor(1.7326, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  240  loss  tensor(0.4960, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  241  loss  tensor(1.0928, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  242  loss  tensor(0.8637, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  243  loss  tensor(0.3835, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  244  loss  tensor(0.9316, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  245  loss  tensor(0.6737, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  246  loss  tensor(2.1583, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  247  loss  tensor(0.5385, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  248  loss  tensor(1.2473, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  249  loss  tensor(1.1054, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  250  loss  tensor(1.1239, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  251  loss  tensor(0.7532, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  252  loss  tensor(0.6850, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  253  loss  tensor(3.1937, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  254  loss  tensor(0.4235, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  255  loss  tensor(1.5351, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  256  loss  tensor(0.7454, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  257  loss  tensor(1.2825, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  258  loss  tensor(0.4352, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  259  loss  tensor(0.5116, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  260  loss  tensor(0.3839, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  261  loss  tensor(0.7056, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  262  loss  tensor(0.6343, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  263  loss  tensor(0.7767, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  264  loss  tensor(1.0595, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  265  loss  tensor(0.9673, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  266  loss  tensor(5.7481, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  267  loss  tensor(0.7185, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  268  loss  tensor(1.0893, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  269  loss  tensor(0.4271, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  270  loss  tensor(0.6199, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  271  loss  tensor(1.9741, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  272  loss  tensor(0.9956, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  273  loss  tensor(0.3368, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  274  loss  tensor(0.7298, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  275  loss  tensor(2.1783, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  276  loss  tensor(0.4137, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  277  loss  tensor(0.8448, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  278  loss  tensor(0.9975, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  279  loss  tensor(0.4618, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  280  loss  tensor(2.6739, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  281  loss  tensor(0.8975, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  282  loss  tensor(1.2489, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  283  loss  tensor(0.6028, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  284  loss  tensor(1.0007, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  285  loss  tensor(0.6814, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  286  loss  tensor(1.1514, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  287  loss  tensor(0.9418, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  288  loss  tensor(1.4412, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  289  loss  tensor(0.8325, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  290  loss  tensor(0.9311, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  291  loss  tensor(0.8478, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  292  loss  tensor(0.2125, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  293  loss  tensor(1.0219, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  294  loss  tensor(0.3128, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  295  loss  tensor(1.8945, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  296  loss  tensor(0.4983, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  297  loss  tensor(1.0173, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  298  loss  tensor(1.0094, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  299  loss  tensor(0.7927, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  300  loss  tensor(1.7505, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  301  loss  tensor(1.5730, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  302  loss  tensor(0.5640, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  303  loss  tensor(1.1854, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  304  loss  tensor(12.1263, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  305  loss  tensor(1.4952, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  306  loss  tensor(0.8168, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  307  loss  tensor(1.5239, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  308  loss  tensor(1.0115, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  309  loss  tensor(0.6332, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  310  loss  tensor(1.6369, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  311  loss  tensor(0.6202, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  312  loss  tensor(1.2921, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  313  loss  tensor(1.0399, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  314  loss  tensor(1.4360, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  315  loss  tensor(2.6319, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  316  loss  tensor(0.3739, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  317  loss  tensor(0.8931, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  318  loss  tensor(0.8229, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  319  loss  tensor(1.4830, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  320  loss  tensor(0.2966, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  321  loss  tensor(1.8124, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  322  loss  tensor(0.7762, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  323  loss  tensor(1.0863, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  324  loss  tensor(0.8420, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  325  loss  tensor(0.6118, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  326  loss  tensor(0.3388, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  327  loss  tensor(0.9848, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  328  loss  tensor(2.0714, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  329  loss  tensor(0.7297, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  330  loss  tensor(0.3849, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  331  loss  tensor(1.0960, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  332  loss  tensor(0.3925, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  333  loss  tensor(3.7187, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  334  loss  tensor(0.5776, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  335  loss  tensor(0.5038, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3  batch  336  loss  tensor(1.0947, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  337  loss  tensor(0.4875, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  338  loss  tensor(0.3624, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  339  loss  tensor(0.6826, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  340  loss  tensor(0.3631, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  341  loss  tensor(0.5079, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  342  loss  tensor(0.5684, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  343  loss  tensor(1.5712, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  344  loss  tensor(0.8535, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  345  loss  tensor(0.7589, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  346  loss  tensor(0.5129, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  347  loss  tensor(0.3759, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  348  loss  tensor(0.5678, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  349  loss  tensor(0.4160, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  350  loss  tensor(3.2893, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  351  loss  tensor(0.4982, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  352  loss  tensor(1.0149, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  353  loss  tensor(0.3553, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  354  loss  tensor(0.8871, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  355  loss  tensor(1.3682, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  356  loss  tensor(0.7365, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  357  loss  tensor(2.2584, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  358  loss  tensor(1.4832, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  359  loss  tensor(1.8483, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  360  loss  tensor(0.7998, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  361  loss  tensor(1.7017, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  362  loss  tensor(1.3534, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  363  loss  tensor(1.2453, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  364  loss  tensor(1.3122, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  365  loss  tensor(0.3212, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  366  loss  tensor(0.5354, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  367  loss  tensor(2.7902, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  368  loss  tensor(0.4681, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  369  loss  tensor(0.3835, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  370  loss  tensor(1.0232, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  371  loss  tensor(1.3155, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  372  loss  tensor(0.5561, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  373  loss  tensor(0.6849, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  374  loss  tensor(5.7969, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  375  loss  tensor(0.4247, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  376  loss  tensor(0.5079, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  377  loss  tensor(1.4368, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  378  loss  tensor(1.5541, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  379  loss  tensor(0.5753, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  380  loss  tensor(0.3857, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  381  loss  tensor(0.5202, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  382  loss  tensor(1.5705, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  383  loss  tensor(0.3845, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  384  loss  tensor(0.2844, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  385  loss  tensor(1.5416, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  386  loss  tensor(0.5112, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  387  loss  tensor(0.7535, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  388  loss  tensor(2.8901, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  389  loss  tensor(1.0241, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  390  loss  tensor(0.4705, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  391  loss  tensor(0.3887, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  392  loss  tensor(0.7165, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  393  loss  tensor(0.6879, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  394  loss  tensor(0.6145, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  395  loss  tensor(1.4896, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  396  loss  tensor(0.8476, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  397  loss  tensor(0.3934, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  398  loss  tensor(0.4216, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  399  loss  tensor(0.9631, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  400  loss  tensor(0.4778, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  401  loss  tensor(0.7589, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  402  loss  tensor(0.6228, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  403  loss  tensor(0.4310, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  404  loss  tensor(1.3969, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  405  loss  tensor(0.8439, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  406  loss  tensor(0.6153, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  407  loss  tensor(0.7522, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  408  loss  tensor(0.8422, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  409  loss  tensor(0.8158, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  410  loss  tensor(0.5587, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  411  loss  tensor(0.2949, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  412  loss  tensor(0.3170, grad_fn=<AddBackward0>)\n",
      "epoch  3  batch  413  loss  tensor(1.1737, grad_fn=<AddBackward0>)\n",
      "epoch [4/100], loss:657.5029\n",
      "epoch  4  batch  0  loss  tensor(0.1777, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  1  loss  tensor(0.3460, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  2  loss  tensor(0.5414, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  3  loss  tensor(0.3843, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  4  loss  tensor(0.8296, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  5  loss  tensor(0.4935, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  6  loss  tensor(0.6837, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  7  loss  tensor(0.4238, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  8  loss  tensor(0.7367, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  9  loss  tensor(0.4722, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  10  loss  tensor(1.7548, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  11  loss  tensor(0.3500, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  12  loss  tensor(0.6495, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  13  loss  tensor(1.6270, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  14  loss  tensor(0.4907, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  15  loss  tensor(2.0079, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  16  loss  tensor(2.2155, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  17  loss  tensor(0.5976, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  18  loss  tensor(0.3388, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  19  loss  tensor(1.3356, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  20  loss  tensor(0.4948, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  21  loss  tensor(0.7712, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  22  loss  tensor(1.8867, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  23  loss  tensor(0.8353, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  24  loss  tensor(0.4341, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  25  loss  tensor(0.9903, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  26  loss  tensor(1.4644, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  27  loss  tensor(0.6921, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  28  loss  tensor(0.3621, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  29  loss  tensor(1.0229, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  30  loss  tensor(1.3090, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  31  loss  tensor(0.9300, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  32  loss  tensor(0.6899, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  33  loss  tensor(0.4677, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  34  loss  tensor(0.3200, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  35  loss  tensor(0.7909, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  36  loss  tensor(0.2641, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  37  loss  tensor(0.7212, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  38  loss  tensor(1.2017, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  39  loss  tensor(0.7761, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  40  loss  tensor(0.4728, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  41  loss  tensor(0.5151, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  42  loss  tensor(1.2782, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  43  loss  tensor(1.8756, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  44  loss  tensor(0.3735, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4  batch  45  loss  tensor(0.5484, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  46  loss  tensor(0.4156, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  47  loss  tensor(0.2930, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  48  loss  tensor(0.2052, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  49  loss  tensor(0.5585, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  50  loss  tensor(0.4072, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  51  loss  tensor(0.2691, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  52  loss  tensor(0.4022, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  53  loss  tensor(1.8362, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  54  loss  tensor(0.6425, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  55  loss  tensor(2.9096, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  56  loss  tensor(0.7743, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  57  loss  tensor(0.4339, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  58  loss  tensor(0.2921, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  59  loss  tensor(0.2370, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  60  loss  tensor(1.1619, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  61  loss  tensor(0.3662, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  62  loss  tensor(0.8085, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  63  loss  tensor(0.2668, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  64  loss  tensor(0.7002, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  65  loss  tensor(0.5847, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  66  loss  tensor(0.6420, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  67  loss  tensor(0.7058, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  68  loss  tensor(0.7250, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  69  loss  tensor(1.2275, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  70  loss  tensor(0.2180, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  71  loss  tensor(0.6921, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  72  loss  tensor(0.4606, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  73  loss  tensor(0.5979, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  74  loss  tensor(0.1875, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  75  loss  tensor(0.9283, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  76  loss  tensor(0.3542, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  77  loss  tensor(0.2867, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  78  loss  tensor(0.3916, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  79  loss  tensor(0.3417, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  80  loss  tensor(0.1953, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  81  loss  tensor(0.7446, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  82  loss  tensor(0.5741, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  83  loss  tensor(0.6381, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  84  loss  tensor(0.3252, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  85  loss  tensor(0.3649, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  86  loss  tensor(0.3857, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  87  loss  tensor(0.3446, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  88  loss  tensor(0.2251, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  89  loss  tensor(0.3705, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  90  loss  tensor(0.3496, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  91  loss  tensor(0.8206, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  92  loss  tensor(0.4684, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  93  loss  tensor(0.9083, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  94  loss  tensor(0.2898, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  95  loss  tensor(0.2196, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  96  loss  tensor(0.2907, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  97  loss  tensor(0.6032, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  98  loss  tensor(1.0546, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  99  loss  tensor(0.2433, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  100  loss  tensor(0.4770, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  101  loss  tensor(0.3804, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  102  loss  tensor(0.6208, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  103  loss  tensor(0.4207, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  104  loss  tensor(0.4005, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  105  loss  tensor(0.3427, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  106  loss  tensor(0.3300, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  107  loss  tensor(0.6812, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  108  loss  tensor(1.1916, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  109  loss  tensor(0.8332, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  110  loss  tensor(0.2635, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  111  loss  tensor(0.4212, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  112  loss  tensor(0.6275, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  113  loss  tensor(1.2834, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  114  loss  tensor(1.1848, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  115  loss  tensor(0.3639, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  116  loss  tensor(0.3895, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  117  loss  tensor(0.5069, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  118  loss  tensor(0.2780, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  119  loss  tensor(0.4168, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  120  loss  tensor(0.5750, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  121  loss  tensor(0.5372, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  122  loss  tensor(0.3307, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  123  loss  tensor(1.0565, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  124  loss  tensor(1.0399, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  125  loss  tensor(0.3175, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  126  loss  tensor(0.3097, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  127  loss  tensor(0.4524, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  128  loss  tensor(0.9966, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  129  loss  tensor(0.2072, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  130  loss  tensor(0.2555, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  131  loss  tensor(0.7091, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  132  loss  tensor(1.4872, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  133  loss  tensor(0.3257, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  134  loss  tensor(1.1337, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  135  loss  tensor(0.1938, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  136  loss  tensor(1.2557, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  137  loss  tensor(0.4002, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  138  loss  tensor(0.4443, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  139  loss  tensor(0.2643, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  140  loss  tensor(0.6147, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  141  loss  tensor(0.2728, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  142  loss  tensor(0.2486, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  143  loss  tensor(0.7747, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  144  loss  tensor(0.4771, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  145  loss  tensor(0.8464, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  146  loss  tensor(0.3300, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  147  loss  tensor(2.4779, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  148  loss  tensor(0.5467, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  149  loss  tensor(0.4226, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  150  loss  tensor(0.3675, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  151  loss  tensor(0.7240, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  152  loss  tensor(0.5824, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  153  loss  tensor(0.3521, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  154  loss  tensor(1.3286, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  155  loss  tensor(0.4549, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  156  loss  tensor(0.3596, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  157  loss  tensor(0.4192, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  158  loss  tensor(0.9963, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  159  loss  tensor(0.4857, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  160  loss  tensor(0.3656, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  161  loss  tensor(0.2388, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  162  loss  tensor(0.4228, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  163  loss  tensor(0.3653, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  164  loss  tensor(0.4733, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  165  loss  tensor(0.3674, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  166  loss  tensor(1.3614, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  167  loss  tensor(0.6251, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  168  loss  tensor(0.2915, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4  batch  169  loss  tensor(0.3419, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  170  loss  tensor(0.2710, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  171  loss  tensor(0.3712, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  172  loss  tensor(0.8042, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  173  loss  tensor(0.6163, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  174  loss  tensor(0.3152, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  175  loss  tensor(0.6302, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  176  loss  tensor(0.4305, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  177  loss  tensor(0.4724, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  178  loss  tensor(0.3825, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  179  loss  tensor(0.3117, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  180  loss  tensor(0.3480, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  181  loss  tensor(0.5517, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  182  loss  tensor(0.4064, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  183  loss  tensor(0.3209, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  184  loss  tensor(0.1457, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  185  loss  tensor(0.2342, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  186  loss  tensor(0.2920, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  187  loss  tensor(0.1918, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  188  loss  tensor(0.2231, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  189  loss  tensor(0.3831, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  190  loss  tensor(0.1848, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  191  loss  tensor(0.6676, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  192  loss  tensor(0.5119, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  193  loss  tensor(0.1967, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  194  loss  tensor(0.2908, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  195  loss  tensor(0.2064, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  196  loss  tensor(0.9099, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  197  loss  tensor(0.6377, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  198  loss  tensor(0.8400, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  199  loss  tensor(0.3297, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  200  loss  tensor(2.1047, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  201  loss  tensor(0.2969, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  202  loss  tensor(0.3075, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  203  loss  tensor(0.2738, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  204  loss  tensor(0.4675, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  205  loss  tensor(0.3180, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  206  loss  tensor(1.2191, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  207  loss  tensor(0.2043, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  208  loss  tensor(1.8138, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  209  loss  tensor(0.3625, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  210  loss  tensor(3.6078, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  211  loss  tensor(0.8166, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  212  loss  tensor(3.3818, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  213  loss  tensor(0.6029, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  214  loss  tensor(0.7217, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  215  loss  tensor(0.2644, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  216  loss  tensor(0.3868, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  217  loss  tensor(0.4161, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  218  loss  tensor(0.8695, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  219  loss  tensor(0.4542, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  220  loss  tensor(2.7748, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  221  loss  tensor(1.1792, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  222  loss  tensor(0.7833, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  223  loss  tensor(0.5355, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  224  loss  tensor(0.4494, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  225  loss  tensor(0.3677, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  226  loss  tensor(0.2990, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  227  loss  tensor(0.6714, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  228  loss  tensor(0.8374, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  229  loss  tensor(1.2135, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  230  loss  tensor(0.4045, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  231  loss  tensor(0.6255, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  232  loss  tensor(0.4556, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  233  loss  tensor(0.2561, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  234  loss  tensor(0.9080, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  235  loss  tensor(0.3649, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  236  loss  tensor(0.5054, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  237  loss  tensor(0.7118, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  238  loss  tensor(0.3073, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  239  loss  tensor(0.4969, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  240  loss  tensor(0.2155, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  241  loss  tensor(0.3728, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  242  loss  tensor(0.3420, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  243  loss  tensor(0.7980, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  244  loss  tensor(1.2522, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  245  loss  tensor(0.2316, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  246  loss  tensor(0.3513, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  247  loss  tensor(1.0410, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  248  loss  tensor(0.2403, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  249  loss  tensor(1.6939, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  250  loss  tensor(3.0356, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  251  loss  tensor(0.2487, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  252  loss  tensor(0.3992, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  253  loss  tensor(0.6762, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  254  loss  tensor(0.5156, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  255  loss  tensor(0.5321, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  256  loss  tensor(0.4014, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  257  loss  tensor(0.2801, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  258  loss  tensor(0.6241, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  259  loss  tensor(0.3312, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  260  loss  tensor(0.3742, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  261  loss  tensor(0.5214, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  262  loss  tensor(0.2896, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  263  loss  tensor(0.8788, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  264  loss  tensor(0.2412, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  265  loss  tensor(0.4836, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  266  loss  tensor(0.3988, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  267  loss  tensor(0.3584, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  268  loss  tensor(0.2847, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  269  loss  tensor(0.2055, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  270  loss  tensor(0.1997, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  271  loss  tensor(0.4137, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  272  loss  tensor(2.8071, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  273  loss  tensor(0.3699, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  274  loss  tensor(0.4488, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  275  loss  tensor(3.3346, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  276  loss  tensor(0.4812, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  277  loss  tensor(0.5637, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  278  loss  tensor(1.0432, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  279  loss  tensor(0.3199, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  280  loss  tensor(0.4861, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  281  loss  tensor(0.5339, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  282  loss  tensor(0.5606, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  283  loss  tensor(0.2968, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  284  loss  tensor(0.1466, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  285  loss  tensor(0.2276, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  286  loss  tensor(0.2647, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  287  loss  tensor(0.2247, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  288  loss  tensor(0.2751, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  289  loss  tensor(0.2823, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  290  loss  tensor(0.2474, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  291  loss  tensor(0.9380, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4  batch  292  loss  tensor(0.1735, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  293  loss  tensor(1.6392, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  294  loss  tensor(0.4085, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  295  loss  tensor(0.4573, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  296  loss  tensor(0.2404, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  297  loss  tensor(0.3590, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  298  loss  tensor(0.7515, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  299  loss  tensor(0.2861, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  300  loss  tensor(0.3455, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  301  loss  tensor(0.2135, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  302  loss  tensor(0.5192, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  303  loss  tensor(0.8534, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  304  loss  tensor(0.6384, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  305  loss  tensor(0.5103, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  306  loss  tensor(0.1830, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  307  loss  tensor(1.2405, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  308  loss  tensor(0.3047, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  309  loss  tensor(0.2649, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  310  loss  tensor(0.3893, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  311  loss  tensor(0.2898, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  312  loss  tensor(0.4579, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  313  loss  tensor(0.2212, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  314  loss  tensor(0.3628, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  315  loss  tensor(0.3832, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  316  loss  tensor(0.1979, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  317  loss  tensor(0.2713, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  318  loss  tensor(0.3779, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  319  loss  tensor(0.5796, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  320  loss  tensor(0.2401, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  321  loss  tensor(0.2877, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  322  loss  tensor(0.3277, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  323  loss  tensor(0.5699, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  324  loss  tensor(0.4302, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  325  loss  tensor(0.2223, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  326  loss  tensor(0.7538, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  327  loss  tensor(0.2066, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  328  loss  tensor(0.7388, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  329  loss  tensor(0.2336, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  330  loss  tensor(0.2907, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  331  loss  tensor(0.4482, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  332  loss  tensor(0.4070, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  333  loss  tensor(0.3162, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  334  loss  tensor(0.1821, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  335  loss  tensor(0.2813, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  336  loss  tensor(0.1878, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  337  loss  tensor(0.1789, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  338  loss  tensor(0.2055, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  339  loss  tensor(0.1716, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  340  loss  tensor(0.7395, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  341  loss  tensor(0.1576, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  342  loss  tensor(0.5730, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  343  loss  tensor(0.3715, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  344  loss  tensor(0.5135, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  345  loss  tensor(0.1823, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  346  loss  tensor(0.3523, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  347  loss  tensor(0.3386, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  348  loss  tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  349  loss  tensor(1.3900, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  350  loss  tensor(0.5533, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  351  loss  tensor(0.2212, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  352  loss  tensor(0.2712, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  353  loss  tensor(0.3696, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  354  loss  tensor(0.1794, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  355  loss  tensor(0.1902, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  356  loss  tensor(0.2404, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  357  loss  tensor(0.1888, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  358  loss  tensor(0.2431, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  359  loss  tensor(0.3195, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  360  loss  tensor(0.1854, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  361  loss  tensor(0.4141, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  362  loss  tensor(0.1945, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  363  loss  tensor(1.0230, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  364  loss  tensor(0.4246, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  365  loss  tensor(0.2537, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  366  loss  tensor(0.2315, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  367  loss  tensor(0.5131, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  368  loss  tensor(0.4301, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  369  loss  tensor(0.4060, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  370  loss  tensor(0.7788, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  371  loss  tensor(0.1936, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  372  loss  tensor(1.1926, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  373  loss  tensor(1.4530, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  374  loss  tensor(0.5825, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  375  loss  tensor(0.5076, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  376  loss  tensor(0.4810, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  377  loss  tensor(0.6601, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  378  loss  tensor(0.5183, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  379  loss  tensor(0.4955, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  380  loss  tensor(0.7682, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  381  loss  tensor(0.2563, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  382  loss  tensor(0.7378, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  383  loss  tensor(0.2699, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  384  loss  tensor(0.6497, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  385  loss  tensor(0.2059, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  386  loss  tensor(0.6869, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  387  loss  tensor(0.3833, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  388  loss  tensor(1.4010, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  389  loss  tensor(0.2461, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  390  loss  tensor(1.0174, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  391  loss  tensor(0.3001, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  392  loss  tensor(0.6246, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  393  loss  tensor(0.5711, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  394  loss  tensor(0.5788, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  395  loss  tensor(0.1888, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  396  loss  tensor(0.6603, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  397  loss  tensor(0.3713, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  398  loss  tensor(0.2524, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  399  loss  tensor(0.3492, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  400  loss  tensor(0.2460, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  401  loss  tensor(0.2446, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  402  loss  tensor(0.2512, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  403  loss  tensor(0.2602, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  404  loss  tensor(0.3680, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  405  loss  tensor(0.3581, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  406  loss  tensor(0.2132, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  407  loss  tensor(0.4450, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  408  loss  tensor(0.1874, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  409  loss  tensor(0.2649, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  410  loss  tensor(0.4359, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  411  loss  tensor(0.2035, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  412  loss  tensor(0.8952, grad_fn=<AddBackward0>)\n",
      "epoch  4  batch  413  loss  tensor(2.0066, grad_fn=<AddBackward0>)\n",
      "epoch [5/100], loss:243.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5  batch  0  loss  tensor(0.2278, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  1  loss  tensor(0.3896, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  2  loss  tensor(0.2342, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  3  loss  tensor(0.2922, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  4  loss  tensor(0.6800, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  5  loss  tensor(0.5895, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  6  loss  tensor(0.2563, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  7  loss  tensor(0.2266, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  8  loss  tensor(0.3878, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  9  loss  tensor(0.4162, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  10  loss  tensor(0.3302, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  11  loss  tensor(0.1952, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  12  loss  tensor(0.4111, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  13  loss  tensor(0.2916, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  14  loss  tensor(1.2121, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  15  loss  tensor(0.4023, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  16  loss  tensor(0.4674, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  17  loss  tensor(0.5692, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  18  loss  tensor(0.2762, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  19  loss  tensor(0.6280, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  20  loss  tensor(0.1430, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  21  loss  tensor(0.2588, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  22  loss  tensor(1.2228, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  23  loss  tensor(0.4123, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  24  loss  tensor(0.3427, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  25  loss  tensor(0.1486, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  26  loss  tensor(1.1876, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  27  loss  tensor(0.2332, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  28  loss  tensor(0.2129, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  29  loss  tensor(0.2470, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  30  loss  tensor(0.4039, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  31  loss  tensor(0.1242, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  32  loss  tensor(1.7634, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  33  loss  tensor(1.5420, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  34  loss  tensor(0.1706, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  35  loss  tensor(0.1301, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  36  loss  tensor(0.6431, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  37  loss  tensor(0.2409, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  38  loss  tensor(0.9028, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  39  loss  tensor(0.2107, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  40  loss  tensor(0.2212, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  41  loss  tensor(0.9512, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  42  loss  tensor(0.2575, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  43  loss  tensor(0.6880, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  44  loss  tensor(0.4077, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  45  loss  tensor(0.3437, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  46  loss  tensor(0.2829, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  47  loss  tensor(0.2169, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  48  loss  tensor(0.2225, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  49  loss  tensor(0.3202, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  50  loss  tensor(0.2454, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  51  loss  tensor(0.2837, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  52  loss  tensor(0.7378, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  53  loss  tensor(0.2005, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  54  loss  tensor(0.6351, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  55  loss  tensor(0.7104, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  56  loss  tensor(0.3097, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  57  loss  tensor(0.5306, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  58  loss  tensor(0.1150, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  59  loss  tensor(0.1795, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  60  loss  tensor(0.1852, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  61  loss  tensor(0.9902, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  62  loss  tensor(0.9029, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  63  loss  tensor(0.2558, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  64  loss  tensor(0.3502, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  65  loss  tensor(0.1822, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  66  loss  tensor(0.1843, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  67  loss  tensor(1.7603, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  68  loss  tensor(0.6575, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  69  loss  tensor(0.3909, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  70  loss  tensor(0.3025, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  71  loss  tensor(0.2618, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  72  loss  tensor(1.3589, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  73  loss  tensor(0.9766, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  74  loss  tensor(1.4432, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  75  loss  tensor(0.6810, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  76  loss  tensor(0.6788, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  77  loss  tensor(0.1713, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  78  loss  tensor(0.2679, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  79  loss  tensor(0.2282, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  80  loss  tensor(0.8713, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  81  loss  tensor(0.2629, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  82  loss  tensor(0.2198, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  83  loss  tensor(0.3727, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  84  loss  tensor(0.1480, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  85  loss  tensor(0.2913, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  86  loss  tensor(0.1902, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  87  loss  tensor(0.2705, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  88  loss  tensor(0.1843, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  89  loss  tensor(0.1301, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  90  loss  tensor(0.3097, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  91  loss  tensor(0.1749, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  92  loss  tensor(0.2613, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  93  loss  tensor(0.2371, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  94  loss  tensor(0.2208, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  95  loss  tensor(0.2567, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  96  loss  tensor(0.1991, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  97  loss  tensor(0.2847, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  98  loss  tensor(0.6318, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  99  loss  tensor(0.5372, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  100  loss  tensor(0.2775, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  101  loss  tensor(0.2512, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  102  loss  tensor(0.1724, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  103  loss  tensor(0.2001, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  104  loss  tensor(0.2143, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  105  loss  tensor(0.7998, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  106  loss  tensor(0.2096, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  107  loss  tensor(0.1648, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  108  loss  tensor(0.3078, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  109  loss  tensor(0.3089, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  110  loss  tensor(0.3135, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  111  loss  tensor(0.3838, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  112  loss  tensor(0.2301, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  113  loss  tensor(0.2128, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  114  loss  tensor(0.2369, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  115  loss  tensor(0.5101, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  116  loss  tensor(0.2380, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  117  loss  tensor(0.1755, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  118  loss  tensor(0.1266, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  119  loss  tensor(0.1673, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  120  loss  tensor(0.3871, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  121  loss  tensor(0.2910, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  122  loss  tensor(0.3459, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  123  loss  tensor(0.2509, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5  batch  124  loss  tensor(0.1733, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  125  loss  tensor(0.1272, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  126  loss  tensor(0.5098, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  127  loss  tensor(0.2509, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  128  loss  tensor(0.1222, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  129  loss  tensor(0.3296, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  130  loss  tensor(0.2417, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  131  loss  tensor(0.1446, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  132  loss  tensor(0.1684, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  133  loss  tensor(0.1925, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  134  loss  tensor(0.6077, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  135  loss  tensor(1.7437, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  136  loss  tensor(0.2070, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  137  loss  tensor(0.2272, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  138  loss  tensor(0.6179, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  139  loss  tensor(0.1367, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  140  loss  tensor(0.4900, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  141  loss  tensor(0.5531, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  142  loss  tensor(0.2605, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  143  loss  tensor(0.1601, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  144  loss  tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  145  loss  tensor(0.2753, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  146  loss  tensor(1.0117, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  147  loss  tensor(0.1834, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  148  loss  tensor(0.2302, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  149  loss  tensor(0.2670, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  150  loss  tensor(0.2569, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  151  loss  tensor(0.2791, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  152  loss  tensor(0.6058, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  153  loss  tensor(0.4347, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  154  loss  tensor(0.1753, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  155  loss  tensor(0.2207, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  156  loss  tensor(0.3270, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  157  loss  tensor(0.2017, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  158  loss  tensor(0.2253, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  159  loss  tensor(0.2591, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  160  loss  tensor(0.2505, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  161  loss  tensor(0.2952, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  162  loss  tensor(2.6823, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  163  loss  tensor(0.6345, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  164  loss  tensor(0.1298, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  165  loss  tensor(0.1686, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  166  loss  tensor(0.4015, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  167  loss  tensor(0.7375, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  168  loss  tensor(0.1601, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  169  loss  tensor(0.4423, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  170  loss  tensor(0.1739, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  171  loss  tensor(0.2386, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  172  loss  tensor(0.3586, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  173  loss  tensor(0.1601, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  174  loss  tensor(0.5295, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  175  loss  tensor(0.1219, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  176  loss  tensor(0.5600, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  177  loss  tensor(1.0299, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  178  loss  tensor(0.2554, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  179  loss  tensor(0.2564, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  180  loss  tensor(0.1637, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  181  loss  tensor(0.1601, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  182  loss  tensor(0.3256, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  183  loss  tensor(3.7879, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  184  loss  tensor(1.3046, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  185  loss  tensor(0.1359, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  186  loss  tensor(0.1468, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  187  loss  tensor(0.3043, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  188  loss  tensor(0.1260, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  189  loss  tensor(0.1458, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  190  loss  tensor(0.2525, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  191  loss  tensor(0.1748, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  192  loss  tensor(0.1395, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  193  loss  tensor(0.4044, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  194  loss  tensor(1.5396, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  195  loss  tensor(0.7248, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  196  loss  tensor(1.3832, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  197  loss  tensor(0.1801, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  198  loss  tensor(0.3061, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  199  loss  tensor(0.1817, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  200  loss  tensor(0.2881, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  201  loss  tensor(0.1613, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  202  loss  tensor(0.2451, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  203  loss  tensor(0.2363, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  204  loss  tensor(0.4165, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  205  loss  tensor(0.3637, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  206  loss  tensor(0.2877, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  207  loss  tensor(0.2125, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  208  loss  tensor(0.2526, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  209  loss  tensor(0.1933, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  210  loss  tensor(0.4952, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  211  loss  tensor(0.1808, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  212  loss  tensor(0.1388, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  213  loss  tensor(0.1721, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  214  loss  tensor(0.1980, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  215  loss  tensor(0.1621, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  216  loss  tensor(0.1696, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  217  loss  tensor(0.3281, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  218  loss  tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  219  loss  tensor(1.0781, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  220  loss  tensor(0.2159, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  221  loss  tensor(0.2484, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  222  loss  tensor(0.2284, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  223  loss  tensor(0.1485, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  224  loss  tensor(0.2142, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  225  loss  tensor(0.1392, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  226  loss  tensor(0.1840, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  227  loss  tensor(0.2707, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  228  loss  tensor(0.7286, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  229  loss  tensor(0.1088, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  230  loss  tensor(0.2642, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  231  loss  tensor(0.2121, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  232  loss  tensor(0.2028, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  233  loss  tensor(0.3031, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  234  loss  tensor(1.1318, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  235  loss  tensor(0.7377, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  236  loss  tensor(0.1195, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  237  loss  tensor(0.1248, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  238  loss  tensor(0.4139, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  239  loss  tensor(0.5475, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  240  loss  tensor(0.4742, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  241  loss  tensor(0.1349, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  242  loss  tensor(0.4725, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  243  loss  tensor(0.1901, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  244  loss  tensor(0.1975, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  245  loss  tensor(0.3793, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  246  loss  tensor(0.1500, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5  batch  247  loss  tensor(0.1315, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  248  loss  tensor(0.2119, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  249  loss  tensor(0.9163, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  250  loss  tensor(0.2035, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  251  loss  tensor(0.2402, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  252  loss  tensor(0.4799, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  253  loss  tensor(0.2905, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  254  loss  tensor(0.3142, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  255  loss  tensor(0.2207, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  256  loss  tensor(1.3470, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  257  loss  tensor(0.1589, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  258  loss  tensor(0.1538, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  259  loss  tensor(0.1203, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  260  loss  tensor(0.1847, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  261  loss  tensor(0.8347, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  262  loss  tensor(0.3364, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  263  loss  tensor(0.1781, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  264  loss  tensor(1.1306, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  265  loss  tensor(0.1881, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  266  loss  tensor(0.1867, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  267  loss  tensor(0.1417, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  268  loss  tensor(0.1734, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  269  loss  tensor(0.1652, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  270  loss  tensor(0.1335, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  271  loss  tensor(0.1681, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  272  loss  tensor(0.1698, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  273  loss  tensor(0.3036, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  274  loss  tensor(0.1812, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  275  loss  tensor(0.4068, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  276  loss  tensor(0.1558, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  277  loss  tensor(0.2399, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  278  loss  tensor(0.1723, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  279  loss  tensor(0.1739, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  280  loss  tensor(0.2281, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  281  loss  tensor(1.7148, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  282  loss  tensor(0.1870, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  283  loss  tensor(0.1286, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  284  loss  tensor(0.2756, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  285  loss  tensor(0.1298, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  286  loss  tensor(0.4328, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  287  loss  tensor(0.1982, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  288  loss  tensor(0.1322, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  289  loss  tensor(0.1568, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  290  loss  tensor(0.1862, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  291  loss  tensor(0.2134, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  292  loss  tensor(0.6143, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  293  loss  tensor(0.1435, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  294  loss  tensor(0.3740, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  295  loss  tensor(0.1917, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  296  loss  tensor(0.1437, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  297  loss  tensor(0.2371, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  298  loss  tensor(0.3472, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  299  loss  tensor(0.2220, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  300  loss  tensor(0.1592, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  301  loss  tensor(0.1355, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  302  loss  tensor(0.1138, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  303  loss  tensor(0.1901, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  304  loss  tensor(0.3083, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  305  loss  tensor(0.2842, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  306  loss  tensor(0.6182, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  307  loss  tensor(1.0586, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  308  loss  tensor(0.2647, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  309  loss  tensor(0.3087, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  310  loss  tensor(0.1493, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  311  loss  tensor(0.1510, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  312  loss  tensor(0.2468, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  313  loss  tensor(0.2408, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  314  loss  tensor(0.2086, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  315  loss  tensor(0.5724, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  316  loss  tensor(0.2672, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  317  loss  tensor(0.4038, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  318  loss  tensor(0.2436, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  319  loss  tensor(0.1259, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  320  loss  tensor(0.2362, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  321  loss  tensor(0.1156, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  322  loss  tensor(0.1809, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  323  loss  tensor(0.1920, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  324  loss  tensor(0.1740, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  325  loss  tensor(0.7596, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  326  loss  tensor(0.3553, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  327  loss  tensor(0.1656, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  328  loss  tensor(0.2124, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  329  loss  tensor(0.5550, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  330  loss  tensor(0.3707, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  331  loss  tensor(0.2066, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  332  loss  tensor(0.3947, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  333  loss  tensor(0.2724, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  334  loss  tensor(0.1912, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  335  loss  tensor(0.3202, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  336  loss  tensor(0.2734, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  337  loss  tensor(0.4921, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  338  loss  tensor(0.2290, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  339  loss  tensor(1.2264, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  340  loss  tensor(0.2099, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  341  loss  tensor(0.1720, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  342  loss  tensor(0.3478, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  343  loss  tensor(5.6929, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  344  loss  tensor(0.4626, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  345  loss  tensor(5.8699, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  346  loss  tensor(0.1128, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  347  loss  tensor(1.1037, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  348  loss  tensor(0.3162, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  349  loss  tensor(0.2763, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  350  loss  tensor(0.7417, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  351  loss  tensor(0.4274, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  352  loss  tensor(1.8332, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  353  loss  tensor(0.4706, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  354  loss  tensor(1.3453, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  355  loss  tensor(0.5938, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  356  loss  tensor(0.2936, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  357  loss  tensor(0.2553, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  358  loss  tensor(0.1098, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  359  loss  tensor(0.2568, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  360  loss  tensor(0.3123, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  361  loss  tensor(0.2019, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  362  loss  tensor(0.2073, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  363  loss  tensor(0.2995, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  364  loss  tensor(0.1469, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  365  loss  tensor(0.2053, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  366  loss  tensor(0.2225, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  367  loss  tensor(0.1453, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  368  loss  tensor(0.4564, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  369  loss  tensor(0.1371, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5  batch  370  loss  tensor(0.4758, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  371  loss  tensor(0.3479, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  372  loss  tensor(0.2120, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  373  loss  tensor(0.1524, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  374  loss  tensor(0.2942, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  375  loss  tensor(0.1735, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  376  loss  tensor(0.5558, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  377  loss  tensor(0.8449, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  378  loss  tensor(0.2370, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  379  loss  tensor(0.2633, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  380  loss  tensor(0.2196, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  381  loss  tensor(0.3685, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  382  loss  tensor(0.3155, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  383  loss  tensor(0.2023, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  384  loss  tensor(0.1259, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  385  loss  tensor(0.2703, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  386  loss  tensor(0.1953, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  387  loss  tensor(0.1869, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  388  loss  tensor(0.1330, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  389  loss  tensor(0.1452, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  390  loss  tensor(0.2289, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  391  loss  tensor(0.1764, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  392  loss  tensor(0.1689, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  393  loss  tensor(0.1766, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  394  loss  tensor(0.7006, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  395  loss  tensor(1.7290, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  396  loss  tensor(0.1832, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  397  loss  tensor(0.2603, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  398  loss  tensor(0.2687, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  399  loss  tensor(0.2084, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  400  loss  tensor(0.1496, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  401  loss  tensor(0.5505, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  402  loss  tensor(0.1132, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  403  loss  tensor(0.1346, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  404  loss  tensor(0.1650, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  405  loss  tensor(0.1392, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  406  loss  tensor(0.1987, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  407  loss  tensor(0.1977, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  408  loss  tensor(0.1710, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  409  loss  tensor(0.1319, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  410  loss  tensor(0.3743, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  411  loss  tensor(0.2707, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  412  loss  tensor(0.5775, grad_fn=<AddBackward0>)\n",
      "epoch  5  batch  413  loss  tensor(0.6191, grad_fn=<AddBackward0>)\n",
      "epoch [6/100], loss:166.4747\n",
      "epoch  6  batch  0  loss  tensor(0.1664, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  1  loss  tensor(1.0630, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  2  loss  tensor(0.1793, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  3  loss  tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  4  loss  tensor(0.2153, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  5  loss  tensor(0.1486, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  6  loss  tensor(0.1186, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  7  loss  tensor(0.1260, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  8  loss  tensor(0.2424, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  9  loss  tensor(0.3800, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  10  loss  tensor(0.1408, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  11  loss  tensor(0.1440, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  12  loss  tensor(0.4796, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  13  loss  tensor(1.1210, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  14  loss  tensor(0.1661, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  15  loss  tensor(0.1547, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  16  loss  tensor(0.2290, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  17  loss  tensor(0.2277, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  18  loss  tensor(0.1271, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  19  loss  tensor(0.3293, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  20  loss  tensor(0.8752, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  21  loss  tensor(0.1236, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  22  loss  tensor(0.1967, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  23  loss  tensor(0.2322, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  24  loss  tensor(0.2314, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  25  loss  tensor(0.1577, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  26  loss  tensor(0.1001, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  27  loss  tensor(0.1837, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  28  loss  tensor(0.7142, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  29  loss  tensor(0.4862, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  30  loss  tensor(0.1265, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  31  loss  tensor(0.1362, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  32  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  33  loss  tensor(0.2361, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  34  loss  tensor(0.1178, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  35  loss  tensor(0.2457, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  36  loss  tensor(0.1194, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  37  loss  tensor(0.2058, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  38  loss  tensor(0.2111, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  39  loss  tensor(0.3261, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  40  loss  tensor(0.1108, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  41  loss  tensor(0.2245, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  42  loss  tensor(0.1247, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  43  loss  tensor(0.1178, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  44  loss  tensor(0.4035, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  45  loss  tensor(0.1970, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  46  loss  tensor(0.3045, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  47  loss  tensor(0.1956, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  48  loss  tensor(0.1205, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  49  loss  tensor(0.4239, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  50  loss  tensor(0.1264, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  51  loss  tensor(0.9902, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  52  loss  tensor(0.1560, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  53  loss  tensor(0.2288, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  54  loss  tensor(0.1458, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  55  loss  tensor(0.2729, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  56  loss  tensor(0.1300, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  57  loss  tensor(0.1547, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  58  loss  tensor(0.2005, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  59  loss  tensor(0.1495, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  60  loss  tensor(0.1466, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  61  loss  tensor(0.1748, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  62  loss  tensor(0.1395, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  63  loss  tensor(0.1716, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  64  loss  tensor(0.6554, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  65  loss  tensor(0.1398, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  66  loss  tensor(0.1258, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  67  loss  tensor(0.2014, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  68  loss  tensor(0.2557, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  69  loss  tensor(0.1975, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  70  loss  tensor(0.2334, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  71  loss  tensor(0.1497, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  72  loss  tensor(0.3422, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  73  loss  tensor(0.1152, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  74  loss  tensor(0.4654, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  75  loss  tensor(0.5695, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  76  loss  tensor(0.2041, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  77  loss  tensor(0.2614, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  78  loss  tensor(0.2246, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  79  loss  tensor(0.2416, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6  batch  80  loss  tensor(0.9015, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  81  loss  tensor(0.3544, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  82  loss  tensor(0.2131, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  83  loss  tensor(0.2153, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  84  loss  tensor(0.1364, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  85  loss  tensor(0.2517, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  86  loss  tensor(0.2646, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  87  loss  tensor(0.1248, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  88  loss  tensor(0.1828, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  89  loss  tensor(0.4556, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  90  loss  tensor(0.3080, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  91  loss  tensor(0.1299, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  92  loss  tensor(0.1594, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  93  loss  tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  94  loss  tensor(0.1970, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  95  loss  tensor(0.2786, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  96  loss  tensor(0.2726, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  97  loss  tensor(0.1310, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  98  loss  tensor(0.1621, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  99  loss  tensor(0.1111, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  100  loss  tensor(0.1690, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  101  loss  tensor(0.1926, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  102  loss  tensor(0.1596, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  103  loss  tensor(0.5246, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  104  loss  tensor(0.1302, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  105  loss  tensor(0.1264, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  106  loss  tensor(0.1583, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  107  loss  tensor(0.2141, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  108  loss  tensor(0.1534, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  109  loss  tensor(0.5604, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  110  loss  tensor(0.1062, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  111  loss  tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  112  loss  tensor(0.3084, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  113  loss  tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  114  loss  tensor(0.1729, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  115  loss  tensor(0.2540, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  116  loss  tensor(0.4993, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  117  loss  tensor(0.2096, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  118  loss  tensor(0.2551, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  119  loss  tensor(0.9767, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  120  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  121  loss  tensor(0.1469, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  122  loss  tensor(0.1437, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  123  loss  tensor(0.1843, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  124  loss  tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  125  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  126  loss  tensor(0.2086, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  127  loss  tensor(0.1669, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  128  loss  tensor(0.1186, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  129  loss  tensor(1.1420, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  130  loss  tensor(0.5580, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  131  loss  tensor(0.1226, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  132  loss  tensor(0.1573, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  133  loss  tensor(0.2317, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  134  loss  tensor(0.1756, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  135  loss  tensor(0.3766, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  136  loss  tensor(0.1432, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  137  loss  tensor(0.2768, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  138  loss  tensor(0.2512, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  139  loss  tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  140  loss  tensor(0.1529, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  141  loss  tensor(0.1328, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  142  loss  tensor(0.1140, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  143  loss  tensor(0.2104, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  144  loss  tensor(0.1306, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  145  loss  tensor(0.1735, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  146  loss  tensor(0.2072, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  147  loss  tensor(0.2370, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  148  loss  tensor(0.1253, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  149  loss  tensor(0.1718, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  150  loss  tensor(0.1618, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  151  loss  tensor(0.1397, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  152  loss  tensor(0.2656, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  153  loss  tensor(0.1640, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  154  loss  tensor(0.1622, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  155  loss  tensor(0.2280, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  156  loss  tensor(0.1156, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  157  loss  tensor(0.2587, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  158  loss  tensor(0.1692, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  159  loss  tensor(0.2713, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  160  loss  tensor(0.1962, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  161  loss  tensor(0.2188, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  162  loss  tensor(0.1210, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  163  loss  tensor(0.2248, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  164  loss  tensor(0.1505, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  165  loss  tensor(0.4659, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  166  loss  tensor(0.2070, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  167  loss  tensor(0.2087, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  168  loss  tensor(0.2192, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  169  loss  tensor(0.1208, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  170  loss  tensor(0.1811, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  171  loss  tensor(0.1882, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  172  loss  tensor(0.1841, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  173  loss  tensor(0.1866, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  174  loss  tensor(0.1801, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  175  loss  tensor(0.1409, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  176  loss  tensor(0.1274, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  177  loss  tensor(0.1170, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  178  loss  tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  179  loss  tensor(0.2624, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  180  loss  tensor(0.1068, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  181  loss  tensor(1.2369, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  182  loss  tensor(0.1234, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  183  loss  tensor(0.1245, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  184  loss  tensor(0.2066, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  185  loss  tensor(0.1081, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  186  loss  tensor(0.1953, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  187  loss  tensor(0.1419, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  188  loss  tensor(0.3464, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  189  loss  tensor(0.2276, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  190  loss  tensor(0.2364, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  191  loss  tensor(0.2948, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  192  loss  tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  193  loss  tensor(0.1734, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  194  loss  tensor(0.4496, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  195  loss  tensor(0.1098, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  196  loss  tensor(0.1101, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  197  loss  tensor(0.1084, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  198  loss  tensor(0.1222, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  199  loss  tensor(0.1855, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  200  loss  tensor(0.9145, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  201  loss  tensor(0.1352, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  202  loss  tensor(0.1209, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6  batch  203  loss  tensor(0.1111, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  204  loss  tensor(0.3092, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  205  loss  tensor(0.2557, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  206  loss  tensor(0.1736, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  207  loss  tensor(0.2578, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  208  loss  tensor(0.1121, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  209  loss  tensor(0.2302, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  210  loss  tensor(0.1616, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  211  loss  tensor(0.1774, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  212  loss  tensor(0.1569, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  213  loss  tensor(0.1321, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  214  loss  tensor(0.2129, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  215  loss  tensor(0.1982, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  216  loss  tensor(0.1977, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  217  loss  tensor(0.1218, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  218  loss  tensor(0.6447, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  219  loss  tensor(0.4442, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  220  loss  tensor(0.1709, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  221  loss  tensor(0.1474, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  222  loss  tensor(0.1230, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  223  loss  tensor(0.1765, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  224  loss  tensor(0.1345, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  225  loss  tensor(0.2210, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  226  loss  tensor(0.1952, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  227  loss  tensor(0.1452, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  228  loss  tensor(0.1339, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  229  loss  tensor(0.3282, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  230  loss  tensor(0.1128, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  231  loss  tensor(0.1663, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  232  loss  tensor(0.1219, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  233  loss  tensor(0.2585, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  234  loss  tensor(0.1338, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  235  loss  tensor(1.0060, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  236  loss  tensor(0.1592, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  237  loss  tensor(0.2292, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  238  loss  tensor(0.1293, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  239  loss  tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  240  loss  tensor(0.3483, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  241  loss  tensor(1.3518, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  242  loss  tensor(0.1189, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  243  loss  tensor(0.1550, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  244  loss  tensor(0.1348, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  245  loss  tensor(0.1655, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  246  loss  tensor(0.1237, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  247  loss  tensor(0.2337, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  248  loss  tensor(0.1641, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  249  loss  tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  250  loss  tensor(0.1359, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  251  loss  tensor(0.3138, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  252  loss  tensor(0.1431, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  253  loss  tensor(0.1722, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  254  loss  tensor(0.1594, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  255  loss  tensor(0.1522, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  256  loss  tensor(0.1826, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  257  loss  tensor(0.3055, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  258  loss  tensor(0.1808, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  259  loss  tensor(0.1886, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  260  loss  tensor(0.1260, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  261  loss  tensor(0.1914, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  262  loss  tensor(0.3930, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  263  loss  tensor(0.1579, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  264  loss  tensor(0.1212, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  265  loss  tensor(0.1232, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  266  loss  tensor(1.0954, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  267  loss  tensor(0.1471, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  268  loss  tensor(0.1167, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  269  loss  tensor(0.1088, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  270  loss  tensor(0.1121, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  271  loss  tensor(0.1003, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  272  loss  tensor(0.1211, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  273  loss  tensor(1.4909, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  274  loss  tensor(0.1247, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  275  loss  tensor(0.1194, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  276  loss  tensor(0.1701, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  277  loss  tensor(0.1070, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  278  loss  tensor(0.1256, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  279  loss  tensor(0.2809, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  280  loss  tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  281  loss  tensor(0.1606, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  282  loss  tensor(0.1247, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  283  loss  tensor(0.1862, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  284  loss  tensor(0.1356, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  285  loss  tensor(0.2430, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  286  loss  tensor(0.1865, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  287  loss  tensor(0.1065, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  288  loss  tensor(0.1251, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  289  loss  tensor(0.9148, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  290  loss  tensor(0.1144, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  291  loss  tensor(0.1394, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  292  loss  tensor(0.1404, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  293  loss  tensor(0.1792, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  294  loss  tensor(0.1032, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  295  loss  tensor(0.1283, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  296  loss  tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  297  loss  tensor(0.1967, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  298  loss  tensor(0.1454, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  299  loss  tensor(0.4711, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  300  loss  tensor(0.2150, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  301  loss  tensor(0.1884, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  302  loss  tensor(0.3183, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  303  loss  tensor(0.2253, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  304  loss  tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  305  loss  tensor(0.1352, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  306  loss  tensor(0.1100, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  307  loss  tensor(0.1215, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  308  loss  tensor(0.1528, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  309  loss  tensor(0.2654, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  310  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  311  loss  tensor(0.1833, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  312  loss  tensor(0.1962, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  313  loss  tensor(0.1656, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  314  loss  tensor(0.1796, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  315  loss  tensor(0.1355, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  316  loss  tensor(0.1209, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  317  loss  tensor(0.1861, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  318  loss  tensor(0.1522, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  319  loss  tensor(0.1715, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  320  loss  tensor(0.1087, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  321  loss  tensor(0.1161, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  322  loss  tensor(0.1362, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  323  loss  tensor(0.4292, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  324  loss  tensor(0.1173, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  325  loss  tensor(0.1354, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6  batch  326  loss  tensor(0.1155, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  327  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  328  loss  tensor(0.2435, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  329  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  330  loss  tensor(0.2118, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  331  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  332  loss  tensor(0.2157, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  333  loss  tensor(0.2332, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  334  loss  tensor(0.1454, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  335  loss  tensor(0.1011, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  336  loss  tensor(0.1165, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  337  loss  tensor(0.1906, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  338  loss  tensor(0.5054, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  339  loss  tensor(0.1261, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  340  loss  tensor(0.1327, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  341  loss  tensor(0.1496, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  342  loss  tensor(0.1828, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  343  loss  tensor(0.1083, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  344  loss  tensor(0.1231, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  345  loss  tensor(0.1027, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  346  loss  tensor(0.1381, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  347  loss  tensor(0.1358, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  348  loss  tensor(0.1184, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  349  loss  tensor(0.7414, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  350  loss  tensor(0.1187, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  351  loss  tensor(0.1793, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  352  loss  tensor(0.1220, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  353  loss  tensor(0.1407, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  354  loss  tensor(0.6585, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  355  loss  tensor(0.2624, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  356  loss  tensor(0.2557, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  357  loss  tensor(1.0792, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  358  loss  tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  359  loss  tensor(0.1092, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  360  loss  tensor(0.1895, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  361  loss  tensor(0.2039, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  362  loss  tensor(0.1495, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  363  loss  tensor(0.5535, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  364  loss  tensor(0.1717, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  365  loss  tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  366  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  367  loss  tensor(0.1194, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  368  loss  tensor(0.1351, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  369  loss  tensor(0.1260, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  370  loss  tensor(0.3344, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  371  loss  tensor(0.2144, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  372  loss  tensor(0.1252, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  373  loss  tensor(0.1101, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  374  loss  tensor(0.2417, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  375  loss  tensor(0.1244, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  376  loss  tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  377  loss  tensor(0.1342, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  378  loss  tensor(0.2208, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  379  loss  tensor(0.2154, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  380  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  381  loss  tensor(0.1409, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  382  loss  tensor(0.1003, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  383  loss  tensor(0.1533, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  384  loss  tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  385  loss  tensor(0.1200, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  386  loss  tensor(0.1270, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  387  loss  tensor(0.1973, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  388  loss  tensor(0.1828, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  389  loss  tensor(0.1701, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  390  loss  tensor(0.1351, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  391  loss  tensor(0.2649, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  392  loss  tensor(0.1713, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  393  loss  tensor(1.9867, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  394  loss  tensor(0.1755, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  395  loss  tensor(0.2188, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  396  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  397  loss  tensor(0.1086, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  398  loss  tensor(0.1173, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  399  loss  tensor(0.2133, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  400  loss  tensor(0.1198, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  401  loss  tensor(0.5967, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  402  loss  tensor(0.1199, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  403  loss  tensor(0.1322, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  404  loss  tensor(0.1481, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  405  loss  tensor(0.3046, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  406  loss  tensor(0.1259, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  407  loss  tensor(0.1621, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  408  loss  tensor(0.8608, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  409  loss  tensor(0.1396, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  410  loss  tensor(0.1909, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  411  loss  tensor(0.1343, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  412  loss  tensor(0.1737, grad_fn=<AddBackward0>)\n",
      "epoch  6  batch  413  loss  tensor(1.0794, grad_fn=<AddBackward0>)\n",
      "epoch [7/100], loss:96.4491\n",
      "epoch  7  batch  0  loss  tensor(0.1329, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  1  loss  tensor(0.1641, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  2  loss  tensor(0.1130, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  3  loss  tensor(0.1157, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  4  loss  tensor(0.1507, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  5  loss  tensor(0.3675, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  6  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  7  loss  tensor(0.1836, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  8  loss  tensor(0.2940, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  9  loss  tensor(0.1653, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  10  loss  tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  11  loss  tensor(0.3204, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  12  loss  tensor(0.1731, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  13  loss  tensor(0.1304, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  14  loss  tensor(0.1449, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  15  loss  tensor(0.1157, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  16  loss  tensor(0.3614, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  17  loss  tensor(0.1653, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  18  loss  tensor(0.1889, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  19  loss  tensor(0.1726, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  20  loss  tensor(0.3136, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  21  loss  tensor(0.1893, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  22  loss  tensor(0.1178, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  23  loss  tensor(0.1310, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  24  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  25  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  26  loss  tensor(0.1410, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  27  loss  tensor(0.1176, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  28  loss  tensor(0.1370, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  29  loss  tensor(0.1925, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  30  loss  tensor(0.3272, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  31  loss  tensor(0.1049, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  32  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  33  loss  tensor(0.1666, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  34  loss  tensor(0.1845, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  7  batch  35  loss  tensor(0.1199, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  36  loss  tensor(0.1867, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  37  loss  tensor(0.1544, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  38  loss  tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  39  loss  tensor(0.1546, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  40  loss  tensor(0.1594, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  41  loss  tensor(0.1261, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  42  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  43  loss  tensor(0.2976, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  44  loss  tensor(0.1368, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  45  loss  tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  46  loss  tensor(0.1358, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  47  loss  tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  48  loss  tensor(0.3072, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  49  loss  tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  50  loss  tensor(0.8829, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  51  loss  tensor(0.2051, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  52  loss  tensor(0.1051, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  53  loss  tensor(0.1163, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  54  loss  tensor(0.1212, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  55  loss  tensor(0.1267, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  56  loss  tensor(0.1300, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  57  loss  tensor(0.1341, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  58  loss  tensor(0.1294, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  59  loss  tensor(0.1413, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  60  loss  tensor(0.1683, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  61  loss  tensor(1.0313, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  62  loss  tensor(0.1825, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  63  loss  tensor(0.1434, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  64  loss  tensor(0.1658, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  65  loss  tensor(0.1984, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  66  loss  tensor(0.1132, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  67  loss  tensor(0.1222, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  68  loss  tensor(0.1530, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  69  loss  tensor(0.1119, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  70  loss  tensor(0.2707, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  71  loss  tensor(0.1832, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  72  loss  tensor(0.6749, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  73  loss  tensor(0.1282, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  74  loss  tensor(0.1329, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  75  loss  tensor(0.1216, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  76  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  77  loss  tensor(0.1173, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  78  loss  tensor(0.8471, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  79  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  80  loss  tensor(0.1100, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  81  loss  tensor(0.4469, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  82  loss  tensor(0.2823, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  83  loss  tensor(0.1541, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  84  loss  tensor(0.1170, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  85  loss  tensor(4.9755, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  86  loss  tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  87  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  88  loss  tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  89  loss  tensor(0.3716, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  90  loss  tensor(0.3083, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  91  loss  tensor(0.4231, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  92  loss  tensor(0.1939, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  93  loss  tensor(0.3144, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  94  loss  tensor(0.9834, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  95  loss  tensor(0.2151, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  96  loss  tensor(0.1541, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  97  loss  tensor(0.2775, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  98  loss  tensor(0.1616, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  99  loss  tensor(0.1520, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  100  loss  tensor(0.2377, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  101  loss  tensor(0.1971, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  102  loss  tensor(0.1688, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  103  loss  tensor(0.1033, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  104  loss  tensor(0.1584, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  105  loss  tensor(0.3053, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  106  loss  tensor(0.1743, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  107  loss  tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  108  loss  tensor(0.2160, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  109  loss  tensor(0.3200, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  110  loss  tensor(0.3036, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  111  loss  tensor(0.1222, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  112  loss  tensor(0.2486, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  113  loss  tensor(0.9468, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  114  loss  tensor(0.1429, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  115  loss  tensor(0.2316, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  116  loss  tensor(0.2706, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  117  loss  tensor(0.1351, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  118  loss  tensor(0.5588, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  119  loss  tensor(0.1477, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  120  loss  tensor(0.1123, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  121  loss  tensor(0.4649, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  122  loss  tensor(0.1262, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  123  loss  tensor(0.1127, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  124  loss  tensor(0.1320, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  125  loss  tensor(0.6540, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  126  loss  tensor(0.1100, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  127  loss  tensor(0.1315, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  128  loss  tensor(0.1497, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  129  loss  tensor(0.1090, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  130  loss  tensor(0.7675, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  131  loss  tensor(0.1795, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  132  loss  tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  133  loss  tensor(0.1355, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  134  loss  tensor(0.1733, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  135  loss  tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  136  loss  tensor(0.5229, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  137  loss  tensor(0.1083, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  138  loss  tensor(0.1494, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  139  loss  tensor(0.1277, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  140  loss  tensor(0.1181, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  141  loss  tensor(0.3635, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  142  loss  tensor(0.1929, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  143  loss  tensor(0.1485, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  144  loss  tensor(0.1397, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  145  loss  tensor(0.2541, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  146  loss  tensor(0.2339, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  147  loss  tensor(0.1155, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  148  loss  tensor(0.2767, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  149  loss  tensor(0.2408, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  150  loss  tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  151  loss  tensor(0.1324, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  152  loss  tensor(0.1144, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  153  loss  tensor(0.1694, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  154  loss  tensor(0.1884, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  155  loss  tensor(0.1703, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  156  loss  tensor(0.2150, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  157  loss  tensor(0.1429, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  158  loss  tensor(0.1149, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  7  batch  159  loss  tensor(0.1059, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  160  loss  tensor(0.1670, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  161  loss  tensor(0.2088, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  162  loss  tensor(0.4596, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  163  loss  tensor(0.1362, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  164  loss  tensor(0.1635, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  165  loss  tensor(0.1489, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  166  loss  tensor(0.3412, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  167  loss  tensor(0.1723, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  168  loss  tensor(0.1564, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  169  loss  tensor(0.2719, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  170  loss  tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  171  loss  tensor(0.1085, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  172  loss  tensor(0.4541, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  173  loss  tensor(0.2010, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  174  loss  tensor(0.1852, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  175  loss  tensor(0.1610, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  176  loss  tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  177  loss  tensor(0.1333, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  178  loss  tensor(0.2138, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  179  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  180  loss  tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  181  loss  tensor(0.3858, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  182  loss  tensor(0.1500, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  183  loss  tensor(0.1276, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  184  loss  tensor(0.1862, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  185  loss  tensor(0.1913, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  186  loss  tensor(0.1141, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  187  loss  tensor(0.4987, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  188  loss  tensor(0.1074, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  189  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  190  loss  tensor(0.1123, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  191  loss  tensor(0.0991, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  192  loss  tensor(0.1708, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  193  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  194  loss  tensor(0.4850, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  195  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  196  loss  tensor(0.1371, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  197  loss  tensor(0.3365, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  198  loss  tensor(0.1073, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  199  loss  tensor(0.1165, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  200  loss  tensor(0.1278, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  201  loss  tensor(0.1240, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  202  loss  tensor(0.1171, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  203  loss  tensor(0.1027, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  204  loss  tensor(0.1798, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  205  loss  tensor(0.2515, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  206  loss  tensor(0.1241, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  207  loss  tensor(0.3603, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  208  loss  tensor(0.1245, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  209  loss  tensor(0.2744, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  210  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  211  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  212  loss  tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  213  loss  tensor(0.1078, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  214  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  215  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  216  loss  tensor(0.1350, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  217  loss  tensor(0.1026, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  218  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  219  loss  tensor(0.2867, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  220  loss  tensor(0.1140, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  221  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  222  loss  tensor(0.1360, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  223  loss  tensor(0.1443, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  224  loss  tensor(0.1451, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  225  loss  tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  226  loss  tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  227  loss  tensor(0.1445, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  228  loss  tensor(0.1420, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  229  loss  tensor(0.2910, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  230  loss  tensor(0.3219, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  231  loss  tensor(0.0979, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  232  loss  tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  233  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  234  loss  tensor(0.4047, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  235  loss  tensor(2.3559, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  236  loss  tensor(0.1814, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  237  loss  tensor(0.1243, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  238  loss  tensor(0.1067, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  239  loss  tensor(0.1772, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  240  loss  tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  241  loss  tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  242  loss  tensor(0.1123, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  243  loss  tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  244  loss  tensor(0.6183, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  245  loss  tensor(0.1098, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  246  loss  tensor(0.2683, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  247  loss  tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  248  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  249  loss  tensor(0.1916, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  250  loss  tensor(0.1291, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  251  loss  tensor(0.1213, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  252  loss  tensor(0.2614, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  253  loss  tensor(0.1473, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  254  loss  tensor(0.1427, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  255  loss  tensor(0.3305, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  256  loss  tensor(0.1884, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  257  loss  tensor(0.1045, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  258  loss  tensor(0.1636, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  259  loss  tensor(0.1512, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  260  loss  tensor(0.2029, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  261  loss  tensor(0.1033, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  262  loss  tensor(0.1321, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  263  loss  tensor(0.1065, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  264  loss  tensor(0.2544, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  265  loss  tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  266  loss  tensor(0.1097, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  267  loss  tensor(0.1114, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  268  loss  tensor(0.1030, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  269  loss  tensor(0.1204, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  270  loss  tensor(0.5596, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  271  loss  tensor(0.1267, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  272  loss  tensor(0.1033, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  273  loss  tensor(0.1275, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  274  loss  tensor(0.1563, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  275  loss  tensor(0.1497, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  276  loss  tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  277  loss  tensor(0.1501, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  278  loss  tensor(0.1303, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  279  loss  tensor(0.1348, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  280  loss  tensor(0.1201, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  281  loss  tensor(0.1009, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  7  batch  282  loss  tensor(0.3490, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  283  loss  tensor(0.2326, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  284  loss  tensor(0.1052, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  285  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  286  loss  tensor(0.1299, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  287  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  288  loss  tensor(0.1144, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  289  loss  tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  290  loss  tensor(0.1510, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  291  loss  tensor(0.1278, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  292  loss  tensor(0.1302, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  293  loss  tensor(0.5546, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  294  loss  tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  295  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  296  loss  tensor(0.1701, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  297  loss  tensor(0.2181, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  298  loss  tensor(0.1079, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  299  loss  tensor(0.2073, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  300  loss  tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  301  loss  tensor(0.1217, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  302  loss  tensor(0.3210, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  303  loss  tensor(0.1049, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  304  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  305  loss  tensor(0.1008, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  306  loss  tensor(0.1091, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  307  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  308  loss  tensor(0.1095, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  309  loss  tensor(0.1695, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  310  loss  tensor(0.1254, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  311  loss  tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  312  loss  tensor(0.1032, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  313  loss  tensor(0.2009, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  314  loss  tensor(0.1302, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  315  loss  tensor(0.1232, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  316  loss  tensor(0.1248, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  317  loss  tensor(0.1747, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  318  loss  tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  319  loss  tensor(0.1020, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  320  loss  tensor(0.1434, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  321  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  322  loss  tensor(0.1052, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  323  loss  tensor(0.3312, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  324  loss  tensor(0.1359, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  325  loss  tensor(0.1057, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  326  loss  tensor(0.1227, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  327  loss  tensor(0.1341, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  328  loss  tensor(0.1778, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  329  loss  tensor(0.2101, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  330  loss  tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  331  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  332  loss  tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  333  loss  tensor(0.1750, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  334  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  335  loss  tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  336  loss  tensor(0.1231, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  337  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  338  loss  tensor(0.1300, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  339  loss  tensor(0.1234, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  340  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  341  loss  tensor(0.1372, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  342  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  343  loss  tensor(0.1134, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  344  loss  tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  345  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  346  loss  tensor(0.1665, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  347  loss  tensor(0.1265, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  348  loss  tensor(0.1008, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  349  loss  tensor(1.5776, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  350  loss  tensor(0.1352, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  351  loss  tensor(0.1062, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  352  loss  tensor(0.2865, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  353  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  354  loss  tensor(0.4795, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  355  loss  tensor(0.1409, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  356  loss  tensor(0.1361, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  357  loss  tensor(0.1223, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  358  loss  tensor(0.1179, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  359  loss  tensor(0.2466, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  360  loss  tensor(0.1032, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  361  loss  tensor(0.1162, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  362  loss  tensor(0.1110, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  363  loss  tensor(0.1447, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  364  loss  tensor(0.1305, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  365  loss  tensor(0.2374, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  366  loss  tensor(0.2235, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  367  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  368  loss  tensor(0.1825, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  369  loss  tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  370  loss  tensor(0.1708, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  371  loss  tensor(0.1318, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  372  loss  tensor(0.1376, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  373  loss  tensor(0.2388, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  374  loss  tensor(0.1212, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  375  loss  tensor(0.1489, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  376  loss  tensor(0.1076, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  377  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  378  loss  tensor(0.1040, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  379  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  380  loss  tensor(0.1355, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  381  loss  tensor(0.1674, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  382  loss  tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  383  loss  tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  384  loss  tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  385  loss  tensor(0.1552, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  386  loss  tensor(0.1386, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  387  loss  tensor(0.1121, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  388  loss  tensor(0.1530, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  389  loss  tensor(0.1241, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  390  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  391  loss  tensor(0.1138, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  392  loss  tensor(0.1856, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  393  loss  tensor(0.5960, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  394  loss  tensor(0.1430, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  395  loss  tensor(0.1681, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  396  loss  tensor(0.1497, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  397  loss  tensor(0.1124, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  398  loss  tensor(0.1330, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  399  loss  tensor(0.1434, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  400  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  401  loss  tensor(0.1069, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  402  loss  tensor(0.1249, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  403  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  404  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  7  batch  405  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  406  loss  tensor(0.1090, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  407  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  408  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  409  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  410  loss  tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  411  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  412  loss  tensor(0.1098, grad_fn=<AddBackward0>)\n",
      "epoch  7  batch  413  loss  tensor(5.5195, grad_fn=<AddBackward0>)\n",
      "epoch [8/100], loss:87.0764\n",
      "epoch  8  batch  0  loss  tensor(0.1330, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  1  loss  tensor(0.3857, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  2  loss  tensor(0.1331, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  3  loss  tensor(1.9347, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  4  loss  tensor(0.1150, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  5  loss  tensor(0.1104, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  6  loss  tensor(0.1212, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  7  loss  tensor(0.1387, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  8  loss  tensor(0.3199, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  9  loss  tensor(0.1534, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  10  loss  tensor(0.1267, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  11  loss  tensor(0.1065, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  12  loss  tensor(3.4263, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  13  loss  tensor(0.2644, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  14  loss  tensor(0.9066, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  15  loss  tensor(0.1180, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  16  loss  tensor(0.1707, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  17  loss  tensor(0.1746, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  18  loss  tensor(0.1046, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  19  loss  tensor(0.1320, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  20  loss  tensor(0.2838, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  21  loss  tensor(0.1178, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  22  loss  tensor(0.1961, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  23  loss  tensor(0.1598, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  24  loss  tensor(0.2935, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  25  loss  tensor(0.1826, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  26  loss  tensor(0.1091, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  27  loss  tensor(0.1608, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  28  loss  tensor(0.1263, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  29  loss  tensor(0.2024, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  30  loss  tensor(0.1482, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  31  loss  tensor(0.4532, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  32  loss  tensor(0.1509, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  33  loss  tensor(0.2275, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  34  loss  tensor(0.2346, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  35  loss  tensor(1.3081, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  36  loss  tensor(0.1193, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  37  loss  tensor(0.1470, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  38  loss  tensor(0.1429, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  39  loss  tensor(0.1542, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  40  loss  tensor(0.1644, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  41  loss  tensor(0.1172, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  42  loss  tensor(0.1731, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  43  loss  tensor(0.2314, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  44  loss  tensor(0.2603, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  45  loss  tensor(0.1073, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  46  loss  tensor(0.1394, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  47  loss  tensor(0.1503, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  48  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  49  loss  tensor(0.1394, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  50  loss  tensor(0.1234, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  51  loss  tensor(0.1506, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  52  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  53  loss  tensor(0.2389, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  54  loss  tensor(0.1108, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  55  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  56  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  57  loss  tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  58  loss  tensor(0.1505, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  59  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  60  loss  tensor(0.2122, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  61  loss  tensor(0.1006, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  62  loss  tensor(0.0980, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  63  loss  tensor(0.1083, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  64  loss  tensor(0.1250, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  65  loss  tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  66  loss  tensor(0.1197, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  67  loss  tensor(0.1771, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  68  loss  tensor(0.1532, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  69  loss  tensor(0.1607, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  70  loss  tensor(0.0991, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  71  loss  tensor(0.1112, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  72  loss  tensor(0.3000, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  73  loss  tensor(0.1302, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  74  loss  tensor(0.1372, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  75  loss  tensor(0.1412, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  76  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  77  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  78  loss  tensor(0.1308, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  79  loss  tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  80  loss  tensor(0.1508, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  81  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  82  loss  tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  83  loss  tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  84  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  85  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  86  loss  tensor(0.1018, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  87  loss  tensor(0.1324, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  88  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  89  loss  tensor(0.1050, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  90  loss  tensor(0.1621, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  91  loss  tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  92  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  93  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  94  loss  tensor(0.3571, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  95  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  96  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  97  loss  tensor(0.1129, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  98  loss  tensor(0.1826, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  99  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  100  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  101  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  102  loss  tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  103  loss  tensor(1.1575, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  104  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  105  loss  tensor(0.3874, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  106  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  107  loss  tensor(0.1323, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  108  loss  tensor(0.1589, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  109  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  110  loss  tensor(0.1170, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  111  loss  tensor(0.1530, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  112  loss  tensor(0.2425, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  113  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  114  loss  tensor(0.2794, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  8  batch  115  loss  tensor(0.1091, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  116  loss  tensor(0.1199, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  117  loss  tensor(0.1553, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  118  loss  tensor(0.1182, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  119  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  120  loss  tensor(0.1213, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  121  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  122  loss  tensor(0.1556, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  123  loss  tensor(0.1809, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  124  loss  tensor(0.2617, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  125  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  126  loss  tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  127  loss  tensor(0.1060, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  128  loss  tensor(0.1236, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  129  loss  tensor(0.0989, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  130  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  131  loss  tensor(0.1325, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  132  loss  tensor(0.1071, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  133  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  134  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  135  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  136  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  137  loss  tensor(0.1606, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  138  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  139  loss  tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  140  loss  tensor(0.1514, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  141  loss  tensor(0.1152, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  142  loss  tensor(0.1057, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  143  loss  tensor(0.1395, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  144  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  145  loss  tensor(0.1390, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  146  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  147  loss  tensor(0.1049, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  148  loss  tensor(0.1261, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  149  loss  tensor(0.1189, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  150  loss  tensor(0.1574, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  151  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  152  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  153  loss  tensor(0.1199, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  154  loss  tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  155  loss  tensor(0.1131, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  156  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  157  loss  tensor(0.5697, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  158  loss  tensor(0.2749, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  159  loss  tensor(0.1119, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  160  loss  tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  161  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  162  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  163  loss  tensor(0.1142, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  164  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  165  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  166  loss  tensor(0.1104, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  167  loss  tensor(0.1030, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  168  loss  tensor(0.1260, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  169  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  170  loss  tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  171  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  172  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  173  loss  tensor(0.1260, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  174  loss  tensor(0.1014, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  175  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  176  loss  tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  177  loss  tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  178  loss  tensor(0.1180, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  179  loss  tensor(0.1217, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  180  loss  tensor(0.0989, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  181  loss  tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  182  loss  tensor(0.1369, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  183  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  184  loss  tensor(0.1027, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  185  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  186  loss  tensor(0.1008, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  187  loss  tensor(0.1156, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  188  loss  tensor(0.1126, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  189  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  190  loss  tensor(0.1305, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  191  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  192  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  193  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  194  loss  tensor(0.1106, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  195  loss  tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  196  loss  tensor(0.1730, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  197  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  198  loss  tensor(0.2045, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  199  loss  tensor(0.1078, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  200  loss  tensor(0.1469, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  201  loss  tensor(0.1225, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  202  loss  tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  203  loss  tensor(0.1018, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  204  loss  tensor(0.1599, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  205  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  206  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  207  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  208  loss  tensor(0.1280, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  209  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  210  loss  tensor(0.1151, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  211  loss  tensor(0.2961, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  212  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  213  loss  tensor(0.1453, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  214  loss  tensor(0.1108, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  215  loss  tensor(0.1123, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  216  loss  tensor(0.0989, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  217  loss  tensor(0.1056, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  218  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  219  loss  tensor(0.1503, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  220  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  221  loss  tensor(0.3990, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  222  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  223  loss  tensor(0.1882, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  224  loss  tensor(0.1384, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  225  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  226  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  227  loss  tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  228  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  229  loss  tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  230  loss  tensor(0.1604, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  231  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  232  loss  tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  233  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  234  loss  tensor(0.1140, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  235  loss  tensor(0.1403, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  236  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  237  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  8  batch  238  loss  tensor(0.1291, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  239  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  240  loss  tensor(0.1198, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  241  loss  tensor(0.1294, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  242  loss  tensor(0.1270, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  243  loss  tensor(0.0995, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  244  loss  tensor(0.1030, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  245  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  246  loss  tensor(0.1203, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  247  loss  tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  248  loss  tensor(0.3286, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  249  loss  tensor(0.2720, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  250  loss  tensor(0.1749, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  251  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  252  loss  tensor(0.1451, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  253  loss  tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  254  loss  tensor(0.1178, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  255  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  256  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  257  loss  tensor(0.1054, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  258  loss  tensor(0.1217, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  259  loss  tensor(0.1027, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  260  loss  tensor(0.1221, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  261  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  262  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  263  loss  tensor(0.0979, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  264  loss  tensor(0.1233, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  265  loss  tensor(0.3105, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  266  loss  tensor(0.1454, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  267  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  268  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  269  loss  tensor(0.1065, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  270  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  271  loss  tensor(0.1614, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  272  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  273  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  274  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  275  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  276  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  277  loss  tensor(0.1530, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  278  loss  tensor(0.1517, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  279  loss  tensor(0.1175, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  280  loss  tensor(0.1177, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  281  loss  tensor(0.2477, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  282  loss  tensor(0.2082, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  283  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  284  loss  tensor(0.1256, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  285  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  286  loss  tensor(0.1487, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  287  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  288  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  289  loss  tensor(0.1583, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  290  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  291  loss  tensor(0.9617, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  292  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  293  loss  tensor(0.1031, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  294  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  295  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  296  loss  tensor(0.1139, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  297  loss  tensor(0.1289, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  298  loss  tensor(0.2084, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  299  loss  tensor(0.1664, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  300  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  301  loss  tensor(0.3444, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  302  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  303  loss  tensor(0.1598, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  304  loss  tensor(0.0987, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  305  loss  tensor(0.2145, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  306  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  307  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  308  loss  tensor(0.2888, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  309  loss  tensor(0.2411, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  310  loss  tensor(0.1133, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  311  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  312  loss  tensor(0.1574, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  313  loss  tensor(0.1044, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  314  loss  tensor(0.2257, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  315  loss  tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  316  loss  tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  317  loss  tensor(0.1552, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  318  loss  tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  319  loss  tensor(0.1763, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  320  loss  tensor(0.1033, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  321  loss  tensor(0.0960, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  322  loss  tensor(0.1334, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  323  loss  tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  324  loss  tensor(0.1074, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  325  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  326  loss  tensor(0.1014, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  327  loss  tensor(0.1105, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  328  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  329  loss  tensor(0.1281, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  330  loss  tensor(0.2019, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  331  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  332  loss  tensor(0.1560, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  333  loss  tensor(0.1171, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  334  loss  tensor(0.1018, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  335  loss  tensor(0.1305, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  336  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  337  loss  tensor(0.1215, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  338  loss  tensor(0.3066, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  339  loss  tensor(0.1730, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  340  loss  tensor(0.1071, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  341  loss  tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  342  loss  tensor(0.1037, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  343  loss  tensor(0.1162, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  344  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  345  loss  tensor(0.1122, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  346  loss  tensor(0.1012, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  347  loss  tensor(0.1645, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  348  loss  tensor(0.1101, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  349  loss  tensor(0.1344, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  350  loss  tensor(0.1266, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  351  loss  tensor(0.1076, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  352  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  353  loss  tensor(0.1040, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  354  loss  tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  355  loss  tensor(0.3152, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  356  loss  tensor(0.1583, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  357  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  358  loss  tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  359  loss  tensor(0.1044, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  360  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  8  batch  361  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  362  loss  tensor(0.1371, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  363  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  364  loss  tensor(0.1058, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  365  loss  tensor(0.7612, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  366  loss  tensor(0.3327, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  367  loss  tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  368  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  369  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  370  loss  tensor(0.1244, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  371  loss  tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  372  loss  tensor(0.1057, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  373  loss  tensor(0.1265, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  374  loss  tensor(0.1892, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  375  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  376  loss  tensor(0.0995, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  377  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  378  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  379  loss  tensor(0.2995, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  380  loss  tensor(0.1151, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  381  loss  tensor(0.1666, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  382  loss  tensor(0.1245, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  383  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  384  loss  tensor(0.1148, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  385  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  386  loss  tensor(0.1496, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  387  loss  tensor(0.1106, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  388  loss  tensor(0.4091, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  389  loss  tensor(0.2223, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  390  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  391  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  392  loss  tensor(0.1038, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  393  loss  tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  394  loss  tensor(0.0968, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  395  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  396  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  397  loss  tensor(1.4768, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  398  loss  tensor(0.2617, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  399  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  400  loss  tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  401  loss  tensor(0.1267, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  402  loss  tensor(0.2584, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  403  loss  tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  404  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  405  loss  tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  406  loss  tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  407  loss  tensor(0.1087, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  408  loss  tensor(0.1454, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  409  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  410  loss  tensor(0.9236, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  411  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  412  loss  tensor(0.1567, grad_fn=<AddBackward0>)\n",
      "epoch  8  batch  413  loss  tensor(0.1870, grad_fn=<AddBackward0>)\n",
      "epoch [9/100], loss:66.5462\n",
      "epoch  9  batch  0  loss  tensor(0.0992, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  1  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  2  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  3  loss  tensor(0.0980, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  4  loss  tensor(0.1102, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  5  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  6  loss  tensor(0.1040, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  7  loss  tensor(0.1304, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  8  loss  tensor(1.3540, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  9  loss  tensor(0.1203, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  10  loss  tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  11  loss  tensor(0.0968, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  12  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  13  loss  tensor(0.4981, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  14  loss  tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  15  loss  tensor(0.1172, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  16  loss  tensor(0.1400, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  17  loss  tensor(0.1241, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  18  loss  tensor(0.1014, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  19  loss  tensor(0.4761, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  20  loss  tensor(0.1312, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  21  loss  tensor(0.1221, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  22  loss  tensor(0.1106, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  23  loss  tensor(0.1275, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  24  loss  tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  25  loss  tensor(0.1576, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  26  loss  tensor(0.1401, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  27  loss  tensor(0.1131, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  28  loss  tensor(0.1718, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  29  loss  tensor(0.1504, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  30  loss  tensor(0.1277, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  31  loss  tensor(0.1264, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  32  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  33  loss  tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  34  loss  tensor(0.1610, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  35  loss  tensor(0.7073, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  36  loss  tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  37  loss  tensor(0.1104, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  38  loss  tensor(0.1182, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  39  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  40  loss  tensor(0.1093, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  41  loss  tensor(0.1318, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  42  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  43  loss  tensor(0.1508, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  44  loss  tensor(0.1868, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  45  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  46  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  47  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  48  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  49  loss  tensor(0.1163, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  50  loss  tensor(0.3906, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  51  loss  tensor(0.1061, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  52  loss  tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  53  loss  tensor(0.1654, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  54  loss  tensor(0.1028, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  55  loss  tensor(0.1243, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  56  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  57  loss  tensor(0.4699, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  58  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  59  loss  tensor(0.1063, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  60  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  61  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  62  loss  tensor(0.1154, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  63  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  64  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  65  loss  tensor(0.1033, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  66  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  67  loss  tensor(0.1406, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  68  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  69  loss  tensor(0.1159, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  70  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  9  batch  71  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  72  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  73  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  74  loss  tensor(0.1152, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  75  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  76  loss  tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  77  loss  tensor(0.1138, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  78  loss  tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  79  loss  tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  80  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  81  loss  tensor(0.0971, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  82  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  83  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  84  loss  tensor(0.1391, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  85  loss  tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  86  loss  tensor(0.1108, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  87  loss  tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  88  loss  tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  89  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  90  loss  tensor(0.1255, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  91  loss  tensor(0.0998, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  92  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  93  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  94  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  95  loss  tensor(0.1456, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  96  loss  tensor(0.1392, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  97  loss  tensor(0.1319, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  98  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  99  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  100  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  101  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  102  loss  tensor(0.1032, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  103  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  104  loss  tensor(0.1062, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  105  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  106  loss  tensor(0.1300, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  107  loss  tensor(0.1015, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  108  loss  tensor(0.0966, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  109  loss  tensor(0.1201, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  110  loss  tensor(3.1560, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  111  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  112  loss  tensor(0.1609, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  113  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  114  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  115  loss  tensor(0.1550, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  116  loss  tensor(0.1292, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  117  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  118  loss  tensor(0.1571, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  119  loss  tensor(0.1145, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  120  loss  tensor(0.1135, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  121  loss  tensor(0.1153, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  122  loss  tensor(0.1121, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  123  loss  tensor(1.1226, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  124  loss  tensor(0.1052, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  125  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  126  loss  tensor(0.1140, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  127  loss  tensor(0.0966, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  128  loss  tensor(0.0975, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  129  loss  tensor(0.3029, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  130  loss  tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  131  loss  tensor(0.1389, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  132  loss  tensor(0.1168, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  133  loss  tensor(0.3830, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  134  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  135  loss  tensor(0.1327, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  136  loss  tensor(0.1458, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  137  loss  tensor(0.1065, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  138  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  139  loss  tensor(0.1238, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  140  loss  tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  141  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  142  loss  tensor(0.1123, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  143  loss  tensor(0.1495, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  144  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  145  loss  tensor(0.1171, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  146  loss  tensor(0.1192, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  147  loss  tensor(0.1268, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  148  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  149  loss  tensor(0.1343, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  150  loss  tensor(0.0995, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  151  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  152  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  153  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  154  loss  tensor(0.2170, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  155  loss  tensor(1.0742, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  156  loss  tensor(0.1126, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  157  loss  tensor(0.1169, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  158  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  159  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  160  loss  tensor(0.1098, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  161  loss  tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  162  loss  tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  163  loss  tensor(0.1442, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  164  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  165  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  166  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  167  loss  tensor(0.0995, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  168  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  169  loss  tensor(0.1592, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  170  loss  tensor(0.0998, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  171  loss  tensor(0.1351, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  172  loss  tensor(0.1271, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  173  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  174  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  175  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  176  loss  tensor(0.1452, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  177  loss  tensor(0.2149, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  178  loss  tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  179  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  180  loss  tensor(0.1422, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  181  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  182  loss  tensor(0.1100, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  183  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  184  loss  tensor(0.1136, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  185  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  186  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  187  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  188  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  189  loss  tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  190  loss  tensor(0.1253, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  191  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  192  loss  tensor(0.3267, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  193  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  9  batch  194  loss  tensor(0.3712, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  195  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  196  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  197  loss  tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  198  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  199  loss  tensor(0.1055, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  200  loss  tensor(0.1792, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  201  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  202  loss  tensor(0.1070, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  203  loss  tensor(0.1069, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  204  loss  tensor(0.0968, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  205  loss  tensor(0.1288, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  206  loss  tensor(0.0960, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  207  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  208  loss  tensor(0.1121, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  209  loss  tensor(0.1002, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  210  loss  tensor(0.0996, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  211  loss  tensor(0.1282, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  212  loss  tensor(0.1210, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  213  loss  tensor(0.1258, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  214  loss  tensor(0.1017, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  215  loss  tensor(0.1368, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  216  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  217  loss  tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  218  loss  tensor(0.1683, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  219  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  220  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  221  loss  tensor(0.0997, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  222  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  223  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  224  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  225  loss  tensor(0.1270, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  226  loss  tensor(0.1371, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  227  loss  tensor(0.1085, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  228  loss  tensor(0.1914, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  229  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  230  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  231  loss  tensor(0.1079, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  232  loss  tensor(0.1074, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  233  loss  tensor(0.1144, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  234  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  235  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  236  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  237  loss  tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  238  loss  tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  239  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  240  loss  tensor(0.1059, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  241  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  242  loss  tensor(0.1726, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  243  loss  tensor(0.1044, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  244  loss  tensor(0.1115, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  245  loss  tensor(0.1215, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  246  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  247  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  248  loss  tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  249  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  250  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  251  loss  tensor(0.1029, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  252  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  253  loss  tensor(0.1068, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  254  loss  tensor(0.1230, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  255  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  256  loss  tensor(0.2058, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  257  loss  tensor(0.1087, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  258  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  259  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  260  loss  tensor(0.1256, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  261  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  262  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  263  loss  tensor(0.1247, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  264  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  265  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  266  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  267  loss  tensor(0.1162, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  268  loss  tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  269  loss  tensor(0.1103, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  270  loss  tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  271  loss  tensor(0.1783, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  272  loss  tensor(0.3292, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  273  loss  tensor(0.1699, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  274  loss  tensor(0.1244, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  275  loss  tensor(0.1292, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  276  loss  tensor(0.5030, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  277  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  278  loss  tensor(0.2327, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  279  loss  tensor(0.1076, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  280  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  281  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  282  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  283  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  284  loss  tensor(0.1293, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  285  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  286  loss  tensor(0.1482, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  287  loss  tensor(0.0963, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  288  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  289  loss  tensor(0.1002, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  290  loss  tensor(0.1056, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  291  loss  tensor(0.1290, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  292  loss  tensor(1.2348, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  293  loss  tensor(0.1199, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  294  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  295  loss  tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  296  loss  tensor(0.1145, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  297  loss  tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  298  loss  tensor(0.1850, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  299  loss  tensor(0.6230, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  300  loss  tensor(0.1202, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  301  loss  tensor(0.1063, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  302  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  303  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  304  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  305  loss  tensor(0.1541, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  306  loss  tensor(0.1175, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  307  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  308  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  309  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  310  loss  tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  311  loss  tensor(0.1098, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  312  loss  tensor(0.1069, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  313  loss  tensor(0.1470, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  314  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  315  loss  tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  316  loss  tensor(0.1095, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  9  batch  317  loss  tensor(0.1249, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  318  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  319  loss  tensor(0.1208, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  320  loss  tensor(0.1100, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  321  loss  tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  322  loss  tensor(0.1453, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  323  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  324  loss  tensor(0.1764, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  325  loss  tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  326  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  327  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  328  loss  tensor(0.1097, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  329  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  330  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  331  loss  tensor(0.1232, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  332  loss  tensor(0.2662, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  333  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  334  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  335  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  336  loss  tensor(0.0968, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  337  loss  tensor(0.1211, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  338  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  339  loss  tensor(0.1057, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  340  loss  tensor(0.1524, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  341  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  342  loss  tensor(0.1075, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  343  loss  tensor(0.1058, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  344  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  345  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  346  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  347  loss  tensor(0.1119, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  348  loss  tensor(0.0979, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  349  loss  tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  350  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  351  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  352  loss  tensor(0.1086, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  353  loss  tensor(0.2606, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  354  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  355  loss  tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  356  loss  tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  357  loss  tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  358  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  359  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  360  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  361  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  362  loss  tensor(0.1179, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  363  loss  tensor(0.1494, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  364  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  365  loss  tensor(0.2698, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  366  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  367  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  368  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  369  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  370  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  371  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  372  loss  tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  373  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  374  loss  tensor(0.1113, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  375  loss  tensor(0.1819, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  376  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  377  loss  tensor(0.1017, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  378  loss  tensor(0.1317, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  379  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  380  loss  tensor(0.2151, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  381  loss  tensor(0.2387, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  382  loss  tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  383  loss  tensor(0.2201, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  384  loss  tensor(0.1136, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  385  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  386  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  387  loss  tensor(0.1109, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  388  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  389  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  390  loss  tensor(0.1448, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  391  loss  tensor(0.1538, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  392  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  393  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  394  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  395  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  396  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  397  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  398  loss  tensor(0.1336, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  399  loss  tensor(0.1072, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  400  loss  tensor(0.1051, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  401  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  402  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  403  loss  tensor(0.0991, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  404  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  405  loss  tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  406  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  407  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  408  loss  tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  409  loss  tensor(0.4652, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  410  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  411  loss  tensor(0.1104, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  412  loss  tensor(0.2110, grad_fn=<AddBackward0>)\n",
      "epoch  9  batch  413  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch [10/100], loss:57.2413\n",
      "epoch  10  batch  0  loss  tensor(0.1158, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  1  loss  tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  2  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  3  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  4  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  5  loss  tensor(0.1329, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  6  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  7  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  8  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  9  loss  tensor(0.1215, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  10  loss  tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  11  loss  tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  12  loss  tensor(0.1322, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  13  loss  tensor(0.1070, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  14  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  15  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  16  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  17  loss  tensor(0.2288, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  18  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  19  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  20  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  21  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  22  loss  tensor(0.1072, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  23  loss  tensor(0.1692, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  24  loss  tensor(0.1283, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10  batch  25  loss  tensor(1.9285, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  26  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  27  loss  tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  28  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  29  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  30  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  31  loss  tensor(0.1969, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  32  loss  tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  33  loss  tensor(0.1243, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  34  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  35  loss  tensor(0.2002, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  36  loss  tensor(0.2136, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  37  loss  tensor(0.2742, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  38  loss  tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  39  loss  tensor(0.1349, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  40  loss  tensor(0.1359, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  41  loss  tensor(0.0971, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  42  loss  tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  43  loss  tensor(0.1633, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  44  loss  tensor(0.1144, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  45  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  46  loss  tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  47  loss  tensor(0.1480, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  48  loss  tensor(0.0992, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  49  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  50  loss  tensor(0.0969, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  51  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  52  loss  tensor(0.1084, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  53  loss  tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  54  loss  tensor(0.1184, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  55  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  56  loss  tensor(1.2239, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  57  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  58  loss  tensor(0.1789, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  59  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  60  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  61  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  62  loss  tensor(0.1170, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  63  loss  tensor(0.1049, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  64  loss  tensor(0.1318, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  65  loss  tensor(0.0975, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  66  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  67  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  68  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  69  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  70  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  71  loss  tensor(0.6164, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  72  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  73  loss  tensor(0.1255, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  74  loss  tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  75  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  76  loss  tensor(0.1237, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  77  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  78  loss  tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  79  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  80  loss  tensor(0.7939, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  81  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  82  loss  tensor(0.2091, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  83  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  84  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  85  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  86  loss  tensor(0.1221, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  87  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  88  loss  tensor(0.1180, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  89  loss  tensor(0.0971, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  90  loss  tensor(0.1023, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  91  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  92  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  93  loss  tensor(0.1013, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  94  loss  tensor(0.1072, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  95  loss  tensor(0.1087, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  96  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  97  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  98  loss  tensor(0.4052, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  99  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  100  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  101  loss  tensor(0.1295, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  102  loss  tensor(0.1384, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  103  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  104  loss  tensor(0.1523, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  105  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  106  loss  tensor(0.1025, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  107  loss  tensor(0.1733, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  108  loss  tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  109  loss  tensor(0.1128, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  110  loss  tensor(0.1258, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  111  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  112  loss  tensor(0.1176, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  113  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  114  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  115  loss  tensor(0.1136, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  116  loss  tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  117  loss  tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  118  loss  tensor(0.1013, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  119  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  120  loss  tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  121  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  122  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  123  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  124  loss  tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  125  loss  tensor(0.1928, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  126  loss  tensor(0.1251, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  127  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  128  loss  tensor(0.2230, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  129  loss  tensor(0.1154, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  130  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  131  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  132  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  133  loss  tensor(0.2211, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  134  loss  tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  135  loss  tensor(0.1204, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  136  loss  tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  137  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  138  loss  tensor(0.1134, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  139  loss  tensor(0.1018, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  140  loss  tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  141  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  142  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  143  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  144  loss  tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  145  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  146  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10  batch  147  loss  tensor(0.0962, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  148  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  149  loss  tensor(0.1605, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  150  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  151  loss  tensor(0.1002, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  152  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  153  loss  tensor(0.2101, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  154  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  155  loss  tensor(0.1848, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  156  loss  tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  157  loss  tensor(0.1692, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  158  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  159  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  160  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  161  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  162  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  163  loss  tensor(0.1031, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  164  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  165  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  166  loss  tensor(0.1186, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  167  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  168  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  169  loss  tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  170  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  171  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  172  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  173  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  174  loss  tensor(0.1093, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  175  loss  tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  176  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  177  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  178  loss  tensor(0.1425, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  179  loss  tensor(0.1017, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  180  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  181  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  182  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  183  loss  tensor(0.1958, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  184  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  185  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  186  loss  tensor(0.1121, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  187  loss  tensor(0.1244, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  188  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  189  loss  tensor(0.1080, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  190  loss  tensor(0.1006, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  191  loss  tensor(0.0963, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  192  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  193  loss  tensor(0.1521, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  194  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  195  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  196  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  197  loss  tensor(0.1866, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  198  loss  tensor(0.3455, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  199  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  200  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  201  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  202  loss  tensor(0.1657, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  203  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  204  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  205  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  206  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  207  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  208  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  209  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  210  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  211  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  212  loss  tensor(0.1119, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  213  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  214  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  215  loss  tensor(0.1534, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  216  loss  tensor(0.0982, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  217  loss  tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  218  loss  tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  219  loss  tensor(0.1068, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  220  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  221  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  222  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  223  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  224  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  225  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  226  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  227  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  228  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  229  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  230  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  231  loss  tensor(0.1070, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  232  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  233  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  234  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  235  loss  tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  236  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  237  loss  tensor(0.1153, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  238  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  239  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  240  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  241  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  242  loss  tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  243  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  244  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  245  loss  tensor(0.1291, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  246  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  247  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  248  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  249  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  250  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  251  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  252  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  253  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  254  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  255  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  256  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  257  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  258  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  259  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  260  loss  tensor(0.4984, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  261  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  262  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  263  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  264  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  265  loss  tensor(0.1176, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  266  loss  tensor(0.1301, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  267  loss  tensor(0.1011, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10  batch  268  loss  tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  269  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  270  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  271  loss  tensor(0.1080, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  272  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  273  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  274  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  275  loss  tensor(0.1074, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  276  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  277  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  278  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  279  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  280  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  281  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  282  loss  tensor(0.2738, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  283  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  284  loss  tensor(0.1540, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  285  loss  tensor(0.1013, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  286  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  287  loss  tensor(0.1186, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  288  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  289  loss  tensor(0.1105, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  290  loss  tensor(0.0997, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  291  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  292  loss  tensor(0.1196, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  293  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  294  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  295  loss  tensor(0.0960, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  296  loss  tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  297  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  298  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  299  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  300  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  301  loss  tensor(0.1037, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  302  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  303  loss  tensor(0.1080, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  304  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  305  loss  tensor(0.1245, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  306  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  307  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  308  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  309  loss  tensor(0.1301, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  310  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  311  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  312  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  313  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  314  loss  tensor(0.1607, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  315  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  316  loss  tensor(0.0997, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  317  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  318  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  319  loss  tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  320  loss  tensor(0.1608, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  321  loss  tensor(0.1173, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  322  loss  tensor(0.2066, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  323  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  324  loss  tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  325  loss  tensor(0.1177, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  326  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  327  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  328  loss  tensor(0.1091, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  329  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  330  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  331  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  332  loss  tensor(0.1647, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  333  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  334  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  335  loss  tensor(0.1072, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  336  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  337  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  338  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  339  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  340  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  341  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  342  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  343  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  344  loss  tensor(0.1096, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  345  loss  tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  346  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  347  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  348  loss  tensor(0.2796, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  349  loss  tensor(0.1414, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  350  loss  tensor(0.1097, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  351  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  352  loss  tensor(0.2166, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  353  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  354  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  355  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  356  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  357  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  358  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  359  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  360  loss  tensor(0.1433, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  361  loss  tensor(0.1001, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  362  loss  tensor(0.1014, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  363  loss  tensor(0.1125, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  364  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  365  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  366  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  367  loss  tensor(0.1130, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  368  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  369  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  370  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  371  loss  tensor(0.1192, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  372  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  373  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  374  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  375  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  376  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  377  loss  tensor(0.7838, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  378  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  379  loss  tensor(0.1020, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  380  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  381  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  382  loss  tensor(0.1236, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  383  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  384  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  385  loss  tensor(0.0966, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  386  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  387  loss  tensor(0.1022, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  388  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10  batch  389  loss  tensor(0.1029, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  390  loss  tensor(0.1076, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  391  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  392  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  393  loss  tensor(0.0989, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  394  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  395  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  396  loss  tensor(0.1214, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  397  loss  tensor(0.1136, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  398  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  399  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  400  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  401  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  402  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  403  loss  tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  404  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  405  loss  tensor(0.1159, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  406  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  407  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  408  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  409  loss  tensor(0.1044, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  410  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  411  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  412  loss  tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "epoch  10  batch  413  loss  tensor(0.1737, grad_fn=<AddBackward0>)\n",
      "epoch [11/100], loss:48.3568\n",
      "epoch  11  batch  0  loss  tensor(0.1017, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  1  loss  tensor(0.1122, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  2  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  3  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  4  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  5  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  6  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  7  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  8  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  9  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  10  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  11  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  12  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  13  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  14  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  15  loss  tensor(0.1175, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  16  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  17  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  18  loss  tensor(0.1218, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  19  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  20  loss  tensor(0.1606, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  21  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  22  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  23  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  24  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  25  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  26  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  27  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  28  loss  tensor(0.1109, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  29  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  30  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  31  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  32  loss  tensor(0.1476, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  33  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  34  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  35  loss  tensor(0.1874, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  36  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  37  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  38  loss  tensor(0.0979, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  39  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  40  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  41  loss  tensor(0.1083, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  42  loss  tensor(0.0991, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  43  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  44  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  45  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  46  loss  tensor(0.1804, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  47  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  48  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  49  loss  tensor(0.0982, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  50  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  51  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  52  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  53  loss  tensor(0.1098, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  54  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  55  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  56  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  57  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  58  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  59  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  60  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  61  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  62  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  63  loss  tensor(0.1148, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  64  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  65  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  66  loss  tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  67  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  68  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  69  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  70  loss  tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  71  loss  tensor(0.1142, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  72  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  73  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  74  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  75  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  76  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  77  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  78  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  79  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  80  loss  tensor(0.1025, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  81  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  82  loss  tensor(0.1022, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  83  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  84  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  85  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  86  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  87  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  88  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  89  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  90  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  91  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  92  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  93  loss  tensor(0.1183, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  94  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  95  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  96  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  11  batch  97  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  98  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  99  loss  tensor(0.1088, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  100  loss  tensor(0.1139, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  101  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  102  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  103  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  104  loss  tensor(0.1363, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  105  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  106  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  107  loss  tensor(0.1909, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  108  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  109  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  110  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  111  loss  tensor(0.5718, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  112  loss  tensor(0.1014, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  113  loss  tensor(0.1006, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  114  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  115  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  116  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  117  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  118  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  119  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  120  loss  tensor(0.5711, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  121  loss  tensor(0.1564, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  122  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  123  loss  tensor(0.2159, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  124  loss  tensor(0.1022, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  125  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  126  loss  tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  127  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  128  loss  tensor(0.1009, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  129  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  130  loss  tensor(0.2108, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  131  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  132  loss  tensor(0.1406, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  133  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  134  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  135  loss  tensor(0.1202, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  136  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  137  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  138  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  139  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  140  loss  tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  141  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  142  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  143  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  144  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  145  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  146  loss  tensor(0.1052, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  147  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  148  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  149  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  150  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  151  loss  tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  152  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  153  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  154  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  155  loss  tensor(0.1226, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  156  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  157  loss  tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  158  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  159  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  160  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  161  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  162  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  163  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  164  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  165  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  166  loss  tensor(0.1085, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  167  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  168  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  169  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  170  loss  tensor(0.1441, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  171  loss  tensor(0.1111, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  172  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  173  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  174  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  175  loss  tensor(0.4469, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  176  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  177  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  178  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  179  loss  tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  180  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  181  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  182  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  183  loss  tensor(0.1391, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  184  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  185  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  186  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  187  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  188  loss  tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  189  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  190  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  191  loss  tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  192  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  193  loss  tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  194  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  195  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  196  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  197  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  198  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  199  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  200  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  201  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  202  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  203  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  204  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  205  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  206  loss  tensor(0.1058, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  207  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  208  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  209  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  210  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  211  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  212  loss  tensor(0.1672, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  213  loss  tensor(0.1028, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  214  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  215  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  216  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  217  loss  tensor(0.0962, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  11  batch  218  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  219  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  220  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  221  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  222  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  223  loss  tensor(0.0960, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  224  loss  tensor(0.1111, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  225  loss  tensor(0.1096, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  226  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  227  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  228  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  229  loss  tensor(0.1225, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  230  loss  tensor(0.1140, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  231  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  232  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  233  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  234  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  235  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  236  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  237  loss  tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  238  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  239  loss  tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  240  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  241  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  242  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  243  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  244  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  245  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  246  loss  tensor(0.0996, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  247  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  248  loss  tensor(0.0996, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  249  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  250  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  251  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  252  loss  tensor(0.1096, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  253  loss  tensor(0.3114, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  254  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  255  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  256  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  257  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  258  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  259  loss  tensor(0.0987, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  260  loss  tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  261  loss  tensor(0.1323, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  262  loss  tensor(0.1038, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  263  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  264  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  265  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  266  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  267  loss  tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  268  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  269  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  270  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  271  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  272  loss  tensor(0.1054, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  273  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  274  loss  tensor(0.1305, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  275  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  276  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  277  loss  tensor(0.1081, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  278  loss  tensor(0.1108, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  279  loss  tensor(0.1478, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  280  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  281  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  282  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  283  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  284  loss  tensor(0.1513, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  285  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  286  loss  tensor(0.1525, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  287  loss  tensor(0.1242, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  288  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  289  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  290  loss  tensor(0.1323, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  291  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  292  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  293  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  294  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  295  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  296  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  297  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  298  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  299  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  300  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  301  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  302  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  303  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  304  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  305  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  306  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  307  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  308  loss  tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  309  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  310  loss  tensor(0.0969, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  311  loss  tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  312  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  313  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  314  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  315  loss  tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  316  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  317  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  318  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  319  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  320  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  321  loss  tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  322  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  323  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  324  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  325  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  326  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  327  loss  tensor(0.1469, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  328  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  329  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  330  loss  tensor(0.0987, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  331  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  332  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  333  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  334  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  335  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  336  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  337  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  338  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  11  batch  339  loss  tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  340  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  341  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  342  loss  tensor(0.1775, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  343  loss  tensor(0.1054, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  344  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  345  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  346  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  347  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  348  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  349  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  350  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  351  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  352  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  353  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  354  loss  tensor(0.1023, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  355  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  356  loss  tensor(0.1106, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  357  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  358  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  359  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  360  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  361  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  362  loss  tensor(0.1026, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  363  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  364  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  365  loss  tensor(0.1031, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  366  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  367  loss  tensor(0.1085, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  368  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  369  loss  tensor(0.1009, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  370  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  371  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  372  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  373  loss  tensor(0.1081, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  374  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  375  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  376  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  377  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  378  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  379  loss  tensor(0.1139, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  380  loss  tensor(0.1769, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  381  loss  tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  382  loss  tensor(0.1084, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  383  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  384  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  385  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  386  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  387  loss  tensor(0.1130, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  388  loss  tensor(0.1229, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  389  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  390  loss  tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  391  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  392  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  393  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  394  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  395  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  396  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  397  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  398  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  399  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  400  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  401  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  402  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  403  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  404  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  405  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  406  loss  tensor(0.1014, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  407  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  408  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  409  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  410  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  411  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  412  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  11  batch  413  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch [12/100], loss:40.2049\n",
      "epoch  12  batch  0  loss  tensor(0.0974, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  1  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  2  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  3  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  4  loss  tensor(0.1104, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  5  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  6  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  7  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  8  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  9  loss  tensor(0.1022, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  10  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  11  loss  tensor(0.1036, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  12  loss  tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  13  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  14  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  15  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  16  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  17  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  18  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  19  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  20  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  21  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  22  loss  tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  23  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  24  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  25  loss  tensor(0.1020, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  26  loss  tensor(0.1551, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  27  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  28  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  29  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  30  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  31  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  32  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  33  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  34  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  35  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  36  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  37  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  38  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  39  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  40  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  41  loss  tensor(0.1522, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  42  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  43  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  44  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  45  loss  tensor(0.1190, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  12  batch  46  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  47  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  48  loss  tensor(0.7485, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  49  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  50  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  51  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  52  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  53  loss  tensor(0.2788, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  54  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  55  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  56  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  57  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  58  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  59  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  60  loss  tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  61  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  62  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  63  loss  tensor(0.4160, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  64  loss  tensor(0.1400, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  65  loss  tensor(3.1218, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  66  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  67  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  68  loss  tensor(0.2001, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  69  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  70  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  71  loss  tensor(0.1340, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  72  loss  tensor(0.4568, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  73  loss  tensor(0.6294, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  74  loss  tensor(10.5965, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  75  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  76  loss  tensor(0.1186, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  77  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  78  loss  tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  79  loss  tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  80  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  81  loss  tensor(3.2025, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  82  loss  tensor(0.1033, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  83  loss  tensor(0.9479, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  84  loss  tensor(0.1213, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  85  loss  tensor(0.1062, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  86  loss  tensor(0.1098, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  87  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  88  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  89  loss  tensor(0.1617, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  90  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  91  loss  tensor(0.1136, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  92  loss  tensor(0.3944, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  93  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  94  loss  tensor(0.1722, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  95  loss  tensor(0.1334, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  96  loss  tensor(0.1277, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  97  loss  tensor(0.5269, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  98  loss  tensor(0.1025, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  99  loss  tensor(0.8570, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  100  loss  tensor(0.5184, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  101  loss  tensor(0.1238, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  102  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  103  loss  tensor(0.1365, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  104  loss  tensor(0.1461, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  105  loss  tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  106  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  107  loss  tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  108  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  109  loss  tensor(0.1716, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  110  loss  tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  111  loss  tensor(0.1121, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  112  loss  tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  113  loss  tensor(0.1500, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  114  loss  tensor(0.1737, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  115  loss  tensor(0.3555, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  116  loss  tensor(0.1003, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  117  loss  tensor(0.1758, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  118  loss  tensor(0.1444, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  119  loss  tensor(0.0962, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  120  loss  tensor(0.1390, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  121  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  122  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  123  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  124  loss  tensor(0.1248, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  125  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  126  loss  tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  127  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  128  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  129  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  130  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  131  loss  tensor(0.1061, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  132  loss  tensor(0.1065, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  133  loss  tensor(0.1080, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  134  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  135  loss  tensor(0.1354, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  136  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  137  loss  tensor(0.2112, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  138  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  139  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  140  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  141  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  142  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  143  loss  tensor(0.1078, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  144  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  145  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  146  loss  tensor(0.1323, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  147  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  148  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  149  loss  tensor(0.1176, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  150  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  151  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  152  loss  tensor(0.1115, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  153  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  154  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  155  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  156  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  157  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  158  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  159  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  160  loss  tensor(0.1819, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  161  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  162  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  163  loss  tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  164  loss  tensor(0.1279, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  165  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  166  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  167  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  12  batch  168  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  169  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  170  loss  tensor(0.0996, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  171  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  172  loss  tensor(0.1446, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  173  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  174  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  175  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  176  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  177  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  178  loss  tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  179  loss  tensor(0.1182, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  180  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  181  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  182  loss  tensor(0.3615, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  183  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  184  loss  tensor(0.0969, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  185  loss  tensor(0.1044, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  186  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  187  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  188  loss  tensor(0.2047, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  189  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  190  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  191  loss  tensor(0.1006, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  192  loss  tensor(0.1507, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  193  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  194  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  195  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  196  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  197  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  198  loss  tensor(0.1275, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  199  loss  tensor(0.1063, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  200  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  201  loss  tensor(0.1633, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  202  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  203  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  204  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  205  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  206  loss  tensor(0.1012, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  207  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  208  loss  tensor(0.1864, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  209  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  210  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  211  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  212  loss  tensor(0.1015, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  213  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  214  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  215  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  216  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  217  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  218  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  219  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  220  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  221  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  222  loss  tensor(0.2992, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  223  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  224  loss  tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  225  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  226  loss  tensor(0.1377, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  227  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  228  loss  tensor(0.0992, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  229  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  230  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  231  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  232  loss  tensor(0.1051, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  233  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  234  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  235  loss  tensor(0.1106, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  236  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  237  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  238  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  239  loss  tensor(0.1892, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  240  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  241  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  242  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  243  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  244  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  245  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  246  loss  tensor(0.1027, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  247  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  248  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  249  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  250  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  251  loss  tensor(0.1375, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  252  loss  tensor(0.1049, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  253  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  254  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  255  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  256  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  257  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  258  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  259  loss  tensor(0.2263, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  260  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  261  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  262  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  263  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  264  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  265  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  266  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  267  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  268  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  269  loss  tensor(0.1129, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  270  loss  tensor(0.1264, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  271  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  272  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  273  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  274  loss  tensor(0.1290, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  275  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  276  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  277  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  278  loss  tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  279  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  280  loss  tensor(0.1198, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  281  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  282  loss  tensor(0.1936, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  283  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  284  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  285  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  286  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  287  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  288  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  12  batch  289  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  290  loss  tensor(0.1278, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  291  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  292  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  293  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  294  loss  tensor(0.1015, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  295  loss  tensor(0.1017, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  296  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  297  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  298  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  299  loss  tensor(0.1015, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  300  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  301  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  302  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  303  loss  tensor(0.1028, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  304  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  305  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  306  loss  tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  307  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  308  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  309  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  310  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  311  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  312  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  313  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  314  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  315  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  316  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  317  loss  tensor(0.2398, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  318  loss  tensor(0.1386, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  319  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  320  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  321  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  322  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  323  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  324  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  325  loss  tensor(0.0962, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  326  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  327  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  328  loss  tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  329  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  330  loss  tensor(0.1113, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  331  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  332  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  333  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  334  loss  tensor(0.6166, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  335  loss  tensor(0.1143, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  336  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  337  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  338  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  339  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  340  loss  tensor(0.1044, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  341  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  342  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  343  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  344  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  345  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  346  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  347  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  348  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  349  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  350  loss  tensor(0.1204, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  351  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  352  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  353  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  354  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  355  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  356  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  357  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  358  loss  tensor(0.1029, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  359  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  360  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  361  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  362  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  363  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  364  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  365  loss  tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  366  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  367  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  368  loss  tensor(0.1778, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  369  loss  tensor(0.1140, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  370  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  371  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  372  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  373  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  374  loss  tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  375  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  376  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  377  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  378  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  379  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  380  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  381  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  382  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  383  loss  tensor(0.1055, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  384  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  385  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  386  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  387  loss  tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  388  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  389  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  390  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  391  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  392  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  393  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  394  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  395  loss  tensor(0.1223, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  396  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  397  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  398  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  399  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  400  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  401  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  402  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  403  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  404  loss  tensor(0.1595, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  405  loss  tensor(0.2460, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  406  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  407  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  408  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  409  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  12  batch  410  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  411  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  412  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  12  batch  413  loss  tensor(0.3343, grad_fn=<AddBackward0>)\n",
      "epoch [13/100], loss:62.8194\n",
      "epoch  13  batch  0  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  1  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  2  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  3  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  4  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  5  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  6  loss  tensor(0.1064, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  7  loss  tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  8  loss  tensor(0.1692, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  9  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  10  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  11  loss  tensor(0.1859, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  12  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  13  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  14  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  15  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  16  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  17  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  18  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  19  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  20  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  21  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  22  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  23  loss  tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  24  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  25  loss  tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  26  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  27  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  28  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  29  loss  tensor(0.1038, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  30  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  31  loss  tensor(0.1291, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  32  loss  tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  33  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  34  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  35  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  36  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  37  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  38  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  39  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  40  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  41  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  42  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  43  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  44  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  45  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  46  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  47  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  48  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  49  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  50  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  51  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  52  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  53  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  54  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  55  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  56  loss  tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  57  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  58  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  59  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  60  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  61  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  62  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  63  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  64  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  65  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  66  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  67  loss  tensor(0.0992, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  68  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  69  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  70  loss  tensor(0.0979, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  71  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  72  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  73  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  74  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  75  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  76  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  77  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  78  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  79  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  80  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  81  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  82  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  83  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  84  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  85  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  86  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  87  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  88  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  89  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  90  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  91  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  92  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  93  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  94  loss  tensor(0.4125, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  95  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  96  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  97  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  98  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  99  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  100  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  101  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  102  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  103  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  104  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  105  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  106  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  107  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  108  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  109  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  110  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  111  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  112  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  113  loss  tensor(0.1245, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  114  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  115  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  116  loss  tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  117  loss  tensor(0.0971, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  13  batch  118  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  119  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  120  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  121  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  122  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  123  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  124  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  125  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  126  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  127  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  128  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  129  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  130  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  131  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  132  loss  tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  133  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  134  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  135  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  136  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  137  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  138  loss  tensor(0.1909, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  139  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  140  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  141  loss  tensor(0.1061, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  142  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  143  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  144  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  145  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  146  loss  tensor(0.1361, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  147  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  148  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  149  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  150  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  151  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  152  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  153  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  154  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  155  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  156  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  157  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  158  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  159  loss  tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  160  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  161  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  162  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  163  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  164  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  165  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  166  loss  tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  167  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  168  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  169  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  170  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  171  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  172  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  173  loss  tensor(0.1125, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  174  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  175  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  176  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  177  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  178  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  179  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  180  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  181  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  182  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  183  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  184  loss  tensor(0.2467, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  185  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  186  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  187  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  188  loss  tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  189  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  190  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  191  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  192  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  193  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  194  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  195  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  196  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  197  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  198  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  199  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  200  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  201  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  202  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  203  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  204  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  205  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  206  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  207  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  208  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  209  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  210  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  211  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  212  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  213  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  214  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  215  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  216  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  217  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  218  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  219  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  220  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  221  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  222  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  223  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  224  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  225  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  226  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  227  loss  tensor(0.1056, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  228  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  229  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  230  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  231  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  232  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  233  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  234  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  235  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  236  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  237  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  238  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  13  batch  239  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  240  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  241  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  242  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  243  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  244  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  245  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  246  loss  tensor(0.2409, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  247  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  248  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  249  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  250  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  251  loss  tensor(0.1009, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  252  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  253  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  254  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  255  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  256  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  257  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  258  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  259  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  260  loss  tensor(0.1052, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  261  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  262  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  263  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  264  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  265  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  266  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  267  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  268  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  269  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  270  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  271  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  272  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  273  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  274  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  275  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  276  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  277  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  278  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  279  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  280  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  281  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  282  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  283  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  284  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  285  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  286  loss  tensor(0.0989, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  287  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  288  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  289  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  290  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  291  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  292  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  293  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  294  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  295  loss  tensor(0.1538, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  296  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  297  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  298  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  299  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  300  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  301  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  302  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  303  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  304  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  305  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  306  loss  tensor(0.1883, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  307  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  308  loss  tensor(0.0996, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  309  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  310  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  311  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  312  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  313  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  314  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  315  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  316  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  317  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  318  loss  tensor(0.3130, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  319  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  320  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  321  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  322  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  323  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  324  loss  tensor(0.3953, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  325  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  326  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  327  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  328  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  329  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  330  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  331  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  332  loss  tensor(0.5728, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  333  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  334  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  335  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  336  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  337  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  338  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  339  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  340  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  341  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  342  loss  tensor(0.1350, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  343  loss  tensor(0.1011, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  344  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  345  loss  tensor(0.1396, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  346  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  347  loss  tensor(0.8307, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  348  loss  tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  349  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  350  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  351  loss  tensor(0.0975, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  352  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  353  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  354  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  355  loss  tensor(1.0128, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  356  loss  tensor(0.1051, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  357  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  358  loss  tensor(0.3796, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  359  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  13  batch  360  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  361  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  362  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  363  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  364  loss  tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  365  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  366  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  367  loss  tensor(0.0980, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  368  loss  tensor(0.1155, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  369  loss  tensor(0.1568, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  370  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  371  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  372  loss  tensor(1.8465, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  373  loss  tensor(0.1732, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  374  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  375  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  376  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  377  loss  tensor(0.1131, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  378  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  379  loss  tensor(0.1087, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  380  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  381  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  382  loss  tensor(0.1692, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  383  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  384  loss  tensor(0.1601, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  385  loss  tensor(0.1550, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  386  loss  tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  387  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  388  loss  tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  389  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  390  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  391  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  392  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  393  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  394  loss  tensor(0.1183, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  395  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  396  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  397  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  398  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  399  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  400  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  401  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  402  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  403  loss  tensor(0.1289, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  404  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  405  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  406  loss  tensor(0.1292, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  407  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  408  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  409  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  410  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  411  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  412  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  13  batch  413  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch [14/100], loss:42.0302\n",
      "epoch  14  batch  0  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  1  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  2  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  3  loss  tensor(0.1260, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  4  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  5  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  6  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  7  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  8  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  9  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  10  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  11  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  12  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  13  loss  tensor(0.2093, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  14  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  15  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  16  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  17  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  18  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  19  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  20  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  21  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  22  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  23  loss  tensor(0.1523, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  24  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  25  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  26  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  27  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  28  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  29  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  30  loss  tensor(0.1695, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  31  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  32  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  33  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  34  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  35  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  36  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  37  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  38  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  39  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  40  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  41  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  42  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  43  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  44  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  45  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  46  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  47  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  48  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  49  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  50  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  51  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  52  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  53  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  54  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  55  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  56  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  57  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  58  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  59  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  60  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  61  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  62  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  63  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  64  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  65  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  66  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  67  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  14  batch  68  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  69  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  70  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  71  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  72  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  73  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  74  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  75  loss  tensor(0.0987, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  76  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  77  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  78  loss  tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  79  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  80  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  81  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  82  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  83  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  84  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  85  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  86  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  87  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  88  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  89  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  90  loss  tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  91  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  92  loss  tensor(0.1127, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  93  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  94  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  95  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  96  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  97  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  98  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  99  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  100  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  101  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  102  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  103  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  104  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  105  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  106  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  107  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  108  loss  tensor(0.1867, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  109  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  110  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  111  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  112  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  113  loss  tensor(0.0989, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  114  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  115  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  116  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  117  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  118  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  119  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  120  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  121  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  122  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  123  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  124  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  125  loss  tensor(0.0974, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  126  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  127  loss  tensor(0.1028, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  128  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  129  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  130  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  131  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  132  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  133  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  134  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  135  loss  tensor(0.1046, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  136  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  137  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  138  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  139  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  140  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  141  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  142  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  143  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  144  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  145  loss  tensor(0.0982, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  146  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  147  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  148  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  149  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  150  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  151  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  152  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  153  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  154  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  155  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  156  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  157  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  158  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  159  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  160  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  161  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  162  loss  tensor(0.1027, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  163  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  164  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  165  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  166  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  167  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  168  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  169  loss  tensor(0.2234, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  170  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  171  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  172  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  173  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  174  loss  tensor(1.0885, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  175  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  176  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  177  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  178  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  179  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  180  loss  tensor(0.1111, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  181  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  182  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  183  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  184  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  185  loss  tensor(0.1153, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  186  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  187  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  188  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  14  batch  189  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  190  loss  tensor(0.1814, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  191  loss  tensor(0.1944, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  192  loss  tensor(0.0971, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  193  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  194  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  195  loss  tensor(0.1013, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  196  loss  tensor(0.1294, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  197  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  198  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  199  loss  tensor(0.1063, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  200  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  201  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  202  loss  tensor(0.0980, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  203  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  204  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  205  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  206  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  207  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  208  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  209  loss  tensor(0.1792, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  210  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  211  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  212  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  213  loss  tensor(0.1104, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  214  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  215  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  216  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  217  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  218  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  219  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  220  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  221  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  222  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  223  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  224  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  225  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  226  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  227  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  228  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  229  loss  tensor(0.1329, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  230  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  231  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  232  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  233  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  234  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  235  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  236  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  237  loss  tensor(0.1092, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  238  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  239  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  240  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  241  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  242  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  243  loss  tensor(0.0996, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  244  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  245  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  246  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  247  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  248  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  249  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  250  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  251  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  252  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  253  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  254  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  255  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  256  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  257  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  258  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  259  loss  tensor(0.1026, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  260  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  261  loss  tensor(0.1265, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  262  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  263  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  264  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  265  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  266  loss  tensor(0.1113, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  267  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  268  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  269  loss  tensor(0.2505, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  270  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  271  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  272  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  273  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  274  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  275  loss  tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  276  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  277  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  278  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  279  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  280  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  281  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  282  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  283  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  284  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  285  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  286  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  287  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  288  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  289  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  290  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  291  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  292  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  293  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  294  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  295  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  296  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  297  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  298  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  299  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  300  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  301  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  302  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  303  loss  tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  304  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  305  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  306  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  307  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  308  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  309  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  14  batch  310  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  311  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  312  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  313  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  314  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  315  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  316  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  317  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  318  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  319  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  320  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  321  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  322  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  323  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  324  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  325  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  326  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  327  loss  tensor(0.1775, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  328  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  329  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  330  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  331  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  332  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  333  loss  tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  334  loss  tensor(0.0969, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  335  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  336  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  337  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  338  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  339  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  340  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  341  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  342  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  343  loss  tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  344  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  345  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  346  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  347  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  348  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  349  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  350  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  351  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  352  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  353  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  354  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  355  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  356  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  357  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  358  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  359  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  360  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  361  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  362  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  363  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  364  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  365  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  366  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  367  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  368  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  369  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  370  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  371  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  372  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  373  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  374  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  375  loss  tensor(0.0675, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  376  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  377  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  378  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  379  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  380  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  381  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  382  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  383  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  384  loss  tensor(0.1376, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  385  loss  tensor(0.1008, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  386  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  387  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  388  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  389  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  390  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  391  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  392  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  393  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  394  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  395  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  396  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  397  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  398  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  399  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  400  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  401  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  402  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  403  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  404  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  405  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  406  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  407  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  408  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  409  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  410  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  411  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  412  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  14  batch  413  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch [15/100], loss:37.1893\n",
      "epoch  15  batch  0  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  1  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  2  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  3  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  4  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  5  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  6  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  7  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  8  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  9  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  10  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  11  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  12  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  13  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  14  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  15  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  16  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  15  batch  17  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  18  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  19  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  20  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  21  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  22  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  23  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  24  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  25  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  26  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  27  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  28  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  29  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  30  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  31  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  32  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  33  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  34  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  35  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  36  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  37  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  38  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  39  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  40  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  41  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  42  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  43  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  44  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  45  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  46  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  47  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  48  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  49  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  50  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  51  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  52  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  53  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  54  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  55  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  56  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  57  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  58  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  59  loss  tensor(0.1853, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  60  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  61  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  62  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  63  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  64  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  65  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  66  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  67  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  68  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  69  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  70  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  71  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  72  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  73  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  74  loss  tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  75  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  76  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  77  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  78  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  79  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  80  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  81  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  82  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  83  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  84  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  85  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  86  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  87  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  88  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  89  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  90  loss  tensor(0.3040, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  91  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  92  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  93  loss  tensor(0.1031, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  94  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  95  loss  tensor(0.0975, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  96  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  97  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  98  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  99  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  100  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  101  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  102  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  103  loss  tensor(0.1100, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  104  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  105  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  106  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  107  loss  tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  108  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  109  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  110  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  111  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  112  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  113  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  114  loss  tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  115  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  116  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  117  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  118  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  119  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  120  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  121  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  122  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  123  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  124  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  125  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  126  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  127  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  128  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  129  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  130  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  131  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  132  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  133  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  134  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  135  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  136  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  137  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  138  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  15  batch  139  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  140  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  141  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  142  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  143  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  144  loss  tensor(0.0982, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  145  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  146  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  147  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  148  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  149  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  150  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  151  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  152  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  153  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  154  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  155  loss  tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  156  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  157  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  158  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  159  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  160  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  161  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  162  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  163  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  164  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  165  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  166  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  167  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  168  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  169  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  170  loss  tensor(0.1015, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  171  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  172  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  173  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  174  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  175  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  176  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  177  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  178  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  179  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  180  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  181  loss  tensor(0.1044, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  182  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  183  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  184  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  185  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  186  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  187  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  188  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  189  loss  tensor(0.1223, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  190  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  191  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  192  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  193  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  194  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  195  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  196  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  197  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  198  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  199  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  200  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  201  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  202  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  203  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  204  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  205  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  206  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  207  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  208  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  209  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  210  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  211  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  212  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  213  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  214  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  215  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  216  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  217  loss  tensor(0.1054, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  218  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  219  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  220  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  221  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  222  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  223  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  224  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  225  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  226  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  227  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  228  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  229  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  230  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  231  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  232  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  233  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  234  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  235  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  236  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  237  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  238  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  239  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  240  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  241  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  242  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  243  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  244  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  245  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  246  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  247  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  248  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  249  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  250  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  251  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  252  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  253  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  254  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  255  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  256  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  257  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  258  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  259  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  15  batch  260  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  261  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  262  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  263  loss  tensor(0.1140, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  264  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  265  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  266  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  267  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  268  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  269  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  270  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  271  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  272  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  273  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  274  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  275  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  276  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  277  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  278  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  279  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  280  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  281  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  282  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  283  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  284  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  285  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  286  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  287  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  288  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  289  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  290  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  291  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  292  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  293  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  294  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  295  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  296  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  297  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  298  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  299  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  300  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  301  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  302  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  303  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  304  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  305  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  306  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  307  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  308  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  309  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  310  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  311  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  312  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  313  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  314  loss  tensor(0.0987, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  315  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  316  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  317  loss  tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  318  loss  tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  319  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  320  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  321  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  322  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  323  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  324  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  325  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  326  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  327  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  328  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  329  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  330  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  331  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  332  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  333  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  334  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  335  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  336  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  337  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  338  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  339  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  340  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  341  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  342  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  343  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  344  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  345  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  346  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  347  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  348  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  349  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  350  loss  tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  351  loss  tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  352  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  353  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  354  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  355  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  356  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  357  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  358  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  359  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  360  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  361  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  362  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  363  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  364  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  365  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  366  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  367  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  368  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  369  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  370  loss  tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  371  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  372  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  373  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  374  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  375  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  376  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  377  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  378  loss  tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  379  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  380  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  15  batch  381  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  382  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  383  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  384  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  385  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  386  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  387  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  388  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  389  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  390  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  391  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  392  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  393  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  394  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  395  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  396  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  397  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  398  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  399  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  400  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  401  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  402  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  403  loss  tensor(0.1016, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  404  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  405  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  406  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  407  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  408  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  409  loss  tensor(0.1036, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  410  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  411  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  412  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  15  batch  413  loss  tensor(0.1344, grad_fn=<AddBackward0>)\n",
      "epoch [16/100], loss:34.7105\n",
      "epoch  16  batch  0  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  1  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  2  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  3  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  4  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  5  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  6  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  7  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  8  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  9  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  10  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  11  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  12  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  13  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  14  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  15  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  16  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  17  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  18  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  19  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  20  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  21  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  22  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  23  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  24  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  25  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  26  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  27  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  28  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  29  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  30  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  31  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  32  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  33  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  34  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  35  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  36  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  37  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  38  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  39  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  40  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  41  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  42  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  43  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  44  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  45  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  46  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  47  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  48  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  49  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  50  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  51  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  52  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  53  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  54  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  55  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  56  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  57  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  58  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  59  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  60  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  61  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  62  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  63  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  64  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  65  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  66  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  67  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  68  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  69  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  70  loss  tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  71  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  72  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  73  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  74  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  75  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  76  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  77  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  78  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  79  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  80  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  81  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  82  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  83  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  84  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  85  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  86  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  87  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  88  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  16  batch  89  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  90  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  91  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  92  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  93  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  94  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  95  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  96  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  97  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  98  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  99  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  100  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  101  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  102  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  103  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  104  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  105  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  106  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  107  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  108  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  109  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  110  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  111  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  112  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  113  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  114  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  115  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  116  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  117  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  118  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  119  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  120  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  121  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  122  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  123  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  124  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  125  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  126  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  127  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  128  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  129  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  130  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  131  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  132  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  133  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  134  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  135  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  136  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  137  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  138  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  139  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  140  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  141  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  142  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  143  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  144  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  145  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  146  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  147  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  148  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  149  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  150  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  151  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  152  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  153  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  154  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  155  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  156  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  157  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  158  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  159  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  160  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  161  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  162  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  163  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  164  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  165  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  166  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  167  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  168  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  169  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  170  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  171  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  172  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  173  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  174  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  175  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  176  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  177  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  178  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  179  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  180  loss  tensor(0.1031, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  181  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  182  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  183  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  184  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  185  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  186  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  187  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  188  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  189  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  190  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  191  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  192  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  193  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  194  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  195  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  196  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  197  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  198  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  199  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  200  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  201  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  202  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  203  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  204  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  205  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  206  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  207  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  208  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  209  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  16  batch  210  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  211  loss  tensor(0.1111, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  212  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  213  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  214  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  215  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  216  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  217  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  218  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  219  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  220  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  221  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  222  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  223  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  224  loss  tensor(0.0982, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  225  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  226  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  227  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  228  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  229  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  230  loss  tensor(0.1155, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  231  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  232  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  233  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  234  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  235  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  236  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  237  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  238  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  239  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  240  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  241  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  242  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  243  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  244  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  245  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  246  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  247  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  248  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  249  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  250  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  251  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  252  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  253  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  254  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  255  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  256  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  257  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  258  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  259  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  260  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  261  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  262  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  263  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  264  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  265  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  266  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  267  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  268  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  269  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  270  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  271  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  272  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  273  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  274  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  275  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  276  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  277  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  278  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  279  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  280  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  281  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  282  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  283  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  284  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  285  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  286  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  287  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  288  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  289  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  290  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  291  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  292  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  293  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  294  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  295  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  296  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  297  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  298  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  299  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  300  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  301  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  302  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  303  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  304  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  305  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  306  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  307  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  308  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  309  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  310  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  311  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  312  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  313  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  314  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  315  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  316  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  317  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  318  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  319  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  320  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  321  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  322  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  323  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  324  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  325  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  326  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  327  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  328  loss  tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  329  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  330  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  16  batch  331  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  332  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  333  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  334  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  335  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  336  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  337  loss  tensor(0.1088, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  338  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  339  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  340  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  341  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  342  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  343  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  344  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  345  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  346  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  347  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  348  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  349  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  350  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  351  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  352  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  353  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  354  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  355  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  356  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  357  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  358  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  359  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  360  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  361  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  362  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  363  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  364  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  365  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  366  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  367  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  368  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  369  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  370  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  371  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  372  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  373  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  374  loss  tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  375  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  376  loss  tensor(0.1230, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  377  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  378  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  379  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  380  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  381  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  382  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  383  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  384  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  385  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  386  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  387  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  388  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  389  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  390  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  391  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  392  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  393  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  394  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  395  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  396  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  397  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  398  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  399  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  400  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  401  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  402  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  403  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  404  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  405  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  406  loss  tensor(0.1510, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  407  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  408  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  409  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  410  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  411  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  412  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  16  batch  413  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch [17/100], loss:34.1080\n",
      "epoch  17  batch  0  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  1  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  2  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  3  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  4  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  5  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  6  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  7  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  8  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  9  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  10  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  11  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  12  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  13  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  14  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  15  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  16  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  17  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  18  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  19  loss  tensor(0.0998, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  20  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  21  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  22  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  23  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  24  loss  tensor(0.1235, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  25  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  26  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  27  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  28  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  29  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  30  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  31  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  32  loss  tensor(0.0997, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  33  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  34  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  35  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  36  loss  tensor(0.1125, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  37  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  17  batch  38  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  39  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  40  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  41  loss  tensor(0.1015, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  42  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  43  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  44  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  45  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  46  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  47  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  48  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  49  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  50  loss  tensor(0.0974, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  51  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  52  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  53  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  54  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  55  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  56  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  57  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  58  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  59  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  60  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  61  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  62  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  63  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  64  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  65  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  66  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  67  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  68  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  69  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  70  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  71  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  72  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  73  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  74  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  75  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  76  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  77  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  78  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  79  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  80  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  81  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  82  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  83  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  84  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  85  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  86  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  87  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  88  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  89  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  90  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  91  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  92  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  93  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  94  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  95  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  96  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  97  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  98  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  99  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  100  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  101  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  102  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  103  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  104  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  105  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  106  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  107  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  108  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  109  loss  tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  110  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  111  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  112  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  113  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  114  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  115  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  116  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  117  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  118  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  119  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  120  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  121  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  122  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  123  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  124  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  125  loss  tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  126  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  127  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  128  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  129  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  130  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  131  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  132  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  133  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  134  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  135  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  136  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  137  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  138  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  139  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  140  loss  tensor(0.0670, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  141  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  142  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  143  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  144  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  145  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  146  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  147  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  148  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  149  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  150  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  151  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  152  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  153  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  154  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  155  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  156  loss  tensor(0.0975, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  157  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  158  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  159  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  17  batch  160  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  161  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  162  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  163  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  164  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  165  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  166  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  167  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  168  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  169  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  170  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  171  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  172  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  173  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  174  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  175  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  176  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  177  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  178  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  179  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  180  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  181  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  182  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  183  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  184  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  185  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  186  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  187  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  188  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  189  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  190  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  191  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  192  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  193  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  194  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  195  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  196  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  197  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  198  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  199  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  200  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  201  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  202  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  203  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  204  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  205  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  206  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  207  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  208  loss  tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  209  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  210  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  211  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  212  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  213  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  214  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  215  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  216  loss  tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  217  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  218  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  219  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  220  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  221  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  222  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  223  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  224  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  225  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  226  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  227  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  228  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  229  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  230  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  231  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  232  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  233  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  234  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  235  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  236  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  237  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  238  loss  tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  239  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  240  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  241  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  242  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  243  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  244  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  245  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  246  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  247  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  248  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  249  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  250  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  251  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  252  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  253  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  254  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  255  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  256  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  257  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  258  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  259  loss  tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  260  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  261  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  262  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  263  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  264  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  265  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  266  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  267  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  268  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  269  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  270  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  271  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  272  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  273  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  274  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  275  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  276  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  277  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  278  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  279  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  280  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  17  batch  281  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  282  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  283  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  284  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  285  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  286  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  287  loss  tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  288  loss  tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  289  loss  tensor(0.0962, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  290  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  291  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  292  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  293  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  294  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  295  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  296  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  297  loss  tensor(0.1306, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  298  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  299  loss  tensor(0.0675, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  300  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  301  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  302  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  303  loss  tensor(0.0969, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  304  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  305  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  306  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  307  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  308  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  309  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  310  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  311  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  312  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  313  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  314  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  315  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  316  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  317  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  318  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  319  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  320  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  321  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  322  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  323  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  324  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  325  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  326  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  327  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  328  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  329  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  330  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  331  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  332  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  333  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  334  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  335  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  336  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  337  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  338  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  339  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  340  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  341  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  342  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  343  loss  tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  344  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  345  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  346  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  347  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  348  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  349  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  350  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  351  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  352  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  353  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  354  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  355  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  356  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  357  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  358  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  359  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  360  loss  tensor(0.1020, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  361  loss  tensor(0.0662, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  362  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  363  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  364  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  365  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  366  loss  tensor(0.1032, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  367  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  368  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  369  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  370  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  371  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  372  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  373  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  374  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  375  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  376  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  377  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  378  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  379  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  380  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  381  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  382  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  383  loss  tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  384  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  385  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  386  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  387  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  388  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  389  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  390  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  391  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  392  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  393  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  394  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  395  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  396  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  397  loss  tensor(0.1838, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  398  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  399  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  400  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  401  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  17  batch  402  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  403  loss  tensor(0.1117, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  404  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  405  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  406  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  407  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  408  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  409  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  410  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  411  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  412  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  17  batch  413  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch [18/100], loss:34.0384\n",
      "epoch  18  batch  0  loss  tensor(0.6009, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  1  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  2  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  3  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  4  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  5  loss  tensor(0.3346, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  6  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  7  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  8  loss  tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  9  loss  tensor(0.3300, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  10  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  11  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  12  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  13  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  14  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  15  loss  tensor(0.4135, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  16  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  17  loss  tensor(0.3427, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  18  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  19  loss  tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  20  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  21  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  22  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  23  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  24  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  25  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  26  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  27  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  28  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  29  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  30  loss  tensor(0.1020, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  31  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  32  loss  tensor(0.1086, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  33  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  34  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  35  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  36  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  37  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  38  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  39  loss  tensor(0.1131, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  40  loss  tensor(0.1064, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  41  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  42  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  43  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  44  loss  tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  45  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  46  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  47  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  48  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  49  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  50  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  51  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  52  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  53  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  54  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  55  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  56  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  57  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  58  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  59  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  60  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  61  loss  tensor(0.0656, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  62  loss  tensor(0.1803, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  63  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  64  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  65  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  66  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  67  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  68  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  69  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  70  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  71  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  72  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  73  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  74  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  75  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  76  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  77  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  78  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  79  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  80  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  81  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  82  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  83  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  84  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  85  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  86  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  87  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  88  loss  tensor(0.1077, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  89  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  90  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  91  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  92  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  93  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  94  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  95  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  96  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  97  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  98  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  99  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  100  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  101  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  102  loss  tensor(0.1040, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  103  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  104  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  105  loss  tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  106  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  107  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  108  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  109  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  18  batch  110  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  111  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  112  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  113  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  114  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  115  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  116  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  117  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  118  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  119  loss  tensor(0.0679, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  120  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  121  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  122  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  123  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  124  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  125  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  126  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  127  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  128  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  129  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  130  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  131  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  132  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  133  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  134  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  135  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  136  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  137  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  138  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  139  loss  tensor(0.1402, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  140  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  141  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  142  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  143  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  144  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  145  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  146  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  147  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  148  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  149  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  150  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  151  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  152  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  153  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  154  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  155  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  156  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  157  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  158  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  159  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  160  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  161  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  162  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  163  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  164  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  165  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  166  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  167  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  168  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  169  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  170  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  171  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  172  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  173  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  174  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  175  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  176  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  177  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  178  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  179  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  180  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  181  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  182  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  183  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  184  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  185  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  186  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  187  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  188  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  189  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  190  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  191  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  192  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  193  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  194  loss  tensor(0.1577, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  195  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  196  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  197  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  198  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  199  loss  tensor(0.0996, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  200  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  201  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  202  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  203  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  204  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  205  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  206  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  207  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  208  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  209  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  210  loss  tensor(0.1889, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  211  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  212  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  213  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  214  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  215  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  216  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  217  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  218  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  219  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  220  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  221  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  222  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  223  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  224  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  225  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  226  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  227  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  228  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  229  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  230  loss  tensor(0.2013, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  18  batch  231  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  232  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  233  loss  tensor(0.1084, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  234  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  235  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  236  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  237  loss  tensor(0.5398, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  238  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  239  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  240  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  241  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  242  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  243  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  244  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  245  loss  tensor(0.1154, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  246  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  247  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  248  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  249  loss  tensor(0.1067, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  250  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  251  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  252  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  253  loss  tensor(0.5257, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  254  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  255  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  256  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  257  loss  tensor(0.1824, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  258  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  259  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  260  loss  tensor(0.2308, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  261  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  262  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  263  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  264  loss  tensor(0.1432, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  265  loss  tensor(0.1256, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  266  loss  tensor(0.1258, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  267  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  268  loss  tensor(0.2890, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  269  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  270  loss  tensor(0.1524, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  271  loss  tensor(0.2650, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  272  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  273  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  274  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  275  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  276  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  277  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  278  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  279  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  280  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  281  loss  tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  282  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  283  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  284  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  285  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  286  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  287  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  288  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  289  loss  tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  290  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  291  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  292  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  293  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  294  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  295  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  296  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  297  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  298  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  299  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  300  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  301  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  302  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  303  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  304  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  305  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  306  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  307  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  308  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  309  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  310  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  311  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  312  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  313  loss  tensor(0.1029, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  314  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  315  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  316  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  317  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  318  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  319  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  320  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  321  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  322  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  323  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  324  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  325  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  326  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  327  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  328  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  329  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  330  loss  tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  331  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  332  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  333  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  334  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  335  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  336  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  337  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  338  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  339  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  340  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  341  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  342  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  343  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  344  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  345  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  346  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  347  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  348  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  349  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  350  loss  tensor(0.1192, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  351  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  18  batch  352  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  353  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  354  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  355  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  356  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  357  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  358  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  359  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  360  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  361  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  362  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  363  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  364  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  365  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  366  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  367  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  368  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  369  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  370  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  371  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  372  loss  tensor(0.1517, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  373  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  374  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  375  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  376  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  377  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  378  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  379  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  380  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  381  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  382  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  383  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  384  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  385  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  386  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  387  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  388  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  389  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  390  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  391  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  392  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  393  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  394  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  395  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  396  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  397  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  398  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  399  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  400  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  401  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  402  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  403  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  404  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  405  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  406  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  407  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  408  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  409  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  410  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  411  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  412  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  18  batch  413  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch [19/100], loss:38.1393\n",
      "epoch  19  batch  0  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  1  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  2  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  3  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  4  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  5  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  6  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  7  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  8  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  9  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  10  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  11  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  12  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  13  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  14  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  15  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  16  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  17  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  18  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  19  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  20  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  21  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  22  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  23  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  24  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  25  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  26  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  27  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  28  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  29  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  30  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  31  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  32  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  33  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  34  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  35  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  36  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  37  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  38  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  39  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  40  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  41  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  42  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  43  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  44  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  45  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  46  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  47  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  48  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  49  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  50  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  51  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  52  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  53  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  54  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  55  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  56  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  57  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  58  loss  tensor(0.1033, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  59  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  19  batch  60  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  61  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  62  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  63  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  64  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  65  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  66  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  67  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  68  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  69  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  70  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  71  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  72  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  73  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  74  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  75  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  76  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  77  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  78  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  79  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  80  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  81  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  82  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  83  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  84  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  85  loss  tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  86  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  87  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  88  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  89  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  90  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  91  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  92  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  93  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  94  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  95  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  96  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  97  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  98  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  99  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  100  loss  tensor(0.1013, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  101  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  102  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  103  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  104  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  105  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  106  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  107  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  108  loss  tensor(0.1187, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  109  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  110  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  111  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  112  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  113  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  114  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  115  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  116  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  117  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  118  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  119  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  120  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  121  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  122  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  123  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  124  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  125  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  126  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  127  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  128  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  129  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  130  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  131  loss  tensor(0.0968, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  132  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  133  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  134  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  135  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  136  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  137  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  138  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  139  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  140  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  141  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  142  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  143  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  144  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  145  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  146  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  147  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  148  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  149  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  150  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  151  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  152  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  153  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  154  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  155  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  156  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  157  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  158  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  159  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  160  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  161  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  162  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  163  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  164  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  165  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  166  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  167  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  168  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  169  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  170  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  171  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  172  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  173  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  174  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  175  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  176  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  177  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  178  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  179  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  180  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  181  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  19  batch  182  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  183  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  184  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  185  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  186  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  187  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  188  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  189  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  190  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  191  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  192  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  193  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  194  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  195  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  196  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  197  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  198  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  199  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  200  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  201  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  202  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  203  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  204  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  205  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  206  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  207  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  208  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  209  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  210  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  211  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  212  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  213  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  214  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  215  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  216  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  217  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  218  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  219  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  220  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  221  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  222  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  223  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  224  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  225  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  226  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  227  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  228  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  229  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  230  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  231  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  232  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  233  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  234  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  235  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  236  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  237  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  238  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  239  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  240  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  241  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  242  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  243  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  244  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  245  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  246  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  247  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  248  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  249  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  250  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  251  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  252  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  253  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  254  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  255  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  256  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  257  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  258  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  259  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  260  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  261  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  262  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  263  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  264  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  265  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  266  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  267  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  268  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  269  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  270  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  271  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  272  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  273  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  274  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  275  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  276  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  277  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  278  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  279  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  280  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  281  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  282  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  283  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  284  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  285  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  286  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  287  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  288  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  289  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  290  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  291  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  292  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  293  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  294  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  295  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  296  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  297  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  298  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  299  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  300  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  301  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  302  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  19  batch  303  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  304  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  305  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  306  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  307  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  308  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  309  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  310  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  311  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  312  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  313  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  314  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  315  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  316  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  317  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  318  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  319  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  320  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  321  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  322  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  323  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  324  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  325  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  326  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  327  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  328  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  329  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  330  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  331  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  332  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  333  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  334  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  335  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  336  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  337  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  338  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  339  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  340  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  341  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  342  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  343  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  344  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  345  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  346  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  347  loss  tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  348  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  349  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  350  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  351  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  352  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  353  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  354  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  355  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  356  loss  tensor(0.0963, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  357  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  358  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  359  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  360  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  361  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  362  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  363  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  364  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  365  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  366  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  367  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  368  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  369  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  370  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  371  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  372  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  373  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  374  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  375  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  376  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  377  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  378  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  379  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  380  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  381  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  382  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  383  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  384  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  385  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  386  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  387  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  388  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  389  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  390  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  391  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  392  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  393  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  394  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  395  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  396  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  397  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  398  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  399  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  400  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  401  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  402  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  403  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  404  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  405  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  406  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  407  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  408  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  409  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  410  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  411  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  412  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  19  batch  413  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch [20/100], loss:33.5192\n",
      "epoch  20  batch  0  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  1  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  2  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  3  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  4  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  5  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  6  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  7  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  8  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  9  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  20  batch  10  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  11  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  12  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  13  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  14  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  15  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  16  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  17  loss  tensor(0.0693, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  18  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  19  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  20  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  21  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  22  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  23  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  24  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  25  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  26  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  27  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  28  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  29  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  30  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  31  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  32  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  33  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  34  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  35  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  36  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  37  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  38  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  39  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  40  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  41  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  42  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  43  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  44  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  45  loss  tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  46  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  47  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  48  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  49  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  50  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  51  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  52  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  53  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  54  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  55  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  56  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  57  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  58  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  59  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  60  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  61  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  62  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  63  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  64  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  65  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  66  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  67  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  68  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  69  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  70  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  71  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  72  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  73  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  74  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  75  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  76  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  77  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  78  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  79  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  80  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  81  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  82  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  83  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  84  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  85  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  86  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  87  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  88  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  89  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  90  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  91  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  92  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  93  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  94  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  95  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  96  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  97  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  98  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  99  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  100  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  101  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  102  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  103  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  104  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  105  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  106  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  107  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  108  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  109  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  110  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  111  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  112  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  113  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  114  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  115  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  116  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  117  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  118  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  119  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  120  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  121  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  122  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  123  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  124  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  125  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  126  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  127  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  128  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  129  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  130  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  131  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  20  batch  132  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  133  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  134  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  135  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  136  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  137  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  138  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  139  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  140  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  141  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  142  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  143  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  144  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  145  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  146  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  147  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  148  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  149  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  150  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  151  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  152  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  153  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  154  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  155  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  156  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  157  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  158  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  159  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  160  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  161  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  162  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  163  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  164  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  165  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  166  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  167  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  168  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  169  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  170  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  171  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  172  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  173  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  174  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  175  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  176  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  177  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  178  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  179  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  180  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  181  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  182  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  183  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  184  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  185  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  186  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  187  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  188  loss  tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  189  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  190  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  191  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  192  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  193  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  194  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  195  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  196  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  197  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  198  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  199  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  200  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  201  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  202  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  203  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  204  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  205  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  206  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  207  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  208  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  209  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  210  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  211  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  212  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  213  loss  tensor(0.1055, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  214  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  215  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  216  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  217  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  218  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  219  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  220  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  221  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  222  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  223  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  224  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  225  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  226  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  227  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  228  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  229  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  230  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  231  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  232  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  233  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  234  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  235  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  236  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  237  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  238  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  239  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  240  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  241  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  242  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  243  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  244  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  245  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  246  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  247  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  248  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  249  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  250  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  251  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  252  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  20  batch  253  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  254  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  255  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  256  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  257  loss  tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  258  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  259  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  260  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  261  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  262  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  263  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  264  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  265  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  266  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  267  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  268  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  269  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  270  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  271  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  272  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  273  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  274  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  275  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  276  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  277  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  278  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  279  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  280  loss  tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  281  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  282  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  283  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  284  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  285  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  286  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  287  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  288  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  289  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  290  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  291  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  292  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  293  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  294  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  295  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  296  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  297  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  298  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  299  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  300  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  301  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  302  loss  tensor(0.0678, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  303  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  304  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  305  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  306  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  307  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  308  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  309  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  310  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  311  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  312  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  313  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  314  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  315  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  316  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  317  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  318  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  319  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  320  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  321  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  322  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  323  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  324  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  325  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  326  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  327  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  328  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  329  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  330  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  331  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  332  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  333  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  334  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  335  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  336  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  337  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  338  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  339  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  340  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  341  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  342  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  343  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  344  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  345  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  346  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  347  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  348  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  349  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  350  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  351  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  352  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  353  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  354  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  355  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  356  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  357  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  358  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  359  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  360  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  361  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  362  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  363  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  364  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  365  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  366  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  367  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  368  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  369  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  370  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  371  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  372  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  373  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  20  batch  374  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  375  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  376  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  377  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  378  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  379  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  380  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  381  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  382  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  383  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  384  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  385  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  386  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  387  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  388  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  389  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  390  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  391  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  392  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  393  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  394  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  395  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  396  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  397  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  398  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  399  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  400  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  401  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  402  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  403  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  404  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  405  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  406  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  407  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  408  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  409  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  410  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  411  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  412  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  20  batch  413  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch [21/100], loss:33.4326\n",
      "epoch  21  batch  0  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  1  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  2  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  3  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  4  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  5  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  6  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  7  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  8  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  9  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  10  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  11  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  12  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  13  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  14  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  15  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  16  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  17  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  18  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  19  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  20  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  21  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  22  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  23  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  24  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  25  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  26  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  27  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  28  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  29  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  30  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  31  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  32  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  33  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  34  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  35  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  36  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  37  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  38  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  39  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  40  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  41  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  42  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  43  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  44  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  45  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  46  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  47  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  48  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  49  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  50  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  51  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  52  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  53  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  54  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  55  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  56  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  57  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  58  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  59  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  60  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  61  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  62  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  63  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  64  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  65  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  66  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  67  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  68  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  69  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  70  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  71  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  72  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  73  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  74  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  75  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  76  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  77  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  78  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  79  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  80  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  81  loss  tensor(0.1014, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  21  batch  82  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  83  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  84  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  85  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  86  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  87  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  88  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  89  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  90  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  91  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  92  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  93  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  94  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  95  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  96  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  97  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  98  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  99  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  100  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  101  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  102  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  103  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  104  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  105  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  106  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  107  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  108  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  109  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  110  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  111  loss  tensor(0.1273, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  112  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  113  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  114  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  115  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  116  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  117  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  118  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  119  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  120  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  121  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  122  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  123  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  124  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  125  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  126  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  127  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  128  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  129  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  130  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  131  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  132  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  133  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  134  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  135  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  136  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  137  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  138  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  139  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  140  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  141  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  142  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  143  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  144  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  145  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  146  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  147  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  148  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  149  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  150  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  151  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  152  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  153  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  154  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  155  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  156  loss  tensor(0.1243, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  157  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  158  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  159  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  160  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  161  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  162  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  163  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  164  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  165  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  166  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  167  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  168  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  169  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  170  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  171  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  172  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  173  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  174  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  175  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  176  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  177  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  178  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  179  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  180  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  181  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  182  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  183  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  184  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  185  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  186  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  187  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  188  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  189  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  190  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  191  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  192  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  193  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  194  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  195  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  196  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  197  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  198  loss  tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  199  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  200  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  201  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  202  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  21  batch  203  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  204  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  205  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  206  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  207  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  208  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  209  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  210  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  211  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  212  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  213  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  214  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  215  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  216  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  217  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  218  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  219  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  220  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  221  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  222  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  223  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  224  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  225  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  226  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  227  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  228  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  229  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  230  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  231  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  232  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  233  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  234  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  235  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  236  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  237  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  238  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  239  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  240  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  241  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  242  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  243  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  244  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  245  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  246  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  247  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  248  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  249  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  250  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  251  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  252  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  253  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  254  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  255  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  256  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  257  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  258  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  259  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  260  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  261  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  262  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  263  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  264  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  265  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  266  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  267  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  268  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  269  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  270  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  271  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  272  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  273  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  274  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  275  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  276  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  277  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  278  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  279  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  280  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  281  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  282  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  283  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  284  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  285  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  286  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  287  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  288  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  289  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  290  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  291  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  292  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  293  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  294  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  295  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  296  loss  tensor(0.1130, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  297  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  298  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  299  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  300  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  301  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  302  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  303  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  304  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  305  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  306  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  307  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  308  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  309  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  310  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  311  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  312  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  313  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  314  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  315  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  316  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  317  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  318  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  319  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  320  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  321  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  322  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  323  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  21  batch  324  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  325  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  326  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  327  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  328  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  329  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  330  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  331  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  332  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  333  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  334  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  335  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  336  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  337  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  338  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  339  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  340  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  341  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  342  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  343  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  344  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  345  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  346  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  347  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  348  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  349  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  350  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  351  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  352  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  353  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  354  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  355  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  356  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  357  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  358  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  359  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  360  loss  tensor(0.0644, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  361  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  362  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  363  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  364  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  365  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  366  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  367  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  368  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  369  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  370  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  371  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  372  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  373  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  374  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  375  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  376  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  377  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  378  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  379  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  380  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  381  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  382  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  383  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  384  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  385  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  386  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  387  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  388  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  389  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  390  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  391  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  392  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  393  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  394  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  395  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  396  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  397  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  398  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  399  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  400  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  401  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  402  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  403  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  404  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  405  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  406  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  407  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  408  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  409  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  410  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  411  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  412  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  21  batch  413  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch [22/100], loss:33.4743\n",
      "epoch  22  batch  0  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  1  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  2  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  3  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  4  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  5  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  6  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  7  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  8  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  9  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  10  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  11  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  12  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  13  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  14  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  15  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  16  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  17  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  18  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  19  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  20  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  21  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  22  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  23  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  24  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  25  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  26  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  27  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  28  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  29  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  30  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  22  batch  31  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  32  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  33  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  34  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  35  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  36  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  37  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  38  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  39  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  40  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  41  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  42  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  43  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  44  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  45  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  46  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  47  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  48  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  49  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  50  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  51  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  52  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  53  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  54  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  55  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  56  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  57  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  58  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  59  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  60  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  61  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  62  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  63  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  64  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  65  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  66  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  67  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  68  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  69  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  70  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  71  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  72  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  73  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  74  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  75  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  76  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  77  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  78  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  79  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  80  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  81  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  82  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  83  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  84  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  85  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  86  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  87  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  88  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  89  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  90  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  91  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  92  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  93  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  94  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  95  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  96  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  97  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  98  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  99  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  100  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  101  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  102  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  103  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  104  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  105  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  106  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  107  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  108  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  109  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  110  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  111  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  112  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  113  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  114  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  115  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  116  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  117  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  118  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  119  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  120  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  121  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  122  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  123  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  124  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  125  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  126  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  127  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  128  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  129  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  130  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  131  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  132  loss  tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  133  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  134  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  135  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  136  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  137  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  138  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  139  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  140  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  141  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  142  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  143  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  144  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  145  loss  tensor(0.3308, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  146  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  147  loss  tensor(0.1124, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  148  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  149  loss  tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  150  loss  tensor(0.3314, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  151  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  152  loss  tensor(0.1010, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  22  batch  153  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  154  loss  tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  155  loss  tensor(0.1112, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  156  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  157  loss  tensor(0.2112, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  158  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  159  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  160  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  161  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  162  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  163  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  164  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  165  loss  tensor(0.1427, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  166  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  167  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  168  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  169  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  170  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  171  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  172  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  173  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  174  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  175  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  176  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  177  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  178  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  179  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  180  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  181  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  182  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  183  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  184  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  185  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  186  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  187  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  188  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  189  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  190  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  191  loss  tensor(0.1109, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  192  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  193  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  194  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  195  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  196  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  197  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  198  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  199  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  200  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  201  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  202  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  203  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  204  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  205  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  206  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  207  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  208  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  209  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  210  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  211  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  212  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  213  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  214  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  215  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  216  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  217  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  218  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  219  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  220  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  221  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  222  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  223  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  224  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  225  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  226  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  227  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  228  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  229  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  230  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  231  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  232  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  233  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  234  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  235  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  236  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  237  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  238  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  239  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  240  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  241  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  242  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  243  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  244  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  245  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  246  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  247  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  248  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  249  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  250  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  251  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  252  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  253  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  254  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  255  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  256  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  257  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  258  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  259  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  260  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  261  loss  tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  262  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  263  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  264  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  265  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  266  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  267  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  268  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  269  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  270  loss  tensor(0.1009, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  271  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  272  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  273  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  22  batch  274  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  275  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  276  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  277  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  278  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  279  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  280  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  281  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  282  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  283  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  284  loss  tensor(0.1030, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  285  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  286  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  287  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  288  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  289  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  290  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  291  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  292  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  293  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  294  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  295  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  296  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  297  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  298  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  299  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  300  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  301  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  302  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  303  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  304  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  305  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  306  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  307  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  308  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  309  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  310  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  311  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  312  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  313  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  314  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  315  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  316  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  317  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  318  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  319  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  320  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  321  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  322  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  323  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  324  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  325  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  326  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  327  loss  tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  328  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  329  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  330  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  331  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  332  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  333  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  334  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  335  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  336  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  337  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  338  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  339  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  340  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  341  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  342  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  343  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  344  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  345  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  346  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  347  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  348  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  349  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  350  loss  tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  351  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  352  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  353  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  354  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  355  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  356  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  357  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  358  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  359  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  360  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  361  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  362  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  363  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  364  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  365  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  366  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  367  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  368  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  369  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  370  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  371  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  372  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  373  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  374  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  375  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  376  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  377  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  378  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  379  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  380  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  381  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  382  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  383  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  384  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  385  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  386  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  387  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  388  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  389  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  390  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  391  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  392  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  393  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  394  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  22  batch  395  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  396  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  397  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  398  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  399  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  400  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  401  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  402  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  403  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  404  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  405  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  406  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  407  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  408  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  409  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  410  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  411  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  412  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  22  batch  413  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch [23/100], loss:34.3523\n",
      "epoch  23  batch  0  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  1  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  2  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  3  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  4  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  5  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  6  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  7  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  8  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  9  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  10  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  11  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  12  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  13  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  14  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  15  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  16  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  17  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  18  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  19  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  20  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  21  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  22  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  23  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  24  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  25  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  26  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  27  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  28  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  29  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  30  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  31  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  32  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  33  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  34  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  35  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  36  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  37  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  38  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  39  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  40  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  41  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  42  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  43  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  44  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  45  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  46  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  47  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  48  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  49  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  50  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  51  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  52  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  53  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  54  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  55  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  56  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  57  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  58  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  59  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  60  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  61  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  62  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  63  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  64  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  65  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  66  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  67  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  68  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  69  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  70  loss  tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  71  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  72  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  73  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  74  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  75  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  76  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  77  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  78  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  79  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  80  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  81  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  82  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  83  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  84  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  85  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  86  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  87  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  88  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  89  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  90  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  91  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  92  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  93  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  94  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  95  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  96  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  97  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  98  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  99  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  100  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  101  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  102  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  23  batch  103  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  104  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  105  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  106  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  107  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  108  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  109  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  110  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  111  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  112  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  113  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  114  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  115  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  116  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  117  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  118  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  119  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  120  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  121  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  122  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  123  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  124  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  125  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  126  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  127  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  128  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  129  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  130  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  131  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  132  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  133  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  134  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  135  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  136  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  137  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  138  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  139  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  140  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  141  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  142  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  143  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  144  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  145  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  146  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  147  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  148  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  149  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  150  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  151  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  152  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  153  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  154  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  155  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  156  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  157  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  158  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  159  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  160  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  161  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  162  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  163  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  164  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  165  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  166  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  167  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  168  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  169  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  170  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  171  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  172  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  173  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  174  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  175  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  176  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  177  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  178  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  179  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  180  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  181  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  182  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  183  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  184  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  185  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  186  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  187  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  188  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  189  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  190  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  191  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  192  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  193  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  194  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  195  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  196  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  197  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  198  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  199  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  200  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  201  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  202  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  203  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  204  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  205  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  206  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  207  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  208  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  209  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  210  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  211  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  212  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  213  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  214  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  215  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  216  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  217  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  218  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  219  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  220  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  221  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  222  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  223  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  23  batch  224  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  225  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  226  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  227  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  228  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  229  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  230  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  231  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  232  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  233  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  234  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  235  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  236  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  237  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  238  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  239  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  240  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  241  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  242  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  243  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  244  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  245  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  246  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  247  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  248  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  249  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  250  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  251  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  252  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  253  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  254  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  255  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  256  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  257  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  258  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  259  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  260  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  261  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  262  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  263  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  264  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  265  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  266  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  267  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  268  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  269  loss  tensor(0.1011, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  270  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  271  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  272  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  273  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  274  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  275  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  276  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  277  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  278  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  279  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  280  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  281  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  282  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  283  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  284  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  285  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  286  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  287  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  288  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  289  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  290  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  291  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  292  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  293  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  294  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  295  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  296  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  297  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  298  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  299  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  300  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  301  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  302  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  303  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  304  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  305  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  306  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  307  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  308  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  309  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  310  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  311  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  312  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  313  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  314  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  315  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  316  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  317  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  318  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  319  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  320  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  321  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  322  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  323  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  324  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  325  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  326  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  327  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  328  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  329  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  330  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  331  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  332  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  333  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  334  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  335  loss  tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  336  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  337  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  338  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  339  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  340  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  341  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  342  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  343  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  344  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  23  batch  345  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  346  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  347  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  348  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  349  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  350  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  351  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  352  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  353  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  354  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  355  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  356  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  357  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  358  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  359  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  360  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  361  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  362  loss  tensor(0.0960, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  363  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  364  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  365  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  366  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  367  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  368  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  369  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  370  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  371  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  372  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  373  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  374  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  375  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  376  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  377  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  378  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  379  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  380  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  381  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  382  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  383  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  384  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  385  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  386  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  387  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  388  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  389  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  390  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  391  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  392  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  393  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  394  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  395  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  396  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  397  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  398  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  399  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  400  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  401  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  402  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  403  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  404  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  405  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  406  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  407  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  408  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  409  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  410  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  411  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  412  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  23  batch  413  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch [24/100], loss:33.3502\n",
      "epoch  24  batch  0  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  1  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  2  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  3  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  4  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  5  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  6  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  7  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  8  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  9  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  10  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  11  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  12  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  13  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  14  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  15  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  16  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  17  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  18  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  19  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  20  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  21  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  22  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  23  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  24  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  25  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  26  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  27  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  28  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  29  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  30  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  31  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  32  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  33  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  34  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  35  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  36  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  37  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  38  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  39  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  40  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  41  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  42  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  43  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  44  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  45  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  46  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  47  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  48  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  49  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  50  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  51  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  24  batch  52  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  53  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  54  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  55  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  56  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  57  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  58  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  59  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  60  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  61  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  62  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  63  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  64  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  65  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  66  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  67  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  68  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  69  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  70  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  71  loss  tensor(0.1761, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  72  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  73  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  74  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  75  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  76  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  77  loss  tensor(0.1343, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  78  loss  tensor(0.5753, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  79  loss  tensor(0.1031, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  80  loss  tensor(0.2282, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  81  loss  tensor(1.7097, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  82  loss  tensor(0.1246, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  83  loss  tensor(0.3237, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  84  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  85  loss  tensor(0.0963, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  86  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  87  loss  tensor(0.1788, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  88  loss  tensor(0.5468, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  89  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  90  loss  tensor(0.1242, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  91  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  92  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  93  loss  tensor(0.1785, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  94  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  95  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  96  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  97  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  98  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  99  loss  tensor(0.1920, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  100  loss  tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  101  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  102  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  103  loss  tensor(0.3038, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  104  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  105  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  106  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  107  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  108  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  109  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  110  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  111  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  112  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  113  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  114  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  115  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  116  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  117  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  118  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  119  loss  tensor(0.1212, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  120  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  121  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  122  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  123  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  124  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  125  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  126  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  127  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  128  loss  tensor(0.1033, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  129  loss  tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  130  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  131  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  132  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  133  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  134  loss  tensor(0.1059, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  135  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  136  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  137  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  138  loss  tensor(0.1684, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  139  loss  tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  140  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  141  loss  tensor(0.1441, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  142  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  143  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  144  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  145  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  146  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  147  loss  tensor(0.5707, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  148  loss  tensor(0.1730, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  149  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  150  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  151  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  152  loss  tensor(0.4753, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  153  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  154  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  155  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  156  loss  tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  157  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  158  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  159  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  160  loss  tensor(0.0974, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  161  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  162  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  163  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  164  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  165  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  166  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  167  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  168  loss  tensor(0.1079, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  169  loss  tensor(0.1223, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  170  loss  tensor(0.1072, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  171  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  172  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  173  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  24  batch  174  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  175  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  176  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  177  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  178  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  179  loss  tensor(0.0660, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  180  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  181  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  182  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  183  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  184  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  185  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  186  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  187  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  188  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  189  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  190  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  191  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  192  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  193  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  194  loss  tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  195  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  196  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  197  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  198  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  199  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  200  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  201  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  202  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  203  loss  tensor(0.1358, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  204  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  205  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  206  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  207  loss  tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  208  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  209  loss  tensor(0.2193, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  210  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  211  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  212  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  213  loss  tensor(0.1309, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  214  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  215  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  216  loss  tensor(0.1156, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  217  loss  tensor(0.3378, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  218  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  219  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  220  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  221  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  222  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  223  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  224  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  225  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  226  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  227  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  228  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  229  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  230  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  231  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  232  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  233  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  234  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  235  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  236  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  237  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  238  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  239  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  240  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  241  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  242  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  243  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  244  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  245  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  246  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  247  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  248  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  249  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  250  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  251  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  252  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  253  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  254  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  255  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  256  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  257  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  258  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  259  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  260  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  261  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  262  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  263  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  264  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  265  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  266  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  267  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  268  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  269  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  270  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  271  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  272  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  273  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  274  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  275  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  276  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  277  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  278  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  279  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  280  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  281  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  282  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  283  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  284  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  285  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  286  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  287  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  288  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  289  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  290  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  291  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  292  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  293  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  294  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  24  batch  295  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  296  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  297  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  298  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  299  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  300  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  301  loss  tensor(0.1032, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  302  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  303  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  304  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  305  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  306  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  307  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  308  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  309  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  310  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  311  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  312  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  313  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  314  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  315  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  316  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  317  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  318  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  319  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  320  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  321  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  322  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  323  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  324  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  325  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  326  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  327  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  328  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  329  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  330  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  331  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  332  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  333  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  334  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  335  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  336  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  337  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  338  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  339  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  340  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  341  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  342  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  343  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  344  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  345  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  346  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  347  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  348  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  349  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  350  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  351  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  352  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  353  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  354  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  355  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  356  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  357  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  358  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  359  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  360  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  361  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  362  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  363  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  364  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  365  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  366  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  367  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  368  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  369  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  370  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  371  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  372  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  373  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  374  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  375  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  376  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  377  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  378  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  379  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  380  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  381  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  382  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  383  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  384  loss  tensor(0.0664, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  385  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  386  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  387  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  388  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  389  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  390  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  391  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  392  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  393  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  394  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  395  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  396  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  397  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  398  loss  tensor(0.0998, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  399  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  400  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  401  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  402  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  403  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  404  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  405  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  406  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  407  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  408  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  409  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  410  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  411  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  412  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  24  batch  413  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch [25/100], loss:39.2350\n",
      "epoch  25  batch  0  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  1  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  25  batch  2  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  3  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  4  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  5  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  6  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  7  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  8  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  9  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  10  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  11  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  12  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  13  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  14  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  15  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  16  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  17  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  18  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  19  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  20  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  21  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  22  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  23  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  24  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  25  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  26  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  27  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  28  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  29  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  30  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  31  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  32  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  33  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  34  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  35  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  36  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  37  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  38  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  39  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  40  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  41  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  42  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  43  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  44  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  45  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  46  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  47  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  48  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  49  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  50  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  51  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  52  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  53  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  54  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  55  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  56  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  57  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  58  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  59  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  60  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  61  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  62  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  63  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  64  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  65  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  66  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  67  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  68  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  69  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  70  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  71  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  72  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  73  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  74  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  75  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  76  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  77  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  78  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  79  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  80  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  81  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  82  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  83  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  84  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  85  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  86  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  87  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  88  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  89  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  90  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  91  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  92  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  93  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  94  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  95  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  96  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  97  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  98  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  99  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  100  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  101  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  102  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  103  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  104  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  105  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  106  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  107  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  108  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  109  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  110  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  111  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  112  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  113  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  114  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  115  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  116  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  117  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  118  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  119  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  120  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  121  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  122  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  123  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  124  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  25  batch  125  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  126  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  127  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  128  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  129  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  130  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  131  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  132  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  133  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  134  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  135  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  136  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  137  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  138  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  139  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  140  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  141  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  142  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  143  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  144  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  145  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  146  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  147  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  148  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  149  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  150  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  151  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  152  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  153  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  154  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  155  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  156  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  157  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  158  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  159  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  160  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  161  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  162  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  163  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  164  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  165  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  166  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  167  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  168  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  169  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  170  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  171  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  172  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  173  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  174  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  175  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  176  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  177  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  178  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  179  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  180  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  181  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  182  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  183  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  184  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  185  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  186  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  187  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  188  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  189  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  190  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  191  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  192  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  193  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  194  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  195  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  196  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  197  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  198  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  199  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  200  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  201  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  202  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  203  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  204  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  205  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  206  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  207  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  208  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  209  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  210  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  211  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  212  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  213  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  214  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  215  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  216  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  217  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  218  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  219  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  220  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  221  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  222  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  223  loss  tensor(0.0693, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  224  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  225  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  226  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  227  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  228  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  229  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  230  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  231  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  232  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  233  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  234  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  235  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  236  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  237  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  238  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  239  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  240  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  241  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  242  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  243  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  244  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  245  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  25  batch  246  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  247  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  248  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  249  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  250  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  251  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  252  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  253  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  254  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  255  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  256  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  257  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  258  loss  tensor(0.1711, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  259  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  260  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  261  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  262  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  263  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  264  loss  tensor(0.0667, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  265  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  266  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  267  loss  tensor(0.1499, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  268  loss  tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  269  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  270  loss  tensor(0.4844, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  271  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  272  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  273  loss  tensor(0.2663, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  274  loss  tensor(0.2713, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  275  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  276  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  277  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  278  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  279  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  280  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  281  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  282  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  283  loss  tensor(0.2693, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  284  loss  tensor(0.3382, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  285  loss  tensor(0.1008, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  286  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  287  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  288  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  289  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  290  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  291  loss  tensor(0.1565, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  292  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  293  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  294  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  295  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  296  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  297  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  298  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  299  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  300  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  301  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  302  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  303  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  304  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  305  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  306  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  307  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  308  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  309  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  310  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  311  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  312  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  313  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  314  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  315  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  316  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  317  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  318  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  319  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  320  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  321  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  322  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  323  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  324  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  325  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  326  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  327  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  328  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  329  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  330  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  331  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  332  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  333  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  334  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  335  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  336  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  337  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  338  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  339  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  340  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  341  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  342  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  343  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  344  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  345  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  346  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  347  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  348  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  349  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  350  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  351  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  352  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  353  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  354  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  355  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  356  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  357  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  358  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  359  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  360  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  361  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  362  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  363  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  364  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  365  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  366  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  25  batch  367  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  368  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  369  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  370  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  371  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  372  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  373  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  374  loss  tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  375  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  376  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  377  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  378  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  379  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  380  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  381  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  382  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  383  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  384  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  385  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  386  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  387  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  388  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  389  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  390  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  391  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  392  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  393  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  394  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  395  loss  tensor(0.0649, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  396  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  397  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  398  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  399  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  400  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  401  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  402  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  403  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  404  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  405  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  406  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  407  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  408  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  409  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  410  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  411  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  412  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  25  batch  413  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch [26/100], loss:34.8473\n",
      "epoch  26  batch  0  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  1  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  2  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  3  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  4  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  5  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  6  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  7  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  8  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  9  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  10  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  11  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  12  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  13  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  14  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  15  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  16  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  17  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  18  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  19  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  20  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  21  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  22  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  23  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  24  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  25  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  26  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  27  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  28  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  29  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  30  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  31  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  32  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  33  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  34  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  35  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  36  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  37  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  38  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  39  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  40  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  41  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  42  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  43  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  44  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  45  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  46  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  47  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  48  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  49  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  50  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  51  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  52  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  53  loss  tensor(0.0651, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  54  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  55  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  56  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  57  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  58  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  59  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  60  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  61  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  62  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  63  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  64  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  65  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  66  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  67  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  68  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  69  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  70  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  71  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  72  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  73  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  74  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  26  batch  75  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  76  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  77  loss  tensor(0.0980, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  78  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  79  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  80  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  81  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  82  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  83  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  84  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  85  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  86  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  87  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  88  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  89  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  90  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  91  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  92  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  93  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  94  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  95  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  96  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  97  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  98  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  99  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  100  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  101  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  102  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  103  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  104  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  105  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  106  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  107  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  108  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  109  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  110  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  111  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  112  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  113  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  114  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  115  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  116  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  117  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  118  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  119  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  120  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  121  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  122  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  123  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  124  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  125  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  126  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  127  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  128  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  129  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  130  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  131  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  132  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  133  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  134  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  135  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  136  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  137  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  138  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  139  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  140  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  141  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  142  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  143  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  144  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  145  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  146  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  147  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  148  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  149  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  150  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  151  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  152  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  153  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  154  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  155  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  156  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  157  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  158  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  159  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  160  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  161  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  162  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  163  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  164  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  165  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  166  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  167  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  168  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  169  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  170  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  171  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  172  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  173  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  174  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  175  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  176  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  177  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  178  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  179  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  180  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  181  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  182  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  183  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  184  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  185  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  186  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  187  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  188  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  189  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  190  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  191  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  192  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  193  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  194  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  195  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  26  batch  196  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  197  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  198  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  199  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  200  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  201  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  202  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  203  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  204  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  205  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  206  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  207  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  208  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  209  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  210  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  211  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  212  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  213  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  214  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  215  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  216  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  217  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  218  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  219  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  220  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  221  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  222  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  223  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  224  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  225  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  226  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  227  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  228  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  229  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  230  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  231  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  232  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  233  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  234  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  235  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  236  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  237  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  238  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  239  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  240  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  241  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  242  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  243  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  244  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  245  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  246  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  247  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  248  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  249  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  250  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  251  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  252  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  253  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  254  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  255  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  256  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  257  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  258  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  259  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  260  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  261  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  262  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  263  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  264  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  265  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  266  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  267  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  268  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  269  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  270  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  271  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  272  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  273  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  274  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  275  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  276  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  277  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  278  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  279  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  280  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  281  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  282  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  283  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  284  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  285  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  286  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  287  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  288  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  289  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  290  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  291  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  292  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  293  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  294  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  295  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  296  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  297  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  298  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  299  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  300  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  301  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  302  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  303  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  304  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  305  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  306  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  307  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  308  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  309  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  310  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  311  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  312  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  313  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  314  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  315  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  316  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  26  batch  317  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  318  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  319  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  320  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  321  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  322  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  323  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  324  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  325  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  326  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  327  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  328  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  329  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  330  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  331  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  332  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  333  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  334  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  335  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  336  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  337  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  338  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  339  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  340  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  341  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  342  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  343  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  344  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  345  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  346  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  347  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  348  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  349  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  350  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  351  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  352  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  353  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  354  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  355  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  356  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  357  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  358  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  359  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  360  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  361  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  362  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  363  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  364  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  365  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  366  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  367  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  368  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  369  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  370  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  371  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  372  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  373  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  374  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  375  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  376  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  377  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  378  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  379  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  380  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  381  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  382  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  383  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  384  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  385  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  386  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  387  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  388  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  389  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  390  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  391  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  392  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  393  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  394  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  395  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  396  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  397  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  398  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  399  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  400  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  401  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  402  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  403  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  404  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  405  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  406  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  407  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  408  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  409  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  410  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  411  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  412  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  26  batch  413  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch [27/100], loss:33.2284\n",
      "epoch  27  batch  0  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  1  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  2  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  3  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  4  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  5  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  6  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  7  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  8  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  9  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  10  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  11  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  12  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  13  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  14  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  15  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  16  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  17  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  18  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  19  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  20  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  21  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  22  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  23  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  27  batch  24  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  25  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  26  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  27  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  28  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  29  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  30  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  31  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  32  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  33  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  34  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  35  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  36  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  37  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  38  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  39  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  40  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  41  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  42  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  43  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  44  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  45  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  46  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  47  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  48  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  49  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  50  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  51  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  52  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  53  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  54  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  55  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  56  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  57  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  58  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  59  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  60  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  61  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  62  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  63  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  64  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  65  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  66  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  67  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  68  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  69  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  70  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  71  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  72  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  73  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  74  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  75  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  76  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  77  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  78  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  79  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  80  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  81  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  82  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  83  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  84  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  85  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  86  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  87  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  88  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  89  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  90  loss  tensor(0.1380, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  91  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  92  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  93  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  94  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  95  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  96  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  97  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  98  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  99  loss  tensor(0.0659, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  100  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  101  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  102  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  103  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  104  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  105  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  106  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  107  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  108  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  109  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  110  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  111  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  112  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  113  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  114  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  115  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  116  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  117  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  118  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  119  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  120  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  121  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  122  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  123  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  124  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  125  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  126  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  127  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  128  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  129  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  130  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  131  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  132  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  133  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  134  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  135  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  136  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  137  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  138  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  139  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  140  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  141  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  142  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  143  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  144  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  145  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  27  batch  146  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  147  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  148  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  149  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  150  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  151  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  152  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  153  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  154  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  155  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  156  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  157  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  158  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  159  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  160  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  161  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  162  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  163  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  164  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  165  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  166  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  167  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  168  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  169  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  170  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  171  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  172  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  173  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  174  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  175  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  176  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  177  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  178  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  179  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  180  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  181  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  182  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  183  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  184  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  185  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  186  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  187  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  188  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  189  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  190  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  191  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  192  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  193  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  194  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  195  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  196  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  197  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  198  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  199  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  200  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  201  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  202  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  203  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  204  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  205  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  206  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  207  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  208  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  209  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  210  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  211  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  212  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  213  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  214  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  215  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  216  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  217  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  218  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  219  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  220  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  221  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  222  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  223  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  224  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  225  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  226  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  227  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  228  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  229  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  230  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  231  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  232  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  233  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  234  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  235  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  236  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  237  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  238  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  239  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  240  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  241  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  242  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  243  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  244  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  245  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  246  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  247  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  248  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  249  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  250  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  251  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  252  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  253  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  254  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  255  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  256  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  257  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  258  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  259  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  260  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  261  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  262  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  263  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  264  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  265  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  266  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  27  batch  267  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  268  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  269  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  270  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  271  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  272  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  273  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  274  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  275  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  276  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  277  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  278  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  279  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  280  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  281  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  282  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  283  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  284  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  285  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  286  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  287  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  288  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  289  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  290  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  291  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  292  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  293  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  294  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  295  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  296  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  297  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  298  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  299  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  300  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  301  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  302  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  303  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  304  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  305  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  306  loss  tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  307  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  308  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  309  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  310  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  311  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  312  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  313  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  314  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  315  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  316  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  317  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  318  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  319  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  320  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  321  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  322  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  323  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  324  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  325  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  326  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  327  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  328  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  329  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  330  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  331  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  332  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  333  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  334  loss  tensor(0.1112, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  335  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  336  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  337  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  338  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  339  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  340  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  341  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  342  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  343  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  344  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  345  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  346  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  347  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  348  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  349  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  350  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  351  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  352  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  353  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  354  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  355  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  356  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  357  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  358  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  359  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  360  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  361  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  362  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  363  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  364  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  365  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  366  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  367  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  368  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  369  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  370  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  371  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  372  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  373  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  374  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  375  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  376  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  377  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  378  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  379  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  380  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  381  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  382  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  383  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  384  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  385  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  386  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  387  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  27  batch  388  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  389  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  390  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  391  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  392  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  393  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  394  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  395  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  396  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  397  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  398  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  399  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  400  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  401  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  402  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  403  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  404  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  405  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  406  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  407  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  408  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  409  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  410  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  411  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  412  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  27  batch  413  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch [28/100], loss:33.2577\n",
      "epoch  28  batch  0  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  1  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  2  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  3  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  4  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  5  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  6  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  7  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  8  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  9  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  10  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  11  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  12  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  13  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  14  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  15  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  16  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  17  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  18  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  19  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  20  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  21  loss  tensor(0.0960, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  22  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  23  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  24  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  25  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  26  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  27  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  28  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  29  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  30  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  31  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  32  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  33  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  34  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  35  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  36  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  37  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  38  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  39  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  40  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  41  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  42  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  43  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  44  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  45  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  46  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  47  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  48  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  49  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  50  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  51  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  52  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  53  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  54  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  55  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  56  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  57  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  58  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  59  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  60  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  61  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  62  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  63  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  64  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  65  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  66  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  67  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  68  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  69  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  70  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  71  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  72  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  73  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  74  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  75  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  76  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  77  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  78  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  79  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  80  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  81  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  82  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  83  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  84  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  85  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  86  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  87  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  88  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  89  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  90  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  91  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  92  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  93  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  94  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  95  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  28  batch  96  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  97  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  98  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  99  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  100  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  101  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  102  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  103  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  104  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  105  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  106  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  107  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  108  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  109  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  110  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  111  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  112  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  113  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  114  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  115  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  116  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  117  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  118  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  119  loss  tensor(0.0658, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  120  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  121  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  122  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  123  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  124  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  125  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  126  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  127  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  128  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  129  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  130  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  131  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  132  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  133  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  134  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  135  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  136  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  137  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  138  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  139  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  140  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  141  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  142  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  143  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  144  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  145  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  146  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  147  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  148  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  149  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  150  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  151  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  152  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  153  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  154  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  155  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  156  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  157  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  158  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  159  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  160  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  161  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  162  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  163  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  164  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  165  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  166  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  167  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  168  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  169  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  170  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  171  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  172  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  173  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  174  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  175  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  176  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  177  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  178  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  179  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  180  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  181  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  182  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  183  loss  tensor(0.0963, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  184  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  185  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  186  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  187  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  188  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  189  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  190  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  191  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  192  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  193  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  194  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  195  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  196  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  197  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  198  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  199  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  200  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  201  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  202  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  203  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  204  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  205  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  206  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  207  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  208  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  209  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  210  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  211  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  212  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  213  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  214  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  215  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  216  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  28  batch  217  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  218  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  219  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  220  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  221  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  222  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  223  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  224  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  225  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  226  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  227  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  228  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  229  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  230  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  231  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  232  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  233  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  234  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  235  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  236  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  237  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  238  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  239  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  240  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  241  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  242  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  243  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  244  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  245  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  246  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  247  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  248  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  249  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  250  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  251  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  252  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  253  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  254  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  255  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  256  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  257  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  258  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  259  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  260  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  261  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  262  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  263  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  264  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  265  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  266  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  267  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  268  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  269  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  270  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  271  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  272  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  273  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  274  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  275  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  276  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  277  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  278  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  279  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  280  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  281  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  282  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  283  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  284  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  285  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  286  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  287  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  288  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  289  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  290  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  291  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  292  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  293  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  294  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  295  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  296  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  297  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  298  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  299  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  300  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  301  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  302  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  303  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  304  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  305  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  306  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  307  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  308  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  309  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  310  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  311  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  312  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  313  loss  tensor(0.0975, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  314  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  315  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  316  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  317  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  318  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  319  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  320  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  321  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  322  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  323  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  324  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  325  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  326  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  327  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  328  loss  tensor(0.0659, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  329  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  330  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  331  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  332  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  333  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  334  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  335  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  336  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  337  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  28  batch  338  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  339  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  340  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  341  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  342  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  343  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  344  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  345  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  346  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  347  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  348  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  349  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  350  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  351  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  352  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  353  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  354  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  355  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  356  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  357  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  358  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  359  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  360  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  361  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  362  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  363  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  364  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  365  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  366  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  367  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  368  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  369  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  370  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  371  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  372  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  373  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  374  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  375  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  376  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  377  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  378  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  379  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  380  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  381  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  382  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  383  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  384  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  385  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  386  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  387  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  388  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  389  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  390  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  391  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  392  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  393  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  394  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  395  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  396  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  397  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  398  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  399  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  400  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  401  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  402  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  403  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  404  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  405  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  406  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  407  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  408  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  409  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  410  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  411  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  412  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  28  batch  413  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch [29/100], loss:33.1662\n",
      "epoch  29  batch  0  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  1  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  2  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  3  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  4  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  5  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  6  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  7  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  8  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  9  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  10  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  11  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  12  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  13  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  14  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  15  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  16  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  17  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  18  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  19  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  20  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  21  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  22  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  23  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  24  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  25  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  26  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  27  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  28  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  29  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  30  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  31  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  32  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  33  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  34  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  35  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  36  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  37  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  38  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  39  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  40  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  41  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  42  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  43  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  44  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  29  batch  45  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  46  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  47  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  48  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  49  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  50  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  51  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  52  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  53  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  54  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  55  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  56  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  57  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  58  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  59  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  60  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  61  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  62  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  63  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  64  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  65  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  66  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  67  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  68  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  69  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  70  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  71  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  72  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  73  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  74  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  75  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  76  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  77  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  78  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  79  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  80  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  81  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  82  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  83  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  84  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  85  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  86  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  87  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  88  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  89  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  90  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  91  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  92  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  93  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  94  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  95  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  96  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  97  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  98  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  99  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  100  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  101  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  102  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  103  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  104  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  105  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  106  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  107  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  108  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  109  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  110  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  111  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  112  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  113  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  114  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  115  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  116  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  117  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  118  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  119  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  120  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  121  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  122  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  123  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  124  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  125  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  126  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  127  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  128  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  129  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  130  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  131  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  132  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  133  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  134  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  135  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  136  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  137  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  138  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  139  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  140  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  141  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  142  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  143  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  144  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  145  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  146  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  147  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  148  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  149  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  150  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  151  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  152  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  153  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  154  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  155  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  156  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  157  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  158  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  159  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  160  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  161  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  162  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  163  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  164  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  165  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  166  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  29  batch  167  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  168  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  169  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  170  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  171  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  172  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  173  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  174  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  175  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  176  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  177  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  178  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  179  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  180  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  181  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  182  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  183  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  184  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  185  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  186  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  187  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  188  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  189  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  190  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  191  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  192  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  193  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  194  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  195  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  196  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  197  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  198  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  199  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  200  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  201  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  202  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  203  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  204  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  205  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  206  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  207  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  208  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  209  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  210  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  211  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  212  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  213  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  214  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  215  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  216  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  217  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  218  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  219  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  220  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  221  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  222  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  223  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  224  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  225  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  226  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  227  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  228  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  229  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  230  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  231  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  232  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  233  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  234  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  235  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  236  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  237  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  238  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  239  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  240  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  241  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  242  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  243  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  244  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  245  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  246  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  247  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  248  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  249  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  250  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  251  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  252  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  253  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  254  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  255  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  256  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  257  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  258  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  259  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  260  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  261  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  262  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  263  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  264  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  265  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  266  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  267  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  268  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  269  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  270  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  271  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  272  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  273  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  274  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  275  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  276  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  277  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  278  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  279  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  280  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  281  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  282  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  283  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  284  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  285  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  286  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  287  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  29  batch  288  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  289  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  290  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  291  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  292  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  293  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  294  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  295  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  296  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  297  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  298  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  299  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  300  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  301  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  302  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  303  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  304  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  305  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  306  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  307  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  308  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  309  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  310  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  311  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  312  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  313  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  314  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  315  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  316  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  317  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  318  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  319  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  320  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  321  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  322  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  323  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  324  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  325  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  326  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  327  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  328  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  329  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  330  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  331  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  332  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  333  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  334  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  335  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  336  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  337  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  338  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  339  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  340  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  341  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  342  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  343  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  344  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  345  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  346  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  347  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  348  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  349  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  350  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  351  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  352  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  353  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  354  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  355  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  356  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  357  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  358  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  359  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  360  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  361  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  362  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  363  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  364  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  365  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  366  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  367  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  368  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  369  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  370  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  371  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  372  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  373  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  374  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  375  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  376  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  377  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  378  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  379  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  380  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  381  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  382  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  383  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  384  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  385  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  386  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  387  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  388  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  389  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  390  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  391  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  392  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  393  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  394  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  395  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  396  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  397  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  398  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  399  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  400  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  401  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  402  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  403  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  404  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  405  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  406  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  407  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  408  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  29  batch  409  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  410  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  411  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  412  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  29  batch  413  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch [30/100], loss:33.1682\n",
      "epoch  30  batch  0  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  1  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  2  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  3  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  4  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  5  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  6  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  7  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  8  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  9  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  10  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  11  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  12  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  13  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  14  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  15  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  16  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  17  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  18  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  19  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  20  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  21  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  22  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  23  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  24  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  25  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  26  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  27  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  28  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  29  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  30  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  31  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  32  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  33  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  34  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  35  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  36  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  37  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  38  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  39  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  40  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  41  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  42  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  43  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  44  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  45  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  46  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  47  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  48  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  49  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  50  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  51  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  52  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  53  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  54  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  55  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  56  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  57  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  58  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  59  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  60  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  61  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  62  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  63  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  64  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  65  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  66  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  67  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  68  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  69  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  70  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  71  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  72  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  73  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  74  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  75  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  76  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  77  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  78  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  79  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  80  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  81  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  82  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  83  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  84  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  85  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  86  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  87  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  88  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  89  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  90  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  91  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  92  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  93  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  94  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  95  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  96  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  97  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  98  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  99  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  100  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  101  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  102  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  103  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  104  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  105  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  106  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  107  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  108  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  109  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  110  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  111  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  112  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  113  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  114  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  115  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  116  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  30  batch  117  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  118  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  119  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  120  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  121  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  122  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  123  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  124  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  125  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  126  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  127  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  128  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  129  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  130  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  131  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  132  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  133  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  134  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  135  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  136  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  137  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  138  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  139  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  140  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  141  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  142  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  143  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  144  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  145  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  146  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  147  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  148  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  149  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  150  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  151  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  152  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  153  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  154  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  155  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  156  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  157  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  158  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  159  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  160  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  161  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  162  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  163  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  164  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  165  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  166  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  167  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  168  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  169  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  170  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  171  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  172  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  173  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  174  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  175  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  176  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  177  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  178  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  179  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  180  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  181  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  182  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  183  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  184  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  185  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  186  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  187  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  188  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  189  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  190  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  191  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  192  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  193  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  194  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  195  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  196  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  197  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  198  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  199  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  200  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  201  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  202  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  203  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  204  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  205  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  206  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  207  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  208  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  209  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  210  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  211  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  212  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  213  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  214  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  215  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  216  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  217  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  218  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  219  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  220  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  221  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  222  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  223  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  224  loss  tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  225  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  226  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  227  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  228  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  229  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  230  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  231  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  232  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  233  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  234  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  235  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  236  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  237  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  30  batch  238  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  239  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  240  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  241  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  242  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  243  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  244  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  245  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  246  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  247  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  248  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  249  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  250  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  251  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  252  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  253  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  254  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  255  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  256  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  257  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  258  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  259  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  260  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  261  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  262  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  263  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  264  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  265  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  266  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  267  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  268  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  269  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  270  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  271  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  272  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  273  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  274  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  275  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  276  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  277  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  278  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  279  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  280  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  281  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  282  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  283  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  284  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  285  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  286  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  287  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  288  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  289  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  290  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  291  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  292  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  293  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  294  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  295  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  296  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  297  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  298  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  299  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  300  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  301  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  302  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  303  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  304  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  305  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  306  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  307  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  308  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  309  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  310  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  311  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  312  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  313  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  314  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  315  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  316  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  317  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  318  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  319  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  320  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  321  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  322  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  323  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  324  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  325  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  326  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  327  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  328  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  329  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  330  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  331  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  332  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  333  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  334  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  335  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  336  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  337  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  338  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  339  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  340  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  341  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  342  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  343  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  344  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  345  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  346  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  347  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  348  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  349  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  350  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  351  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  352  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  353  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  354  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  355  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  356  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  357  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  358  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  30  batch  359  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  360  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  361  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  362  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  363  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  364  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  365  loss  tensor(0.0655, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  366  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  367  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  368  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  369  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  370  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  371  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  372  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  373  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  374  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  375  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  376  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  377  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  378  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  379  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  380  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  381  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  382  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  383  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  384  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  385  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  386  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  387  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  388  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  389  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  390  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  391  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  392  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  393  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  394  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  395  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  396  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  397  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  398  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  399  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  400  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  401  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  402  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  403  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  404  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  405  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  406  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  407  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  408  loss  tensor(0.0960, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  409  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  410  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  411  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  412  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  30  batch  413  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch [31/100], loss:33.1831\n",
      "epoch  31  batch  0  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  1  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  2  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  3  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  4  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  5  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  6  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  7  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  8  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  9  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  10  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  11  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  12  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  13  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  14  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  15  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  16  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  17  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  18  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  19  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  20  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  21  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  22  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  23  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  24  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  25  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  26  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  27  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  28  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  29  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  30  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  31  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  32  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  33  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  34  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  35  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  36  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  37  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  38  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  39  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  40  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  41  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  42  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  43  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  44  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  45  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  46  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  47  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  48  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  49  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  50  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  51  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  52  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  53  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  54  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  55  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  56  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  57  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  58  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  59  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  60  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  61  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  62  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  63  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  64  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  65  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  66  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  31  batch  67  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  68  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  69  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  70  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  71  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  72  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  73  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  74  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  75  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  76  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  77  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  78  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  79  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  80  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  81  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  82  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  83  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  84  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  85  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  86  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  87  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  88  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  89  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  90  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  91  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  92  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  93  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  94  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  95  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  96  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  97  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  98  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  99  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  100  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  101  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  102  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  103  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  104  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  105  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  106  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  107  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  108  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  109  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  110  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  111  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  112  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  113  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  114  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  115  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  116  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  117  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  118  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  119  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  120  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  121  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  122  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  123  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  124  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  125  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  126  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  127  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  128  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  129  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  130  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  131  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  132  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  133  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  134  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  135  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  136  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  137  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  138  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  139  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  140  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  141  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  142  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  143  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  144  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  145  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  146  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  147  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  148  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  149  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  150  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  151  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  152  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  153  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  154  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  155  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  156  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  157  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  158  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  159  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  160  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  161  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  162  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  163  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  164  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  165  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  166  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  167  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  168  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  169  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  170  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  171  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  172  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  173  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  174  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  175  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  176  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  177  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  178  loss  tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  179  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  180  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  181  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  182  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  183  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  184  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  185  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  186  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  187  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  31  batch  188  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  189  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  190  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  191  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  192  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  193  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  194  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  195  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  196  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  197  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  198  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  199  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  200  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  201  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  202  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  203  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  204  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  205  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  206  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  207  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  208  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  209  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  210  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  211  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  212  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  213  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  214  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  215  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  216  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  217  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  218  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  219  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  220  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  221  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  222  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  223  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  224  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  225  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  226  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  227  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  228  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  229  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  230  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  231  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  232  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  233  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  234  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  235  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  236  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  237  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  238  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  239  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  240  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  241  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  242  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  243  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  244  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  245  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  246  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  247  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  248  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  249  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  250  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  251  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  252  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  253  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  254  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  255  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  256  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  257  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  258  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  259  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  260  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  261  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  262  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  263  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  264  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  265  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  266  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  267  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  268  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  269  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  270  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  271  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  272  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  273  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  274  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  275  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  276  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  277  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  278  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  279  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  280  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  281  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  282  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  283  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  284  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  285  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  286  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  287  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  288  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  289  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  290  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  291  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  292  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  293  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  294  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  295  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  296  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  297  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  298  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  299  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  300  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  301  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  302  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  303  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  304  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  305  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  306  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  307  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  308  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  31  batch  309  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  310  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  311  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  312  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  313  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  314  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  315  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  316  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  317  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  318  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  319  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  320  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  321  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  322  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  323  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  324  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  325  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  326  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  327  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  328  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  329  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  330  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  331  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  332  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  333  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  334  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  335  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  336  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  337  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  338  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  339  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  340  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  341  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  342  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  343  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  344  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  345  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  346  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  347  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  348  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  349  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  350  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  351  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  352  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  353  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  354  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  355  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  356  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  357  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  358  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  359  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  360  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  361  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  362  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  363  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  364  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  365  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  366  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  367  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  368  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  369  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  370  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  371  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  372  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  373  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  374  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  375  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  376  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  377  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  378  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  379  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  380  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  381  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  382  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  383  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  384  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  385  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  386  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  387  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  388  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  389  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  390  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  391  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  392  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  393  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  394  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  395  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  396  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  397  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  398  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  399  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  400  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  401  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  402  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  403  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  404  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  405  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  406  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  407  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  408  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  409  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  410  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  411  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  412  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  31  batch  413  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch [32/100], loss:33.1555\n",
      "epoch  32  batch  0  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  1  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  2  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  3  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  4  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  5  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  6  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  7  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  8  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  9  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  10  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  11  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  12  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  13  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  14  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  15  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  32  batch  16  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  17  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  18  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  19  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  20  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  21  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  22  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  23  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  24  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  25  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  26  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  27  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  28  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  29  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  30  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  31  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  32  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  33  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  34  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  35  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  36  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  37  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  38  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  39  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  40  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  41  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  42  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  43  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  44  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  45  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  46  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  47  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  48  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  49  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  50  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  51  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  52  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  53  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  54  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  55  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  56  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  57  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  58  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  59  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  60  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  61  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  62  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  63  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  64  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  65  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  66  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  67  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  68  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  69  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  70  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  71  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  72  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  73  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  74  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  75  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  76  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  77  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  78  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  79  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  80  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  81  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  82  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  83  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  84  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  85  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  86  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  87  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  88  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  89  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  90  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  91  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  92  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  93  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  94  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  95  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  96  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  97  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  98  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  99  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  100  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  101  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  102  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  103  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  104  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  105  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  106  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  107  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  108  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  109  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  110  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  111  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  112  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  113  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  114  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  115  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  116  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  117  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  118  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  119  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  120  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  121  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  122  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  123  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  124  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  125  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  126  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  127  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  128  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  129  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  130  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  131  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  132  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  133  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  134  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  135  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  136  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  137  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  32  batch  138  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  139  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  140  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  141  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  142  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  143  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  144  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  145  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  146  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  147  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  148  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  149  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  150  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  151  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  152  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  153  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  154  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  155  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  156  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  157  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  158  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  159  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  160  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  161  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  162  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  163  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  164  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  165  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  166  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  167  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  168  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  169  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  170  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  171  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  172  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  173  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  174  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  175  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  176  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  177  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  178  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  179  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  180  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  181  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  182  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  183  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  184  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  185  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  186  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  187  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  188  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  189  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  190  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  191  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  192  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  193  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  194  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  195  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  196  loss  tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  197  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  198  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  199  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  200  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  201  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  202  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  203  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  204  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  205  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  206  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  207  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  208  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  209  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  210  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  211  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  212  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  213  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  214  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  215  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  216  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  217  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  218  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  219  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  220  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  221  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  222  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  223  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  224  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  225  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  226  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  227  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  228  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  229  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  230  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  231  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  232  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  233  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  234  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  235  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  236  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  237  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  238  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  239  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  240  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  241  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  242  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  243  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  244  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  245  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  246  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  247  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  248  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  249  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  250  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  251  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  252  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  253  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  254  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  255  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  256  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  257  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  258  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  32  batch  259  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  260  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  261  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  262  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  263  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  264  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  265  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  266  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  267  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  268  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  269  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  270  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  271  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  272  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  273  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  274  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  275  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  276  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  277  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  278  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  279  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  280  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  281  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  282  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  283  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  284  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  285  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  286  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  287  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  288  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  289  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  290  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  291  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  292  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  293  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  294  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  295  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  296  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  297  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  298  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  299  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  300  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  301  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  302  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  303  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  304  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  305  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  306  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  307  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  308  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  309  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  310  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  311  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  312  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  313  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  314  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  315  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  316  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  317  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  318  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  319  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  320  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  321  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  322  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  323  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  324  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  325  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  326  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  327  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  328  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  329  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  330  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  331  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  332  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  333  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  334  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  335  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  336  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  337  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  338  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  339  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  340  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  341  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  342  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  343  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  344  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  345  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  346  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  347  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  348  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  349  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  350  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  351  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  352  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  353  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  354  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  355  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  356  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  357  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  358  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  359  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  360  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  361  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  362  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  363  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  364  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  365  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  366  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  367  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  368  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  369  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  370  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  371  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  372  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  373  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  374  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  375  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  376  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  377  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  378  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  379  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  32  batch  380  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  381  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  382  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  383  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  384  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  385  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  386  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  387  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  388  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  389  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  390  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  391  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  392  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  393  loss  tensor(0.0665, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  394  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  395  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  396  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  397  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  398  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  399  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  400  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  401  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  402  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  403  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  404  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  405  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  406  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  407  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  408  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  409  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  410  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  411  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  412  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  32  batch  413  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch [33/100], loss:33.1618\n",
      "epoch  33  batch  0  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  1  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  2  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  3  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  4  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  5  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  6  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  7  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  8  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  9  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  10  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  11  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  12  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  13  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  14  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  15  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  16  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  17  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  18  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  19  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  20  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  21  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  22  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  23  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  24  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  25  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  26  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  27  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  28  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  29  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  30  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  31  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  32  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  33  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  34  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  35  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  36  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  37  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  38  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  39  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  40  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  41  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  42  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  43  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  44  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  45  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  46  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  47  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  48  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  49  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  50  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  51  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  52  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  53  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  54  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  55  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  56  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  57  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  58  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  59  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  60  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  61  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  62  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  63  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  64  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  65  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  66  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  67  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  68  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  69  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  70  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  71  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  72  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  73  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  74  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  75  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  76  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  77  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  78  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  79  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  80  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  81  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  82  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  83  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  84  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  85  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  86  loss  tensor(0.2104, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  87  loss  tensor(0.3521, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  33  batch  88  loss  tensor(0.1045, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  89  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  90  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  91  loss  tensor(0.1135, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  92  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  93  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  94  loss  tensor(0.1275, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  95  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  96  loss  tensor(0.1075, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  97  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  98  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  99  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  100  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  101  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  102  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  103  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  104  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  105  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  106  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  107  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  108  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  109  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  110  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  111  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  112  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  113  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  114  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  115  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  116  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  117  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  118  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  119  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  120  loss  tensor(0.1187, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  121  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  122  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  123  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  124  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  125  loss  tensor(0.1373, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  126  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  127  loss  tensor(0.3551, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  128  loss  tensor(0.2103, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  129  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  130  loss  tensor(0.1380, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  131  loss  tensor(0.1882, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  132  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  133  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  134  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  135  loss  tensor(0.1281, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  136  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  137  loss  tensor(0.1063, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  138  loss  tensor(0.1435, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  139  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  140  loss  tensor(0.1706, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  141  loss  tensor(0.1357, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  142  loss  tensor(0.3023, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  143  loss  tensor(0.2025, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  144  loss  tensor(0.1800, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  145  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  146  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  147  loss  tensor(0.1261, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  148  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  149  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  150  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  151  loss  tensor(0.1327, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  152  loss  tensor(0.1230, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  153  loss  tensor(0.1935, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  154  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  155  loss  tensor(0.4285, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  156  loss  tensor(0.1414, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  157  loss  tensor(0.6317, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  158  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  159  loss  tensor(0.2644, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  160  loss  tensor(0.1260, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  161  loss  tensor(0.1420, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  162  loss  tensor(1.8090, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  163  loss  tensor(0.1271, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  164  loss  tensor(6.3032, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  165  loss  tensor(2.4589, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  166  loss  tensor(2.1534, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  167  loss  tensor(0.8623, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  168  loss  tensor(1.2345, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  169  loss  tensor(0.1334, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  170  loss  tensor(0.1157, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  171  loss  tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  172  loss  tensor(0.1622, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  173  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  174  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  175  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  176  loss  tensor(0.6018, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  177  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  178  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  179  loss  tensor(0.1604, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  180  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  181  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  182  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  183  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  184  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  185  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  186  loss  tensor(0.1371, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  187  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  188  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  189  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  190  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  191  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  192  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  193  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  194  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  195  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  196  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  197  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  198  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  199  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  200  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  201  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  202  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  203  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  204  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  205  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  206  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  207  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  208  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  33  batch  209  loss  tensor(0.1678, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  210  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  211  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  212  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  213  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  214  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  215  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  216  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  217  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  218  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  219  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  220  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  221  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  222  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  223  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  224  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  225  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  226  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  227  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  228  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  229  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  230  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  231  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  232  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  233  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  234  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  235  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  236  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  237  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  238  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  239  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  240  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  241  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  242  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  243  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  244  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  245  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  246  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  247  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  248  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  249  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  250  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  251  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  252  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  253  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  254  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  255  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  256  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  257  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  258  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  259  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  260  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  261  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  262  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  263  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  264  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  265  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  266  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  267  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  268  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  269  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  270  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  271  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  272  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  273  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  274  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  275  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  276  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  277  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  278  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  279  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  280  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  281  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  282  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  283  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  284  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  285  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  286  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  287  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  288  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  289  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  290  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  291  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  292  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  293  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  294  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  295  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  296  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  297  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  298  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  299  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  300  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  301  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  302  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  303  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  304  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  305  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  306  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  307  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  308  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  309  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  310  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  311  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  312  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  313  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  314  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  315  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  316  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  317  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  318  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  319  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  320  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  321  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  322  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  323  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  324  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  325  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  326  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  327  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  328  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  329  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  33  batch  330  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  331  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  332  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  333  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  334  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  335  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  336  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  337  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  338  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  339  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  340  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  341  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  342  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  343  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  344  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  345  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  346  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  347  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  348  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  349  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  350  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  351  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  352  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  353  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  354  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  355  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  356  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  357  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  358  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  359  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  360  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  361  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  362  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  363  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  364  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  365  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  366  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  367  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  368  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  369  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  370  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  371  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  372  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  373  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  374  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  375  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  376  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  377  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  378  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  379  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  380  loss  tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  381  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  382  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  383  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  384  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  385  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  386  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  387  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  388  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  389  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  390  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  391  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  392  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  393  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  394  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  395  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  396  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  397  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  398  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  399  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  400  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  401  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  402  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  403  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  404  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  405  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  406  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  407  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  408  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  409  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  410  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  411  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  412  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  33  batch  413  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch [34/100], loss:52.0501\n",
      "epoch  34  batch  0  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  1  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  2  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  3  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  4  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  5  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  6  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  7  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  8  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  9  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  10  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  11  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  12  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  13  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  14  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  15  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  16  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  17  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  18  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  19  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  20  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  21  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  22  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  23  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  24  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  25  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  26  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  27  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  28  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  29  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  30  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  31  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  32  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  33  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  34  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  35  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  36  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  34  batch  37  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  38  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  39  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  40  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  41  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  42  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  43  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  44  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  45  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  46  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  47  loss  tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  48  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  49  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  50  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  51  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  52  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  53  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  54  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  55  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  56  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  57  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  58  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  59  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  60  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  61  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  62  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  63  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  64  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  65  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  66  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  67  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  68  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  69  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  70  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  71  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  72  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  73  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  74  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  75  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  76  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  77  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  78  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  79  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  80  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  81  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  82  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  83  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  84  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  85  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  86  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  87  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  88  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  89  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  90  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  91  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  92  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  93  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  94  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  95  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  96  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  97  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  98  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  99  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  100  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  101  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  102  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  103  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  104  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  105  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  106  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  107  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  108  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  109  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  110  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  111  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  112  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  113  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  114  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  115  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  116  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  117  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  118  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  119  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  120  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  121  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  122  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  123  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  124  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  125  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  126  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  127  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  128  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  129  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  130  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  131  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  132  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  133  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  134  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  135  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  136  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  137  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  138  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  139  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  140  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  141  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  142  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  143  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  144  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  145  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  146  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  147  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  148  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  149  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  150  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  151  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  152  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  153  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  154  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  155  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  156  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  157  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  158  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  34  batch  159  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  160  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  161  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  162  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  163  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  164  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  165  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  166  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  167  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  168  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  169  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  170  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  171  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  172  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  173  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  174  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  175  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  176  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  177  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  178  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  179  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  180  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  181  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  182  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  183  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  184  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  185  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  186  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  187  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  188  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  189  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  190  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  191  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  192  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  193  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  194  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  195  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  196  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  197  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  198  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  199  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  200  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  201  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  202  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  203  loss  tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  204  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  205  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  206  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  207  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  208  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  209  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  210  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  211  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  212  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  213  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  214  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  215  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  216  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  217  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  218  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  219  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  220  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  221  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  222  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  223  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  224  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  225  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  226  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  227  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  228  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  229  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  230  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  231  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  232  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  233  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  234  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  235  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  236  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  237  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  238  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  239  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  240  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  241  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  242  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  243  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  244  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  245  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  246  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  247  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  248  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  249  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  250  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  251  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  252  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  253  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  254  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  255  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  256  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  257  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  258  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  259  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  260  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  261  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  262  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  263  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  264  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  265  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  266  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  267  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  268  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  269  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  270  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  271  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  272  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  273  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  274  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  275  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  276  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  277  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  278  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  279  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  34  batch  280  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  281  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  282  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  283  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  284  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  285  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  286  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  287  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  288  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  289  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  290  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  291  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  292  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  293  loss  tensor(0.0693, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  294  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  295  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  296  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  297  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  298  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  299  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  300  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  301  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  302  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  303  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  304  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  305  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  306  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  307  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  308  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  309  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  310  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  311  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  312  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  313  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  314  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  315  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  316  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  317  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  318  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  319  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  320  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  321  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  322  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  323  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  324  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  325  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  326  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  327  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  328  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  329  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  330  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  331  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  332  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  333  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  334  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  335  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  336  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  337  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  338  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  339  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  340  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  341  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  342  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  343  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  344  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  345  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  346  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  347  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  348  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  349  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  350  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  351  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  352  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  353  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  354  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  355  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  356  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  357  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  358  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  359  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  360  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  361  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  362  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  363  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  364  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  365  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  366  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  367  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  368  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  369  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  370  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  371  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  372  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  373  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  374  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  375  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  376  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  377  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  378  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  379  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  380  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  381  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  382  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  383  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  384  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  385  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  386  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  387  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  388  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  389  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  390  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  391  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  392  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  393  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  394  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  395  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  396  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  397  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  398  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  399  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  400  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  34  batch  401  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  402  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  403  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  404  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  405  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  406  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  407  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  408  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  409  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  410  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  411  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  412  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  34  batch  413  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch [35/100], loss:33.1523\n",
      "epoch  35  batch  0  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  1  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  2  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  3  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  4  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  5  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  6  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  7  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  8  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  9  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  10  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  11  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  12  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  13  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  14  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  15  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  16  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  17  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  18  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  19  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  20  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  21  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  22  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  23  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  24  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  25  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  26  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  27  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  28  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  29  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  30  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  31  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  32  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  33  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  34  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  35  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  36  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  37  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  38  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  39  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  40  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  41  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  42  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  43  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  44  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  45  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  46  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  47  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  48  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  49  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  50  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  51  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  52  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  53  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  54  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  55  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  56  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  57  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  58  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  59  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  60  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  61  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  62  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  63  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  64  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  65  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  66  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  67  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  68  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  69  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  70  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  71  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  72  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  73  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  74  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  75  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  76  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  77  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  78  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  79  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  80  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  81  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  82  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  83  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  84  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  85  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  86  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  87  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  88  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  89  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  90  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  91  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  92  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  93  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  94  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  95  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  96  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  97  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  98  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  99  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  100  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  101  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  102  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  103  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  104  loss  tensor(0.0678, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  105  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  106  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  107  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  108  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  35  batch  109  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  110  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  111  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  112  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  113  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  114  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  115  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  116  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  117  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  118  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  119  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  120  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  121  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  122  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  123  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  124  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  125  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  126  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  127  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  128  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  129  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  130  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  131  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  132  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  133  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  134  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  135  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  136  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  137  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  138  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  139  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  140  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  141  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  142  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  143  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  144  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  145  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  146  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  147  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  148  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  149  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  150  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  151  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  152  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  153  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  154  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  155  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  156  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  157  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  158  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  159  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  160  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  161  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  162  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  163  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  164  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  165  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  166  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  167  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  168  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  169  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  170  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  171  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  172  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  173  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  174  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  175  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  176  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  177  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  178  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  179  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  180  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  181  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  182  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  183  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  184  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  185  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  186  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  187  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  188  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  189  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  190  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  191  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  192  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  193  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  194  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  195  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  196  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  197  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  198  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  199  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  200  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  201  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  202  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  203  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  204  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  205  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  206  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  207  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  208  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  209  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  210  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  211  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  212  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  213  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  214  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  215  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  216  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  217  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  218  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  219  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  220  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  221  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  222  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  223  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  224  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  225  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  226  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  227  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  228  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  229  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  35  batch  230  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  231  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  232  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  233  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  234  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  235  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  236  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  237  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  238  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  239  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  240  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  241  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  242  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  243  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  244  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  245  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  246  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  247  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  248  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  249  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  250  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  251  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  252  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  253  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  254  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  255  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  256  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  257  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  258  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  259  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  260  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  261  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  262  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  263  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  264  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  265  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  266  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  267  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  268  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  269  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  270  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  271  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  272  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  273  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  274  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  275  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  276  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  277  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  278  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  279  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  280  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  281  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  282  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  283  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  284  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  285  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  286  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  287  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  288  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  289  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  290  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  291  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  292  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  293  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  294  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  295  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  296  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  297  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  298  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  299  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  300  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  301  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  302  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  303  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  304  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  305  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  306  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  307  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  308  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  309  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  310  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  311  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  312  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  313  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  314  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  315  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  316  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  317  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  318  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  319  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  320  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  321  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  322  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  323  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  324  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  325  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  326  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  327  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  328  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  329  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  330  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  331  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  332  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  333  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  334  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  335  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  336  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  337  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  338  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  339  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  340  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  341  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  342  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  343  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  344  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  345  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  346  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  347  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  348  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  349  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  350  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  35  batch  351  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  352  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  353  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  354  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  355  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  356  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  357  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  358  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  359  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  360  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  361  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  362  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  363  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  364  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  365  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  366  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  367  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  368  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  369  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  370  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  371  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  372  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  373  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  374  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  375  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  376  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  377  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  378  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  379  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  380  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  381  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  382  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  383  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  384  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  385  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  386  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  387  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  388  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  389  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  390  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  391  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  392  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  393  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  394  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  395  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  396  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  397  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  398  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  399  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  400  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  401  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  402  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  403  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  404  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  405  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  406  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  407  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  408  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  409  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  410  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  411  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  412  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  35  batch  413  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch [36/100], loss:33.1424\n",
      "epoch  36  batch  0  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  1  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  2  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  3  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  4  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  5  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  6  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  7  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  8  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  9  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  10  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  11  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  12  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  13  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  14  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  15  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  16  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  17  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  18  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  19  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  20  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  21  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  22  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  23  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  24  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  25  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  26  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  27  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  28  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  29  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  30  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  31  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  32  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  33  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  34  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  35  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  36  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  37  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  38  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  39  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  40  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  41  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  42  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  43  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  44  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  45  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  46  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  47  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  48  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  49  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  50  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  51  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  52  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  53  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  54  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  55  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  56  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  57  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  58  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  36  batch  59  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  60  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  61  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  62  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  63  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  64  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  65  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  66  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  67  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  68  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  69  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  70  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  71  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  72  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  73  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  74  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  75  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  76  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  77  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  78  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  79  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  80  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  81  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  82  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  83  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  84  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  85  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  86  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  87  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  88  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  89  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  90  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  91  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  92  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  93  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  94  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  95  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  96  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  97  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  98  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  99  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  100  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  101  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  102  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  103  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  104  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  105  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  106  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  107  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  108  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  109  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  110  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  111  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  112  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  113  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  114  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  115  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  116  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  117  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  118  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  119  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  120  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  121  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  122  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  123  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  124  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  125  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  126  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  127  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  128  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  129  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  130  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  131  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  132  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  133  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  134  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  135  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  136  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  137  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  138  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  139  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  140  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  141  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  142  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  143  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  144  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  145  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  146  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  147  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  148  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  149  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  150  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  151  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  152  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  153  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  154  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  155  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  156  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  157  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  158  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  159  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  160  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  161  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  162  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  163  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  164  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  165  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  166  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  167  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  168  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  169  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  170  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  171  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  172  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  173  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  174  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  175  loss  tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  176  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  177  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  178  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  179  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  180  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  36  batch  181  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  182  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  183  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  184  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  185  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  186  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  187  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  188  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  189  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  190  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  191  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  192  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  193  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  194  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  195  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  196  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  197  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  198  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  199  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  200  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  201  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  202  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  203  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  204  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  205  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  206  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  207  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  208  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  209  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  210  loss  tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  211  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  212  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  213  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  214  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  215  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  216  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  217  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  218  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  219  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  220  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  221  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  222  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  223  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  224  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  225  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  226  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  227  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  228  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  229  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  230  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  231  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  232  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  233  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  234  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  235  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  236  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  237  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  238  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  239  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  240  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  241  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  242  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  243  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  244  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  245  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  246  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  247  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  248  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  249  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  250  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  251  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  252  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  253  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  254  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  255  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  256  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  257  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  258  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  259  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  260  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  261  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  262  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  263  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  264  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  265  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  266  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  267  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  268  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  269  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  270  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  271  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  272  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  273  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  274  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  275  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  276  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  277  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  278  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  279  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  280  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  281  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  282  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  283  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  284  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  285  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  286  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  287  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  288  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  289  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  290  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  291  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  292  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  293  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  294  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  295  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  296  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  297  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  298  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  299  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  300  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  301  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  36  batch  302  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  303  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  304  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  305  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  306  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  307  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  308  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  309  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  310  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  311  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  312  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  313  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  314  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  315  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  316  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  317  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  318  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  319  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  320  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  321  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  322  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  323  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  324  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  325  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  326  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  327  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  328  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  329  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  330  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  331  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  332  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  333  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  334  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  335  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  336  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  337  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  338  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  339  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  340  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  341  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  342  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  343  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  344  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  345  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  346  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  347  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  348  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  349  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  350  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  351  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  352  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  353  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  354  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  355  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  356  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  357  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  358  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  359  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  360  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  361  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  362  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  363  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  364  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  365  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  366  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  367  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  368  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  369  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  370  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  371  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  372  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  373  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  374  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  375  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  376  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  377  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  378  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  379  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  380  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  381  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  382  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  383  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  384  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  385  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  386  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  387  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  388  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  389  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  390  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  391  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  392  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  393  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  394  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  395  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  396  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  397  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  398  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  399  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  400  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  401  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  402  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  403  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  404  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  405  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  406  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  407  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  408  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  409  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  410  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  411  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  412  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  36  batch  413  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch [37/100], loss:33.1400\n",
      "epoch  37  batch  0  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  1  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  2  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  3  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  4  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  5  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  6  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  7  loss  tensor(0.0971, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  8  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  37  batch  9  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  10  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  11  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  12  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  13  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  14  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  15  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  16  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  17  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  18  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  19  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  20  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  21  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  22  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  23  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  24  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  25  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  26  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  27  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  28  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  29  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  30  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  31  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  32  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  33  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  34  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  35  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  36  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  37  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  38  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  39  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  40  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  41  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  42  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  43  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  44  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  45  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  46  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  47  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  48  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  49  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  50  loss  tensor(0.0671, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  51  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  52  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  53  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  54  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  55  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  56  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  57  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  58  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  59  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  60  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  61  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  62  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  63  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  64  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  65  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  66  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  67  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  68  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  69  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  70  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  71  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  72  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  73  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  74  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  75  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  76  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  77  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  78  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  79  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  80  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  81  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  82  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  83  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  84  loss  tensor(0.0693, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  85  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  86  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  87  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  88  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  89  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  90  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  91  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  92  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  93  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  94  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  95  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  96  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  97  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  98  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  99  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  100  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  101  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  102  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  103  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  104  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  105  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  106  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  107  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  108  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  109  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  110  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  111  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  112  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  113  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  114  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  115  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  116  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  117  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  118  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  119  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  120  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  121  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  122  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  123  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  124  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  125  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  126  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  127  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  128  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  129  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  130  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  37  batch  131  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  132  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  133  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  134  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  135  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  136  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  137  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  138  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  139  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  140  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  141  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  142  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  143  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  144  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  145  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  146  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  147  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  148  loss  tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  149  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  150  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  151  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  152  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  153  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  154  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  155  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  156  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  157  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  158  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  159  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  160  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  161  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  162  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  163  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  164  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  165  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  166  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  167  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  168  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  169  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  170  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  171  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  172  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  173  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  174  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  175  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  176  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  177  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  178  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  179  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  180  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  181  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  182  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  183  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  184  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  185  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  186  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  187  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  188  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  189  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  190  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  191  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  192  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  193  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  194  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  195  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  196  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  197  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  198  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  199  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  200  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  201  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  202  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  203  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  204  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  205  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  206  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  207  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  208  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  209  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  210  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  211  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  212  loss  tensor(0.0670, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  213  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  214  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  215  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  216  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  217  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  218  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  219  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  220  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  221  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  222  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  223  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  224  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  225  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  226  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  227  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  228  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  229  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  230  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  231  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  232  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  233  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  234  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  235  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  236  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  237  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  238  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  239  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  240  loss  tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  241  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  242  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  243  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  244  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  245  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  246  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  247  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  248  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  249  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  250  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  251  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  37  batch  252  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  253  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  254  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  255  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  256  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  257  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  258  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  259  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  260  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  261  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  262  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  263  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  264  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  265  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  266  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  267  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  268  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  269  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  270  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  271  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  272  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  273  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  274  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  275  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  276  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  277  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  278  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  279  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  280  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  281  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  282  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  283  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  284  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  285  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  286  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  287  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  288  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  289  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  290  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  291  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  292  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  293  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  294  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  295  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  296  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  297  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  298  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  299  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  300  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  301  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  302  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  303  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  304  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  305  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  306  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  307  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  308  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  309  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  310  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  311  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  312  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  313  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  314  loss  tensor(0.0661, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  315  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  316  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  317  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  318  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  319  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  320  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  321  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  322  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  323  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  324  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  325  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  326  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  327  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  328  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  329  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  330  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  331  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  332  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  333  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  334  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  335  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  336  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  337  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  338  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  339  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  340  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  341  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  342  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  343  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  344  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  345  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  346  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  347  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  348  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  349  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  350  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  351  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  352  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  353  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  354  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  355  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  356  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  357  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  358  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  359  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  360  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  361  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  362  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  363  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  364  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  365  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  366  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  367  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  368  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  369  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  370  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  371  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  372  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  37  batch  373  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  374  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  375  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  376  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  377  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  378  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  379  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  380  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  381  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  382  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  383  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  384  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  385  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  386  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  387  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  388  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  389  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  390  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  391  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  392  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  393  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  394  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  395  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  396  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  397  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  398  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  399  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  400  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  401  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  402  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  403  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  404  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  405  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  406  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  407  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  408  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  409  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  410  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  411  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  412  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  37  batch  413  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch [38/100], loss:33.1432\n",
      "epoch  38  batch  0  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  1  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  2  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  3  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  4  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  5  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  6  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  7  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  8  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  9  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  10  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  11  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  12  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  13  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  14  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  15  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  16  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  17  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  18  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  19  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  20  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  21  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  22  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  23  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  24  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  25  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  26  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  27  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  28  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  29  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  30  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  31  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  32  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  33  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  34  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  35  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  36  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  37  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  38  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  39  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  40  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  41  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  42  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  43  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  44  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  45  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  46  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  47  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  48  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  49  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  50  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  51  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  52  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  53  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  54  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  55  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  56  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  57  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  58  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  59  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  60  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  61  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  62  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  63  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  64  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  65  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  66  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  67  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  68  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  69  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  70  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  71  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  72  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  73  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  74  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  75  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  76  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  77  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  78  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  79  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  80  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  38  batch  81  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  82  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  83  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  84  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  85  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  86  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  87  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  88  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  89  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  90  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  91  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  92  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  93  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  94  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  95  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  96  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  97  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  98  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  99  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  100  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  101  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  102  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  103  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  104  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  105  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  106  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  107  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  108  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  109  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  110  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  111  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  112  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  113  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  114  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  115  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  116  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  117  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  118  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  119  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  120  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  121  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  122  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  123  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  124  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  125  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  126  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  127  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  128  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  129  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  130  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  131  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  132  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  133  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  134  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  135  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  136  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  137  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  138  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  139  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  140  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  141  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  142  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  143  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  144  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  145  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  146  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  147  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  148  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  149  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  150  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  151  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  152  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  153  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  154  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  155  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  156  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  157  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  158  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  159  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  160  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  161  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  162  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  163  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  164  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  165  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  166  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  167  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  168  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  169  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  170  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  171  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  172  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  173  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  174  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  175  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  176  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  177  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  178  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  179  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  180  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  181  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  182  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  183  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  184  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  185  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  186  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  187  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  188  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  189  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  190  loss  tensor(0.0665, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  191  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  192  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  193  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  194  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  195  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  196  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  197  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  198  loss  tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  199  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  200  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  201  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  38  batch  202  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  203  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  204  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  205  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  206  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  207  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  208  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  209  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  210  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  211  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  212  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  213  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  214  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  215  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  216  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  217  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  218  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  219  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  220  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  221  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  222  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  223  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  224  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  225  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  226  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  227  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  228  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  229  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  230  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  231  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  232  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  233  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  234  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  235  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  236  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  237  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  238  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  239  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  240  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  241  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  242  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  243  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  244  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  245  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  246  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  247  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  248  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  249  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  250  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  251  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  252  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  253  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  254  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  255  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  256  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  257  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  258  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  259  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  260  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  261  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  262  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  263  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  264  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  265  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  266  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  267  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  268  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  269  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  270  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  271  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  272  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  273  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  274  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  275  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  276  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  277  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  278  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  279  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  280  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  281  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  282  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  283  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  284  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  285  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  286  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  287  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  288  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  289  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  290  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  291  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  292  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  293  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  294  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  295  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  296  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  297  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  298  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  299  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  300  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  301  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  302  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  303  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  304  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  305  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  306  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  307  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  308  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  309  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  310  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  311  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  312  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  313  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  314  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  315  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  316  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  317  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  318  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  319  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  320  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  321  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  322  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  38  batch  323  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  324  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  325  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  326  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  327  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  328  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  329  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  330  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  331  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  332  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  333  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  334  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  335  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  336  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  337  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  338  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  339  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  340  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  341  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  342  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  343  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  344  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  345  loss  tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  346  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  347  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  348  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  349  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  350  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  351  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  352  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  353  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  354  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  355  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  356  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  357  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  358  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  359  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  360  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  361  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  362  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  363  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  364  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  365  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  366  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  367  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  368  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  369  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  370  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  371  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  372  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  373  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  374  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  375  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  376  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  377  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  378  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  379  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  380  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  381  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  382  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  383  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  384  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  385  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  386  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  387  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  388  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  389  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  390  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  391  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  392  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  393  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  394  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  395  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  396  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  397  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  398  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  399  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  400  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  401  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  402  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  403  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  404  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  405  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  406  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  407  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  408  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  409  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  410  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  411  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  412  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  38  batch  413  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch [39/100], loss:33.1438\n",
      "epoch  39  batch  0  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  1  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  2  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  3  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  4  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  5  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  6  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  7  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  8  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  9  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  10  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  11  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  12  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  13  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  14  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  15  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  16  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  17  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  18  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  19  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  20  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  21  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  22  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  23  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  24  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  25  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  26  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  27  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  28  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  29  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  39  batch  30  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  31  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  32  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  33  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  34  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  35  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  36  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  37  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  38  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  39  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  40  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  41  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  42  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  43  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  44  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  45  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  46  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  47  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  48  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  49  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  50  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  51  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  52  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  53  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  54  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  55  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  56  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  57  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  58  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  59  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  60  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  61  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  62  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  63  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  64  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  65  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  66  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  67  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  68  loss  tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  69  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  70  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  71  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  72  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  73  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  74  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  75  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  76  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  77  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  78  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  79  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  80  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  81  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  82  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  83  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  84  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  85  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  86  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  87  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  88  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  89  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  90  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  91  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  92  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  93  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  94  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  95  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  96  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  97  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  98  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  99  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  100  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  101  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  102  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  103  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  104  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  105  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  106  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  107  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  108  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  109  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  110  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  111  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  112  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  113  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  114  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  115  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  116  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  117  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  118  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  119  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  120  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  121  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  122  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  123  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  124  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  125  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  126  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  127  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  128  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  129  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  130  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  131  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  132  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  133  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  134  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  135  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  136  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  137  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  138  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  139  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  140  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  141  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  142  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  143  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  144  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  145  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  146  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  147  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  148  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  149  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  150  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  151  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  39  batch  152  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  153  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  154  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  155  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  156  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  157  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  158  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  159  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  160  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  161  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  162  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  163  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  164  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  165  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  166  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  167  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  168  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  169  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  170  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  171  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  172  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  173  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  174  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  175  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  176  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  177  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  178  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  179  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  180  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  181  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  182  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  183  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  184  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  185  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  186  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  187  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  188  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  189  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  190  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  191  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  192  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  193  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  194  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  195  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  196  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  197  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  198  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  199  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  200  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  201  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  202  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  203  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  204  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  205  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  206  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  207  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  208  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  209  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  210  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  211  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  212  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  213  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  214  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  215  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  216  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  217  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  218  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  219  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  220  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  221  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  222  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  223  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  224  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  225  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  226  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  227  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  228  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  229  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  230  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  231  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  232  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  233  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  234  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  235  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  236  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  237  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  238  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  239  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  240  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  241  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  242  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  243  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  244  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  245  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  246  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  247  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  248  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  249  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  250  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  251  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  252  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  253  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  254  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  255  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  256  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  257  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  258  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  259  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  260  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  261  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  262  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  263  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  264  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  265  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  266  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  267  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  268  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  269  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  270  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  271  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  272  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  39  batch  273  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  274  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  275  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  276  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  277  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  278  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  279  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  280  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  281  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  282  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  283  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  284  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  285  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  286  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  287  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  288  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  289  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  290  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  291  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  292  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  293  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  294  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  295  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  296  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  297  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  298  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  299  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  300  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  301  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  302  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  303  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  304  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  305  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  306  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  307  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  308  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  309  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  310  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  311  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  312  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  313  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  314  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  315  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  316  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  317  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  318  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  319  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  320  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  321  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  322  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  323  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  324  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  325  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  326  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  327  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  328  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  329  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  330  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  331  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  332  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  333  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  334  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  335  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  336  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  337  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  338  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  339  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  340  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  341  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  342  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  343  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  344  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  345  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  346  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  347  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  348  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  349  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  350  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  351  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  352  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  353  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  354  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  355  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  356  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  357  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  358  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  359  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  360  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  361  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  362  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  363  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  364  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  365  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  366  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  367  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  368  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  369  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  370  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  371  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  372  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  373  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  374  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  375  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  376  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  377  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  378  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  379  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  380  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  381  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  382  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  383  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  384  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  385  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  386  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  387  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  388  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  389  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  390  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  391  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  392  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  393  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  39  batch  394  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  395  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  396  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  397  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  398  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  399  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  400  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  401  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  402  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  403  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  404  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  405  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  406  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  407  loss  tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  408  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  409  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  410  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  411  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  412  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  39  batch  413  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch [40/100], loss:33.1605\n",
      "epoch  40  batch  0  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  1  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  2  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  3  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  4  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  5  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  6  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  7  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  8  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  9  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  10  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  11  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  12  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  13  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  14  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  15  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  16  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  17  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  18  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  19  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  20  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  21  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  22  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  23  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  24  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  25  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  26  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  27  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  28  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  29  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  30  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  31  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  32  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  33  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  34  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  35  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  36  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  37  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  38  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  39  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  40  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  41  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  42  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  43  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  44  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  45  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  46  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  47  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  48  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  49  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  50  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  51  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  52  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  53  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  54  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  55  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  56  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  57  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  58  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  59  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  60  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  61  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  62  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  63  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  64  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  65  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  66  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  67  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  68  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  69  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  70  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  71  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  72  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  73  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  74  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  75  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  76  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  77  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  78  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  79  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  80  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  81  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  82  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  83  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  84  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  85  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  86  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  87  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  88  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  89  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  90  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  91  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  92  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  93  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  94  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  95  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  96  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  97  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  98  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  99  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  100  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  101  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  40  batch  102  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  103  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  104  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  105  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  106  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  107  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  108  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  109  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  110  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  111  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  112  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  113  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  114  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  115  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  116  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  117  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  118  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  119  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  120  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  121  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  122  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  123  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  124  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  125  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  126  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  127  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  128  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  129  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  130  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  131  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  132  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  133  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  134  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  135  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  136  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  137  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  138  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  139  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  140  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  141  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  142  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  143  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  144  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  145  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  146  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  147  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  148  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  149  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  150  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  151  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  152  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  153  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  154  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  155  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  156  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  157  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  158  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  159  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  160  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  161  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  162  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  163  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  164  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  165  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  166  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  167  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  168  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  169  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  170  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  171  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  172  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  173  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  174  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  175  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  176  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  177  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  178  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  179  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  180  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  181  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  182  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  183  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  184  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  185  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  186  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  187  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  188  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  189  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  190  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  191  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  192  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  193  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  194  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  195  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  196  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  197  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  198  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  199  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  200  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  201  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  202  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  203  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  204  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  205  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  206  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  207  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  208  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  209  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  210  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  211  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  212  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  213  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  214  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  215  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  216  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  217  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  218  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  219  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  220  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  221  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  222  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  40  batch  223  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  224  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  225  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  226  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  227  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  228  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  229  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  230  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  231  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  232  loss  tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  233  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  234  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  235  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  236  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  237  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  238  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  239  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  240  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  241  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  242  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  243  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  244  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  245  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  246  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  247  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  248  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  249  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  250  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  251  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  252  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  253  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  254  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  255  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  256  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  257  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  258  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  259  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  260  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  261  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  262  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  263  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  264  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  265  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  266  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  267  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  268  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  269  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  270  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  271  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  272  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  273  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  274  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  275  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  276  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  277  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  278  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  279  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  280  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  281  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  282  loss  tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  283  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  284  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  285  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  286  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  287  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  288  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  289  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  290  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  291  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  292  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  293  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  294  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  295  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  296  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  297  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  298  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  299  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  300  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  301  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  302  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  303  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  304  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  305  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  306  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  307  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  308  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  309  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  310  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  311  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  312  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  313  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  314  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  315  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  316  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  317  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  318  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  319  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  320  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  321  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  322  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  323  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  324  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  325  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  326  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  327  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  328  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  329  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  330  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  331  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  332  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  333  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  334  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  335  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  336  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  337  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  338  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  339  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  340  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  341  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  342  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  343  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  40  batch  344  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  345  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  346  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  347  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  348  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  349  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  350  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  351  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  352  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  353  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  354  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  355  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  356  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  357  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  358  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  359  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  360  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  361  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  362  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  363  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  364  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  365  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  366  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  367  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  368  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  369  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  370  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  371  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  372  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  373  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  374  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  375  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  376  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  377  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  378  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  379  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  380  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  381  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  382  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  383  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  384  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  385  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  386  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  387  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  388  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  389  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  390  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  391  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  392  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  393  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  394  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  395  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  396  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  397  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  398  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  399  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  400  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  401  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  402  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  403  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  404  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  405  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  406  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  407  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  408  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  409  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  410  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  411  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  412  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  40  batch  413  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch [41/100], loss:33.1389\n",
      "epoch  41  batch  0  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  1  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  2  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  3  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  4  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  5  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  6  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  7  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  8  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  9  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  10  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  11  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  12  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  13  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  14  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  15  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  16  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  17  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  18  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  19  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  20  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  21  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  22  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  23  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  24  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  25  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  26  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  27  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  28  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  29  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  30  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  31  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  32  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  33  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  34  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  35  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  36  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  37  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  38  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  39  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  40  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  41  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  42  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  43  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  44  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  45  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  46  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  47  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  48  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  49  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  50  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  41  batch  51  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  52  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  53  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  54  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  55  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  56  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  57  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  58  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  59  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  60  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  61  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  62  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  63  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  64  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  65  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  66  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  67  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  68  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  69  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  70  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  71  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  72  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  73  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  74  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  75  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  76  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  77  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  78  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  79  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  80  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  81  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  82  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  83  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  84  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  85  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  86  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  87  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  88  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  89  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  90  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  91  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  92  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  93  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  94  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  95  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  96  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  97  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  98  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  99  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  100  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  101  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  102  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  103  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  104  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  105  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  106  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  107  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  108  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  109  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  110  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  111  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  112  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  113  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  114  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  115  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  116  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  117  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  118  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  119  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  120  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  121  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  122  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  123  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  124  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  125  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  126  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  127  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  128  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  129  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  130  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  131  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  132  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  133  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  134  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  135  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  136  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  137  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  138  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  139  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  140  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  141  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  142  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  143  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  144  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  145  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  146  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  147  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  148  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  149  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  150  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  151  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  152  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  153  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  154  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  155  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  156  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  157  loss  tensor(0.0667, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  158  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  159  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  160  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  161  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  162  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  163  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  164  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  165  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  166  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  167  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  168  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  169  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  170  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  171  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  172  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  41  batch  173  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  174  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  175  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  176  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  177  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  178  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  179  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  180  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  181  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  182  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  183  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  184  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  185  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  186  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  187  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  188  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  189  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  190  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  191  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  192  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  193  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  194  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  195  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  196  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  197  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  198  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  199  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  200  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  201  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  202  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  203  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  204  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  205  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  206  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  207  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  208  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  209  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  210  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  211  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  212  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  213  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  214  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  215  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  216  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  217  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  218  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  219  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  220  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  221  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  222  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  223  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  224  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  225  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  226  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  227  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  228  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  229  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  230  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  231  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  232  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  233  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  234  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  235  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  236  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  237  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  238  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  239  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  240  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  241  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  242  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  243  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  244  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  245  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  246  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  247  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  248  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  249  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  250  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  251  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  252  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  253  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  254  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  255  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  256  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  257  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  258  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  259  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  260  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  261  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  262  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  263  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  264  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  265  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  266  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  267  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  268  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  269  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  270  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  271  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  272  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  273  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  274  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  275  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  276  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  277  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  278  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  279  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  280  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  281  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  282  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  283  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  284  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  285  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  286  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  287  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  288  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  289  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  290  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  291  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  292  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  293  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  41  batch  294  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  295  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  296  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  297  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  298  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  299  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  300  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  301  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  302  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  303  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  304  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  305  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  306  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  307  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  308  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  309  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  310  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  311  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  312  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  313  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  314  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  315  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  316  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  317  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  318  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  319  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  320  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  321  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  322  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  323  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  324  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  325  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  326  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  327  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  328  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  329  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  330  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  331  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  332  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  333  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  334  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  335  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  336  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  337  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  338  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  339  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  340  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  341  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  342  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  343  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  344  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  345  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  346  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  347  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  348  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  349  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  350  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  351  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  352  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  353  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  354  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  355  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  356  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  357  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  358  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  359  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  360  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  361  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  362  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  363  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  364  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  365  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  366  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  367  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  368  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  369  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  370  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  371  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  372  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  373  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  374  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  375  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  376  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  377  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  378  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  379  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  380  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  381  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  382  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  383  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  384  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  385  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  386  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  387  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  388  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  389  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  390  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  391  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  392  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  393  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  394  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  395  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  396  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  397  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  398  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  399  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  400  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  401  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  402  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  403  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  404  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  405  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  406  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  407  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  408  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  409  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  410  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  411  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  412  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  41  batch  413  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch [42/100], loss:33.1509\n",
      "epoch  42  batch  0  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  42  batch  1  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  2  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  3  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  4  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  5  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  6  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  7  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  8  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  9  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  10  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  11  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  12  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  13  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  14  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  15  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  16  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  17  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  18  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  19  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  20  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  21  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  22  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  23  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  24  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  25  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  26  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  27  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  28  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  29  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  30  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  31  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  32  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  33  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  34  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  35  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  36  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  37  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  38  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  39  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  40  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  41  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  42  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  43  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  44  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  45  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  46  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  47  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  48  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  49  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  50  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  51  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  52  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  53  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  54  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  55  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  56  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  57  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  58  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  59  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  60  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  61  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  62  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  63  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  64  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  65  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  66  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  67  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  68  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  69  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  70  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  71  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  72  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  73  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  74  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  75  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  76  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  77  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  78  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  79  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  80  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  81  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  82  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  83  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  84  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  85  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  86  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  87  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  88  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  89  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  90  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  91  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  92  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  93  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  94  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  95  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  96  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  97  loss  tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  98  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  99  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  100  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  101  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  102  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  103  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  104  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  105  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  106  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  107  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  108  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  109  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  110  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  111  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  112  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  113  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  114  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  115  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  116  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  117  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  118  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  119  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  120  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  121  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  122  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  123  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  42  batch  124  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  125  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  126  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  127  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  128  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  129  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  130  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  131  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  132  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  133  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  134  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  135  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  136  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  137  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  138  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  139  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  140  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  141  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  142  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  143  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  144  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  145  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  146  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  147  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  148  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  149  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  150  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  151  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  152  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  153  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  154  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  155  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  156  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  157  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  158  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  159  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  160  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  161  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  162  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  163  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  164  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  165  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  166  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  167  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  168  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  169  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  170  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  171  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  172  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  173  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  174  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  175  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  176  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  177  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  178  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  179  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  180  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  181  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  182  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  183  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  184  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  185  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  186  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  187  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  188  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  189  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  190  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  191  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  192  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  193  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  194  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  195  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  196  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  197  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  198  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  199  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  200  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  201  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  202  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  203  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  204  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  205  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  206  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  207  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  208  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  209  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  210  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  211  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  212  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  213  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  214  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  215  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  216  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  217  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  218  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  219  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  220  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  221  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  222  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  223  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  224  loss  tensor(0.0974, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  225  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  226  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  227  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  228  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  229  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  230  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  231  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  232  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  233  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  234  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  235  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  236  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  237  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  238  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  239  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  240  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  241  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  242  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  243  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  244  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  42  batch  245  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  246  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  247  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  248  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  249  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  250  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  251  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  252  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  253  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  254  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  255  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  256  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  257  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  258  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  259  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  260  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  261  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  262  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  263  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  264  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  265  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  266  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  267  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  268  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  269  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  270  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  271  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  272  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  273  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  274  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  275  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  276  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  277  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  278  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  279  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  280  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  281  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  282  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  283  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  284  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  285  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  286  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  287  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  288  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  289  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  290  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  291  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  292  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  293  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  294  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  295  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  296  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  297  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  298  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  299  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  300  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  301  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  302  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  303  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  304  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  305  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  306  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  307  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  308  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  309  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  310  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  311  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  312  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  313  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  314  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  315  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  316  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  317  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  318  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  319  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  320  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  321  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  322  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  323  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  324  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  325  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  326  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  327  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  328  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  329  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  330  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  331  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  332  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  333  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  334  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  335  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  336  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  337  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  338  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  339  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  340  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  341  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  342  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  343  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  344  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  345  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  346  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  347  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  348  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  349  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  350  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  351  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  352  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  353  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  354  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  355  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  356  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  357  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  358  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  359  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  360  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  361  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  362  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  363  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  364  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  365  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  42  batch  366  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  367  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  368  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  369  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  370  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  371  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  372  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  373  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  374  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  375  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  376  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  377  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  378  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  379  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  380  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  381  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  382  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  383  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  384  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  385  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  386  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  387  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  388  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  389  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  390  loss  tensor(0.0677, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  391  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  392  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  393  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  394  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  395  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  396  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  397  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  398  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  399  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  400  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  401  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  402  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  403  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  404  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  405  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  406  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  407  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  408  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  409  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  410  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  411  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  412  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  42  batch  413  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch [43/100], loss:33.1410\n",
      "epoch  43  batch  0  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  1  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  2  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  3  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  4  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  5  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  6  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  7  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  8  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  9  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  10  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  11  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  12  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  13  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  14  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  15  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  16  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  17  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  18  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  19  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  20  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  21  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  22  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  23  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  24  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  25  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  26  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  27  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  28  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  29  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  30  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  31  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  32  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  33  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  34  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  35  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  36  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  37  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  38  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  39  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  40  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  41  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  42  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  43  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  44  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  45  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  46  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  47  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  48  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  49  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  50  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  51  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  52  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  53  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  54  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  55  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  56  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  57  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  58  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  59  loss  tensor(0.0668, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  60  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  61  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  62  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  63  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  64  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  65  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  66  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  67  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  68  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  69  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  70  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  71  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  72  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  73  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  43  batch  74  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  75  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  76  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  77  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  78  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  79  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  80  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  81  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  82  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  83  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  84  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  85  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  86  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  87  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  88  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  89  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  90  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  91  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  92  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  93  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  94  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  95  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  96  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  97  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  98  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  99  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  100  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  101  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  102  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  103  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  104  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  105  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  106  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  107  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  108  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  109  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  110  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  111  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  112  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  113  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  114  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  115  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  116  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  117  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  118  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  119  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  120  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  121  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  122  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  123  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  124  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  125  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  126  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  127  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  128  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  129  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  130  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  131  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  132  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  133  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  134  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  135  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  136  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  137  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  138  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  139  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  140  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  141  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  142  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  143  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  144  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  145  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  146  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  147  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  148  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  149  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  150  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  151  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  152  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  153  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  154  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  155  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  156  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  157  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  158  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  159  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  160  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  161  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  162  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  163  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  164  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  165  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  166  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  167  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  168  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  169  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  170  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  171  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  172  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  173  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  174  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  175  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  176  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  177  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  178  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  179  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  180  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  181  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  182  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  183  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  184  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  185  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  186  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  187  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  188  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  189  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  190  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  191  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  192  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  193  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  194  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  43  batch  195  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  196  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  197  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  198  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  199  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  200  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  201  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  202  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  203  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  204  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  205  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  206  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  207  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  208  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  209  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  210  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  211  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  212  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  213  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  214  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  215  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  216  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  217  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  218  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  219  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  220  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  221  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  222  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  223  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  224  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  225  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  226  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  227  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  228  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  229  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  230  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  231  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  232  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  233  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  234  loss  tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  235  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  236  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  237  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  238  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  239  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  240  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  241  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  242  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  243  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  244  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  245  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  246  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  247  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  248  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  249  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  250  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  251  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  252  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  253  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  254  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  255  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  256  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  257  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  258  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  259  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  260  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  261  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  262  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  263  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  264  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  265  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  266  loss  tensor(0.0665, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  267  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  268  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  269  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  270  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  271  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  272  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  273  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  274  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  275  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  276  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  277  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  278  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  279  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  280  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  281  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  282  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  283  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  284  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  285  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  286  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  287  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  288  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  289  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  290  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  291  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  292  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  293  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  294  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  295  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  296  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  297  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  298  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  299  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  300  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  301  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  302  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  303  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  304  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  305  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  306  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  307  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  308  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  309  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  310  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  311  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  312  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  313  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  314  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  315  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  43  batch  316  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  317  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  318  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  319  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  320  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  321  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  322  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  323  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  324  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  325  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  326  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  327  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  328  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  329  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  330  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  331  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  332  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  333  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  334  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  335  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  336  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  337  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  338  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  339  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  340  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  341  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  342  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  343  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  344  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  345  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  346  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  347  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  348  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  349  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  350  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  351  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  352  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  353  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  354  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  355  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  356  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  357  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  358  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  359  loss  tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  360  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  361  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  362  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  363  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  364  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  365  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  366  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  367  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  368  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  369  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  370  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  371  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  372  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  373  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  374  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  375  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  376  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  377  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  378  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  379  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  380  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  381  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  382  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  383  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  384  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  385  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  386  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  387  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  388  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  389  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  390  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  391  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  392  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  393  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  394  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  395  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  396  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  397  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  398  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  399  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  400  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  401  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  402  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  403  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  404  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  405  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  406  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  407  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  408  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  409  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  410  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  411  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  412  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  43  batch  413  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch [44/100], loss:33.1400\n",
      "epoch  44  batch  0  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  1  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  2  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  3  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  4  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  5  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  6  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  7  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  8  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  9  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  10  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  11  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  12  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  13  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  14  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  15  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  16  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  17  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  18  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  19  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  20  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  21  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  22  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  44  batch  23  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  24  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  25  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  26  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  27  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  28  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  29  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  30  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  31  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  32  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  33  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  34  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  35  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  36  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  37  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  38  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  39  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  40  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  41  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  42  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  43  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  44  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  45  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  46  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  47  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  48  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  49  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  50  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  51  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  52  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  53  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  54  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  55  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  56  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  57  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  58  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  59  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  60  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  61  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  62  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  63  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  64  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  65  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  66  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  67  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  68  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  69  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  70  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  71  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  72  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  73  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  74  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  75  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  76  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  77  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  78  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  79  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  80  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  81  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  82  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  83  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  84  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  85  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  86  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  87  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  88  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  89  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  90  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  91  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  92  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  93  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  94  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  95  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  96  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  97  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  98  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  99  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  100  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  101  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  102  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  103  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  104  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  105  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  106  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  107  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  108  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  109  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  110  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  111  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  112  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  113  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  114  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  115  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  116  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  117  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  118  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  119  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  120  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  121  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  122  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  123  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  124  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  125  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  126  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  127  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  128  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  129  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  130  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  131  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  132  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  133  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  134  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  135  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  136  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  137  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  138  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  139  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  140  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  141  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  142  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  143  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  144  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  44  batch  145  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  146  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  147  loss  tensor(0.0664, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  148  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  149  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  150  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  151  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  152  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  153  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  154  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  155  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  156  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  157  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  158  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  159  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  160  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  161  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  162  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  163  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  164  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  165  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  166  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  167  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  168  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  169  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  170  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  171  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  172  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  173  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  174  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  175  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  176  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  177  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  178  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  179  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  180  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  181  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  182  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  183  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  184  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  185  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  186  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  187  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  188  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  189  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  190  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  191  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  192  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  193  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  194  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  195  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  196  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  197  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  198  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  199  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  200  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  201  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  202  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  203  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  204  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  205  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  206  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  207  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  208  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  209  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  210  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  211  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  212  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  213  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  214  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  215  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  216  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  217  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  218  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  219  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  220  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  221  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  222  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  223  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  224  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  225  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  226  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  227  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  228  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  229  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  230  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  231  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  232  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  233  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  234  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  235  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  236  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  237  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  238  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  239  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  240  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  241  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  242  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  243  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  244  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  245  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  246  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  247  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  248  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  249  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  250  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  251  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  252  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  253  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  254  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  255  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  256  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  257  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  258  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  259  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  260  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  261  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  262  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  263  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  264  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  265  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  44  batch  266  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  267  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  268  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  269  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  270  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  271  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  272  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  273  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  274  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  275  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  276  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  277  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  278  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  279  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  280  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  281  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  282  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  283  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  284  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  285  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  286  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  287  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  288  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  289  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  290  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  291  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  292  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  293  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  294  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  295  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  296  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  297  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  298  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  299  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  300  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  301  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  302  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  303  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  304  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  305  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  306  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  307  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  308  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  309  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  310  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  311  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  312  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  313  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  314  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  315  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  316  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  317  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  318  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  319  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  320  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  321  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  322  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  323  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  324  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  325  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  326  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  327  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  328  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  329  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  330  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  331  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  332  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  333  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  334  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  335  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  336  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  337  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  338  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  339  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  340  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  341  loss  tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  342  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  343  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  344  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  345  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  346  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  347  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  348  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  349  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  350  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  351  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  352  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  353  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  354  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  355  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  356  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  357  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  358  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  359  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  360  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  361  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  362  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  363  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  364  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  365  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  366  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  367  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  368  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  369  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  370  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  371  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  372  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  373  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  374  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  375  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  376  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  377  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  378  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  379  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  380  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  381  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  382  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  383  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  384  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  385  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  386  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  44  batch  387  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  388  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  389  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  390  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  391  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  392  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  393  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  394  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  395  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  396  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  397  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  398  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  399  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  400  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  401  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  402  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  403  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  404  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  405  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  406  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  407  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  408  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  409  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  410  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  411  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  412  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  44  batch  413  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch [45/100], loss:33.1410\n",
      "epoch  45  batch  0  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  1  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  2  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  3  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  4  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  5  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  6  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  7  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  8  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  9  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  10  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  11  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  12  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  13  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  14  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  15  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  16  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  17  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  18  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  19  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  20  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  21  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  22  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  23  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  24  loss  tensor(0.0639, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  25  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  26  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  27  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  28  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  29  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  30  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  31  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  32  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  33  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  34  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  35  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  36  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  37  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  38  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  39  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  40  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  41  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  42  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  43  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  44  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  45  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  46  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  47  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  48  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  49  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  50  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  51  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  52  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  53  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  54  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  55  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  56  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  57  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  58  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  59  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  60  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  61  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  62  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  63  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  64  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  65  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  66  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  67  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  68  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  69  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  70  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  71  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  72  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  73  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  74  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  75  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  76  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  77  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  78  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  79  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  80  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  81  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  82  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  83  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  84  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  85  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  86  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  87  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  88  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  89  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  90  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  91  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  92  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  93  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  94  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  45  batch  95  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  96  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  97  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  98  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  99  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  100  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  101  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  102  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  103  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  104  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  105  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  106  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  107  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  108  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  109  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  110  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  111  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  112  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  113  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  114  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  115  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  116  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  117  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  118  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  119  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  120  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  121  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  122  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  123  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  124  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  125  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  126  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  127  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  128  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  129  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  130  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  131  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  132  loss  tensor(0.0675, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  133  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  134  loss  tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  135  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  136  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  137  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  138  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  139  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  140  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  141  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  142  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  143  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  144  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  145  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  146  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  147  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  148  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  149  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  150  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  151  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  152  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  153  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  154  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  155  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  156  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  157  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  158  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  159  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  160  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  161  loss  tensor(0.0670, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  162  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  163  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  164  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  165  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  166  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  167  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  168  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  169  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  170  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  171  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  172  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  173  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  174  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  175  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  176  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  177  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  178  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  179  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  180  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  181  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  182  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  183  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  184  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  185  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  186  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  187  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  188  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  189  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  190  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  191  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  192  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  193  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  194  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  195  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  196  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  197  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  198  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  199  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  200  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  201  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  202  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  203  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  204  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  205  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  206  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  207  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  208  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  209  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  210  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  211  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  212  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  213  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  214  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  215  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  45  batch  216  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  217  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  218  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  219  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  220  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  221  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  222  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  223  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  224  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  225  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  226  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  227  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  228  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  229  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  230  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  231  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  232  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  233  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  234  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  235  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  236  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  237  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  238  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  239  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  240  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  241  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  242  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  243  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  244  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  245  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  246  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  247  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  248  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  249  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  250  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  251  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  252  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  253  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  254  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  255  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  256  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  257  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  258  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  259  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  260  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  261  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  262  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  263  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  264  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  265  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  266  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  267  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  268  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  269  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  270  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  271  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  272  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  273  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  274  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  275  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  276  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  277  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  278  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  279  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  280  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  281  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  282  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  283  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  284  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  285  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  286  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  287  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  288  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  289  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  290  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  291  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  292  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  293  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  294  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  295  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  296  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  297  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  298  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  299  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  300  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  301  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  302  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  303  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  304  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  305  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  306  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  307  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  308  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  309  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  310  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  311  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  312  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  313  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  314  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  315  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  316  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  317  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  318  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  319  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  320  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  321  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  322  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  323  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  324  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  325  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  326  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  327  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  328  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  329  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  330  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  331  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  332  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  333  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  334  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  335  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  336  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  45  batch  337  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  338  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  339  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  340  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  341  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  342  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  343  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  344  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  345  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  346  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  347  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  348  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  349  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  350  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  351  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  352  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  353  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  354  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  355  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  356  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  357  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  358  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  359  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  360  loss  tensor(0.0662, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  361  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  362  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  363  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  364  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  365  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  366  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  367  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  368  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  369  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  370  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  371  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  372  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  373  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  374  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  375  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  376  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  377  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  378  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  379  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  380  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  381  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  382  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  383  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  384  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  385  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  386  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  387  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  388  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  389  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  390  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  391  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  392  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  393  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  394  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  395  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  396  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  397  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  398  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  399  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  400  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  401  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  402  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  403  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  404  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  405  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  406  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  407  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  408  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  409  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  410  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  411  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  412  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  45  batch  413  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch [46/100], loss:33.1365\n",
      "epoch  46  batch  0  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  1  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  2  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  3  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  4  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  5  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  6  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  7  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  8  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  9  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  10  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  11  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  12  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  13  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  14  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  15  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  16  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  17  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  18  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  19  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  20  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  21  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  22  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  23  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  24  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  25  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  26  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  27  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  28  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  29  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  30  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  31  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  32  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  33  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  34  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  35  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  36  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  37  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  38  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  39  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  40  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  41  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  42  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  43  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  46  batch  44  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  45  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  46  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  47  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  48  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  49  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  50  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  51  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  52  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  53  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  54  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  55  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  56  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  57  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  58  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  59  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  60  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  61  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  62  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  63  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  64  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  65  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  66  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  67  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  68  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  69  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  70  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  71  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  72  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  73  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  74  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  75  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  76  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  77  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  78  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  79  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  80  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  81  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  82  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  83  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  84  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  85  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  86  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  87  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  88  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  89  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  90  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  91  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  92  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  93  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  94  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  95  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  96  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  97  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  98  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  99  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  100  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  101  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  102  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  103  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  104  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  105  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  106  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  107  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  108  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  109  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  110  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  111  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  112  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  113  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  114  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  115  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  116  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  117  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  118  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  119  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  120  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  121  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  122  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  123  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  124  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  125  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  126  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  127  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  128  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  129  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  130  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  131  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  132  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  133  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  134  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  135  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  136  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  137  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  138  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  139  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  140  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  141  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  142  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  143  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  144  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  145  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  146  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  147  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  148  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  149  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  150  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  151  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  152  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  153  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  154  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  155  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  156  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  157  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  158  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  159  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  160  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  161  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  162  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  163  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  164  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  165  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  46  batch  166  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  167  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  168  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  169  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  170  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  171  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  172  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  173  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  174  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  175  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  176  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  177  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  178  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  179  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  180  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  181  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  182  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  183  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  184  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  185  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  186  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  187  loss  tensor(0.1009, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  188  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  189  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  190  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  191  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  192  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  193  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  194  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  195  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  196  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  197  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  198  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  199  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  200  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  201  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  202  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  203  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  204  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  205  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  206  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  207  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  208  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  209  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  210  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  211  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  212  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  213  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  214  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  215  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  216  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  217  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  218  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  219  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  220  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  221  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  222  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  223  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  224  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  225  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  226  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  227  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  228  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  229  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  230  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  231  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  232  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  233  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  234  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  235  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  236  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  237  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  238  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  239  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  240  loss  tensor(0.0693, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  241  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  242  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  243  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  244  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  245  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  246  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  247  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  248  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  249  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  250  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  251  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  252  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  253  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  254  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  255  loss  tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  256  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  257  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  258  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  259  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  260  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  261  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  262  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  263  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  264  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  265  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  266  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  267  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  268  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  269  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  270  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  271  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  272  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  273  loss  tensor(0.1017, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  274  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  275  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  276  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  277  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  278  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  279  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  280  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  281  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  282  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  283  loss  tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  284  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  285  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  286  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  46  batch  287  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  288  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  289  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  290  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  291  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  292  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  293  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  294  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  295  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  296  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  297  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  298  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  299  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  300  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  301  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  302  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  303  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  304  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  305  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  306  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  307  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  308  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  309  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  310  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  311  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  312  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  313  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  314  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  315  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  316  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  317  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  318  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  319  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  320  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  321  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  322  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  323  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  324  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  325  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  326  loss  tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  327  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  328  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  329  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  330  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  331  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  332  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  333  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  334  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  335  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  336  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  337  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  338  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  339  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  340  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  341  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  342  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  343  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  344  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  345  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  346  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  347  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  348  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  349  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  350  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  351  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  352  loss  tensor(0.0664, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  353  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  354  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  355  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  356  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  357  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  358  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  359  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  360  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  361  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  362  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  363  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  364  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  365  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  366  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  367  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  368  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  369  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  370  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  371  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  372  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  373  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  374  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  375  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  376  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  377  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  378  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  379  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  380  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  381  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  382  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  383  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  384  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  385  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  386  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  387  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  388  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  389  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  390  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  391  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  392  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  393  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  394  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  395  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  396  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  397  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  398  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  399  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  400  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  401  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  402  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  403  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  404  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  405  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  406  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  407  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  46  batch  408  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  409  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  410  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  411  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  412  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  46  batch  413  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch [47/100], loss:33.1431\n",
      "epoch  47  batch  0  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  1  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  2  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  3  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  4  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  5  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  6  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  7  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  8  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  9  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  10  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  11  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  12  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  13  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  14  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  15  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  16  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  17  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  18  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  19  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  20  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  21  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  22  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  23  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  24  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  25  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  26  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  27  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  28  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  29  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  30  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  31  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  32  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  33  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  34  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  35  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  36  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  37  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  38  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  39  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  40  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  41  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  42  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  43  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  44  loss  tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  45  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  46  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  47  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  48  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  49  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  50  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  51  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  52  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  53  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  54  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  55  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  56  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  57  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  58  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  59  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  60  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  61  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  62  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  63  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  64  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  65  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  66  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  67  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  68  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  69  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  70  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  71  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  72  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  73  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  74  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  75  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  76  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  77  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  78  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  79  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  80  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  81  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  82  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  83  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  84  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  85  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  86  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  87  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  88  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  89  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  90  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  91  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  92  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  93  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  94  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  95  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  96  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  97  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  98  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  99  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  100  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  101  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  102  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  103  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  104  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  105  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  106  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  107  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  108  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  109  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  110  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  111  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  112  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  113  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  114  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  115  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  47  batch  116  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  117  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  118  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  119  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  120  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  121  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  122  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  123  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  124  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  125  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  126  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  127  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  128  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  129  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  130  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  131  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  132  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  133  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  134  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  135  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  136  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  137  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  138  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  139  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  140  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  141  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  142  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  143  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  144  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  145  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  146  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  147  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  148  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  149  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  150  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  151  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  152  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  153  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  154  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  155  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  156  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  157  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  158  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  159  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  160  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  161  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  162  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  163  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  164  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  165  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  166  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  167  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  168  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  169  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  170  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  171  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  172  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  173  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  174  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  175  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  176  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  177  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  178  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  179  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  180  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  181  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  182  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  183  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  184  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  185  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  186  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  187  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  188  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  189  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  190  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  191  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  192  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  193  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  194  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  195  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  196  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  197  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  198  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  199  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  200  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  201  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  202  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  203  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  204  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  205  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  206  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  207  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  208  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  209  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  210  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  211  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  212  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  213  loss  tensor(0.0693, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  214  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  215  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  216  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  217  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  218  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  219  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  220  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  221  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  222  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  223  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  224  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  225  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  226  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  227  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  228  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  229  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  230  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  231  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  232  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  233  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  234  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  235  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  236  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  47  batch  237  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  238  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  239  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  240  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  241  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  242  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  243  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  244  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  245  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  246  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  247  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  248  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  249  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  250  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  251  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  252  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  253  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  254  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  255  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  256  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  257  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  258  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  259  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  260  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  261  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  262  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  263  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  264  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  265  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  266  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  267  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  268  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  269  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  270  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  271  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  272  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  273  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  274  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  275  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  276  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  277  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  278  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  279  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  280  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  281  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  282  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  283  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  284  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  285  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  286  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  287  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  288  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  289  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  290  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  291  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  292  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  293  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  294  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  295  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  296  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  297  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  298  loss  tensor(0.0996, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  299  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  300  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  301  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  302  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  303  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  304  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  305  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  306  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  307  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  308  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  309  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  310  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  311  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  312  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  313  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  314  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  315  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  316  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  317  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  318  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  319  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  320  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  321  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  322  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  323  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  324  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  325  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  326  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  327  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  328  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  329  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  330  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  331  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  332  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  333  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  334  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  335  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  336  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  337  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  338  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  339  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  340  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  341  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  342  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  343  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  344  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  345  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  346  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  347  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  348  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  349  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  350  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  351  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  352  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  353  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  354  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  355  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  356  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  357  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  47  batch  358  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  359  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  360  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  361  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  362  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  363  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  364  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  365  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  366  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  367  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  368  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  369  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  370  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  371  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  372  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  373  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  374  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  375  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  376  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  377  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  378  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  379  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  380  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  381  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  382  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  383  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  384  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  385  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  386  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  387  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  388  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  389  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  390  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  391  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  392  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  393  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  394  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  395  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  396  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  397  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  398  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  399  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  400  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  401  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  402  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  403  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  404  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  405  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  406  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  407  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  408  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  409  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  410  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  411  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  412  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  47  batch  413  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch [48/100], loss:33.1487\n",
      "epoch  48  batch  0  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  1  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  2  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  3  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  4  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  5  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  6  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  7  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  8  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  9  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  10  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  11  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  12  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  13  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  14  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  15  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  16  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  17  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  18  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  19  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  20  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  21  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  22  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  23  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  24  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  25  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  26  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  27  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  28  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  29  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  30  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  31  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  32  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  33  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  34  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  35  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  36  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  37  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  38  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  39  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  40  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  41  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  42  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  43  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  44  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  45  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  46  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  47  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  48  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  49  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  50  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  51  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  52  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  53  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  54  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  55  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  56  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  57  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  58  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  59  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  60  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  61  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  62  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  63  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  64  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  65  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  48  batch  66  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  67  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  68  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  69  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  70  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  71  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  72  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  73  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  74  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  75  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  76  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  77  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  78  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  79  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  80  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  81  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  82  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  83  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  84  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  85  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  86  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  87  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  88  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  89  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  90  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  91  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  92  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  93  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  94  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  95  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  96  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  97  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  98  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  99  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  100  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  101  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  102  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  103  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  104  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  105  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  106  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  107  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  108  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  109  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  110  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  111  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  112  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  113  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  114  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  115  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  116  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  117  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  118  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  119  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  120  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  121  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  122  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  123  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  124  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  125  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  126  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  127  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  128  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  129  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  130  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  131  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  132  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  133  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  134  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  135  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  136  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  137  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  138  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  139  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  140  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  141  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  142  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  143  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  144  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  145  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  146  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  147  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  148  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  149  loss  tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  150  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  151  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  152  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  153  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  154  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  155  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  156  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  157  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  158  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  159  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  160  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  161  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  162  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  163  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  164  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  165  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  166  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  167  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  168  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  169  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  170  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  171  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  172  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  173  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  174  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  175  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  176  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  177  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  178  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  179  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  180  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  181  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  182  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  183  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  184  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  185  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  186  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  48  batch  187  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  188  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  189  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  190  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  191  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  192  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  193  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  194  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  195  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  196  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  197  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  198  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  199  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  200  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  201  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  202  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  203  loss  tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  204  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  205  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  206  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  207  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  208  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  209  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  210  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  211  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  212  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  213  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  214  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  215  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  216  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  217  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  218  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  219  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  220  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  221  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  222  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  223  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  224  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  225  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  226  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  227  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  228  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  229  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  230  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  231  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  232  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  233  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  234  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  235  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  236  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  237  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  238  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  239  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  240  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  241  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  242  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  243  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  244  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  245  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  246  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  247  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  248  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  249  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  250  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  251  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  252  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  253  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  254  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  255  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  256  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  257  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  258  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  259  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  260  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  261  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  262  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  263  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  264  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  265  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  266  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  267  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  268  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  269  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  270  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  271  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  272  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  273  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  274  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  275  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  276  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  277  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  278  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  279  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  280  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  281  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  282  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  283  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  284  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  285  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  286  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  287  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  288  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  289  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  290  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  291  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  292  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  293  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  294  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  295  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  296  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  297  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  298  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  299  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  300  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  301  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  302  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  303  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  304  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  305  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  306  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  307  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  48  batch  308  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  309  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  310  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  311  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  312  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  313  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  314  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  315  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  316  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  317  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  318  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  319  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  320  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  321  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  322  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  323  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  324  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  325  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  326  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  327  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  328  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  329  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  330  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  331  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  332  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  333  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  334  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  335  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  336  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  337  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  338  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  339  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  340  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  341  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  342  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  343  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  344  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  345  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  346  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  347  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  348  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  349  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  350  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  351  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  352  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  353  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  354  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  355  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  356  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  357  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  358  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  359  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  360  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  361  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  362  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  363  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  364  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  365  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  366  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  367  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  368  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  369  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  370  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  371  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  372  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  373  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  374  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  375  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  376  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  377  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  378  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  379  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  380  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  381  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  382  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  383  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  384  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  385  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  386  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  387  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  388  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  389  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  390  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  391  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  392  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  393  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  394  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  395  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  396  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  397  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  398  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  399  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  400  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  401  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  402  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  403  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  404  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  405  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  406  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  407  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  408  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  409  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  410  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  411  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  412  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  48  batch  413  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch [49/100], loss:33.1434\n",
      "epoch  49  batch  0  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  1  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  2  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  3  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  4  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  5  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  6  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  7  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  8  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  9  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  10  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  11  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  12  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  13  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  14  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  49  batch  15  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  16  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  17  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  18  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  19  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  20  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  21  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  22  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  23  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  24  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  25  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  26  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  27  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  28  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  29  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  30  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  31  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  32  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  33  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  34  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  35  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  36  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  37  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  38  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  39  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  40  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  41  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  42  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  43  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  44  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  45  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  46  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  47  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  48  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  49  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  50  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  51  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  52  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  53  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  54  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  55  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  56  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  57  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  58  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  59  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  60  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  61  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  62  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  63  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  64  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  65  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  66  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  67  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  68  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  69  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  70  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  71  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  72  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  73  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  74  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  75  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  76  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  77  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  78  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  79  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  80  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  81  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  82  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  83  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  84  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  85  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  86  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  87  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  88  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  89  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  90  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  91  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  92  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  93  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  94  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  95  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  96  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  97  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  98  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  99  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  100  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  101  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  102  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  103  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  104  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  105  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  106  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  107  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  108  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  109  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  110  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  111  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  112  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  113  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  114  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  115  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  116  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  117  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  118  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  119  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  120  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  121  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  122  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  123  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  124  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  125  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  126  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  127  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  128  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  129  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  130  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  131  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  132  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  133  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  134  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  135  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  136  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  49  batch  137  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  138  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  139  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  140  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  141  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  142  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  143  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  144  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  145  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  146  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  147  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  148  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  149  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  150  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  151  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  152  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  153  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  154  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  155  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  156  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  157  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  158  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  159  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  160  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  161  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  162  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  163  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  164  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  165  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  166  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  167  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  168  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  169  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  170  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  171  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  172  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  173  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  174  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  175  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  176  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  177  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  178  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  179  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  180  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  181  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  182  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  183  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  184  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  185  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  186  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  187  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  188  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  189  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  190  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  191  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  192  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  193  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  194  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  195  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  196  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  197  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  198  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  199  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  200  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  201  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  202  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  203  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  204  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  205  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  206  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  207  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  208  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  209  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  210  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  211  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  212  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  213  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  214  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  215  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  216  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  217  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  218  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  219  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  220  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  221  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  222  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  223  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  224  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  225  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  226  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  227  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  228  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  229  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  230  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  231  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  232  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  233  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  234  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  235  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  236  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  237  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  238  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  239  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  240  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  241  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  242  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  243  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  244  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  245  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  246  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  247  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  248  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  249  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  250  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  251  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  252  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  253  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  254  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  255  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  256  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  257  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  49  batch  258  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  259  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  260  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  261  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  262  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  263  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  264  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  265  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  266  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  267  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  268  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  269  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  270  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  271  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  272  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  273  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  274  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  275  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  276  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  277  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  278  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  279  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  280  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  281  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  282  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  283  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  284  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  285  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  286  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  287  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  288  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  289  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  290  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  291  loss  tensor(0.0974, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  292  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  293  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  294  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  295  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  296  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  297  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  298  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  299  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  300  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  301  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  302  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  303  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  304  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  305  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  306  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  307  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  308  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  309  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  310  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  311  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  312  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  313  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  314  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  315  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  316  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  317  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  318  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  319  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  320  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  321  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  322  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  323  loss  tensor(0.1006, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  324  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  325  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  326  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  327  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  328  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  329  loss  tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  330  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  331  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  332  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  333  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  334  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  335  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  336  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  337  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  338  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  339  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  340  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  341  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  342  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  343  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  344  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  345  loss  tensor(0.0664, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  346  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  347  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  348  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  349  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  350  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  351  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  352  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  353  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  354  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  355  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  356  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  357  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  358  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  359  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  360  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  361  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  362  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  363  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  364  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  365  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  366  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  367  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  368  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  369  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  370  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  371  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  372  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  373  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  374  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  375  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  376  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  377  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  378  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  49  batch  379  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  380  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  381  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  382  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  383  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  384  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  385  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  386  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  387  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  388  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  389  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  390  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  391  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  392  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  393  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  394  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  395  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  396  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  397  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  398  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  399  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  400  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  401  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  402  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  403  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  404  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  405  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  406  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  407  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  408  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  409  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  410  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  411  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  412  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  49  batch  413  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch [50/100], loss:33.1424\n",
      "epoch  50  batch  0  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  1  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  2  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  3  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  4  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  5  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  6  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  7  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  8  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  9  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  10  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  11  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  12  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  13  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  14  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  15  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  16  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  17  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  18  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  19  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  20  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  21  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  22  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  23  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  24  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  25  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  26  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  27  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  28  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  29  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  30  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  31  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  32  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  33  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  34  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  35  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  36  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  37  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  38  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  39  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  40  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  41  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  42  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  43  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  44  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  45  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  46  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  47  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  48  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  49  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  50  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  51  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  52  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  53  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  54  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  55  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  56  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  57  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  58  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  59  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  60  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  61  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  62  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  63  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  64  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  65  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  66  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  67  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  68  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  69  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  70  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  71  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  72  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  73  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  74  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  75  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  76  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  77  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  78  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  79  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  80  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  81  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  82  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  83  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  84  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  85  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  86  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  50  batch  87  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  88  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  89  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  90  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  91  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  92  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  93  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  94  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  95  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  96  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  97  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  98  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  99  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  100  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  101  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  102  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  103  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  104  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  105  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  106  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  107  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  108  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  109  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  110  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  111  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  112  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  113  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  114  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  115  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  116  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  117  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  118  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  119  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  120  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  121  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  122  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  123  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  124  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  125  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  126  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  127  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  128  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  129  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  130  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  131  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  132  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  133  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  134  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  135  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  136  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  137  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  138  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  139  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  140  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  141  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  142  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  143  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  144  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  145  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  146  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  147  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  148  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  149  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  150  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  151  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  152  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  153  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  154  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  155  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  156  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  157  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  158  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  159  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  160  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  161  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  162  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  163  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  164  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  165  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  166  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  167  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  168  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  169  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  170  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  171  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  172  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  173  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  174  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  175  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  176  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  177  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  178  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  179  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  180  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  181  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  182  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  183  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  184  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  185  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  186  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  187  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  188  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  189  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  190  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  191  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  192  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  193  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  194  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  195  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  196  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  197  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  198  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  199  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  200  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  201  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  202  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  203  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  204  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  205  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  206  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  207  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  50  batch  208  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  209  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  210  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  211  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  212  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  213  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  214  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  215  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  216  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  217  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  218  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  219  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  220  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  221  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  222  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  223  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  224  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  225  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  226  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  227  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  228  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  229  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  230  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  231  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  232  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  233  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  234  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  235  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  236  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  237  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  238  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  239  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  240  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  241  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  242  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  243  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  244  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  245  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  246  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  247  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  248  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  249  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  250  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  251  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  252  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  253  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  254  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  255  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  256  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  257  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  258  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  259  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  260  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  261  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  262  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  263  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  264  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  265  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  266  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  267  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  268  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  269  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  270  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  271  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  272  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  273  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  274  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  275  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  276  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  277  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  278  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  279  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  280  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  281  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  282  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  283  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  284  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  285  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  286  loss  tensor(0.0667, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  287  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  288  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  289  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  290  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  291  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  292  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  293  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  294  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  295  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  296  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  297  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  298  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  299  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  300  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  301  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  302  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  303  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  304  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  305  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  306  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  307  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  308  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  309  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  310  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  311  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  312  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  313  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  314  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  315  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  316  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  317  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  318  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  319  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  320  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  321  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  322  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  323  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  324  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  325  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  326  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  327  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  328  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  50  batch  329  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  330  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  331  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  332  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  333  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  334  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  335  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  336  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  337  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  338  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  339  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  340  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  341  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  342  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  343  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  344  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  345  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  346  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  347  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  348  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  349  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  350  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  351  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  352  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  353  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  354  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  355  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  356  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  357  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  358  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  359  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  360  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  361  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  362  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  363  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  364  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  365  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  366  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  367  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  368  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  369  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  370  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  371  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  372  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  373  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  374  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  375  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  376  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  377  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  378  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  379  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  380  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  381  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  382  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  383  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  384  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  385  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  386  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  387  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  388  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  389  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  390  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  391  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  392  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  393  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  394  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  395  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  396  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  397  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  398  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  399  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  400  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  401  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  402  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  403  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  404  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  405  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  406  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  407  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  408  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  409  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  410  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  411  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  412  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  50  batch  413  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch [51/100], loss:33.1432\n",
      "epoch  51  batch  0  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  1  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  2  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  3  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  4  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  5  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  6  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  7  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  8  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  9  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  10  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  11  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  12  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  13  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  14  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  15  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  16  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  17  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  18  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  19  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  20  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  21  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  22  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  23  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  24  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  25  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  26  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  27  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  28  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  29  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  30  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  31  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  32  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  33  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  34  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  35  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  51  batch  36  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  37  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  38  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  39  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  40  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  41  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  42  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  43  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  44  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  45  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  46  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  47  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  48  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  49  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  50  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  51  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  52  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  53  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  54  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  55  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  56  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  57  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  58  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  59  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  60  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  61  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  62  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  63  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  64  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  65  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  66  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  67  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  68  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  69  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  70  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  71  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  72  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  73  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  74  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  75  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  76  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  77  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  78  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  79  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  80  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  81  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  82  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  83  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  84  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  85  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  86  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  87  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  88  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  89  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  90  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  91  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  92  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  93  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  94  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  95  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  96  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  97  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  98  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  99  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  100  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  101  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  102  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  103  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  104  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  105  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  106  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  107  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  108  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  109  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  110  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  111  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  112  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  113  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  114  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  115  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  116  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  117  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  118  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  119  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  120  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  121  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  122  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  123  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  124  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  125  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  126  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  127  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  128  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  129  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  130  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  131  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  132  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  133  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  134  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  135  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  136  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  137  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  138  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  139  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  140  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  141  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  142  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  143  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  144  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  145  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  146  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  147  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  148  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  149  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  150  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  151  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  152  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  153  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  154  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  155  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  156  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  157  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  51  batch  158  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  159  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  160  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  161  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  162  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  163  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  164  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  165  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  166  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  167  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  168  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  169  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  170  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  171  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  172  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  173  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  174  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  175  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  176  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  177  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  178  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  179  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  180  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  181  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  182  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  183  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  184  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  185  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  186  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  187  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  188  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  189  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  190  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  191  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  192  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  193  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  194  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  195  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  196  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  197  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  198  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  199  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  200  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  201  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  202  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  203  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  204  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  205  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  206  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  207  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  208  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  209  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  210  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  211  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  212  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  213  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  214  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  215  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  216  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  217  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  218  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  219  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  220  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  221  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  222  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  223  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  224  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  225  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  226  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  227  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  228  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  229  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  230  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  231  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  232  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  233  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  234  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  235  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  236  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  237  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  238  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  239  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  240  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  241  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  242  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  243  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  244  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  245  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  246  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  247  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  248  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  249  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  250  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  251  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  252  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  253  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  254  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  255  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  256  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  257  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  258  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  259  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  260  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  261  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  262  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  263  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  264  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  265  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  266  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  267  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  268  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  269  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  270  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  271  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  272  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  273  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  274  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  275  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  276  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  277  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  278  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  51  batch  279  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  280  loss  tensor(0.0678, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  281  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  282  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  283  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  284  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  285  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  286  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  287  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  288  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  289  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  290  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  291  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  292  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  293  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  294  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  295  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  296  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  297  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  298  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  299  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  300  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  301  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  302  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  303  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  304  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  305  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  306  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  307  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  308  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  309  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  310  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  311  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  312  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  313  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  314  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  315  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  316  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  317  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  318  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  319  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  320  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  321  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  322  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  323  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  324  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  325  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  326  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  327  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  328  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  329  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  330  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  331  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  332  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  333  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  334  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  335  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  336  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  337  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  338  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  339  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  340  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  341  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  342  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  343  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  344  loss  tensor(0.0962, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  345  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  346  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  347  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  348  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  349  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  350  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  351  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  352  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  353  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  354  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  355  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  356  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  357  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  358  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  359  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  360  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  361  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  362  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  363  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  364  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  365  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  366  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  367  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  368  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  369  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  370  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  371  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  372  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  373  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  374  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  375  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  376  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  377  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  378  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  379  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  380  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  381  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  382  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  383  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  384  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  385  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  386  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  387  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  388  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  389  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  390  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  391  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  392  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  393  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  394  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  395  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  396  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  397  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  398  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  399  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  51  batch  400  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  401  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  402  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  403  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  404  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  405  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  406  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  407  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  408  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  409  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  410  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  411  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  412  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  51  batch  413  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch [52/100], loss:33.1418\n",
      "epoch  52  batch  0  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  1  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  2  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  3  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  4  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  5  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  6  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  7  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  8  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  9  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  10  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  11  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  12  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  13  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  14  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  15  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  16  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  17  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  18  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  19  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  20  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  21  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  22  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  23  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  24  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  25  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  26  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  27  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  28  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  29  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  30  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  31  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  32  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  33  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  34  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  35  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  36  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  37  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  38  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  39  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  40  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  41  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  42  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  43  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  44  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  45  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  46  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  47  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  48  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  49  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  50  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  51  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  52  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  53  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  54  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  55  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  56  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  57  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  58  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  59  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  60  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  61  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  62  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  63  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  64  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  65  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  66  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  67  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  68  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  69  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  70  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  71  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  72  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  73  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  74  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  75  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  76  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  77  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  78  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  79  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  80  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  81  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  82  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  83  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  84  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  85  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  86  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  87  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  88  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  89  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  90  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  91  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  92  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  93  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  94  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  95  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  96  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  97  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  98  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  99  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  100  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  101  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  102  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  103  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  104  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  105  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  106  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  107  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  52  batch  108  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  109  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  110  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  111  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  112  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  113  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  114  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  115  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  116  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  117  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  118  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  119  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  120  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  121  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  122  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  123  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  124  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  125  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  126  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  127  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  128  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  129  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  130  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  131  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  132  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  133  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  134  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  135  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  136  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  137  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  138  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  139  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  140  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  141  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  142  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  143  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  144  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  145  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  146  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  147  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  148  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  149  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  150  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  151  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  152  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  153  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  154  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  155  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  156  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  157  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  158  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  159  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  160  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  161  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  162  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  163  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  164  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  165  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  166  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  167  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  168  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  169  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  170  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  171  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  172  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  173  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  174  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  175  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  176  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  177  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  178  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  179  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  180  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  181  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  182  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  183  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  184  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  185  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  186  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  187  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  188  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  189  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  190  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  191  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  192  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  193  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  194  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  195  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  196  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  197  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  198  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  199  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  200  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  201  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  202  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  203  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  204  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  205  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  206  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  207  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  208  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  209  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  210  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  211  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  212  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  213  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  214  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  215  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  216  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  217  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  218  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  219  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  220  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  221  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  222  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  223  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  224  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  225  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  226  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  227  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  228  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  52  batch  229  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  230  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  231  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  232  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  233  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  234  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  235  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  236  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  237  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  238  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  239  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  240  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  241  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  242  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  243  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  244  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  245  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  246  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  247  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  248  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  249  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  250  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  251  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  252  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  253  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  254  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  255  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  256  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  257  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  258  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  259  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  260  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  261  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  262  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  263  loss  tensor(0.0678, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  264  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  265  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  266  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  267  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  268  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  269  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  270  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  271  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  272  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  273  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  274  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  275  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  276  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  277  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  278  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  279  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  280  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  281  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  282  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  283  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  284  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  285  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  286  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  287  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  288  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  289  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  290  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  291  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  292  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  293  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  294  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  295  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  296  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  297  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  298  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  299  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  300  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  301  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  302  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  303  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  304  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  305  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  306  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  307  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  308  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  309  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  310  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  311  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  312  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  313  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  314  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  315  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  316  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  317  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  318  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  319  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  320  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  321  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  322  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  323  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  324  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  325  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  326  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  327  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  328  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  329  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  330  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  331  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  332  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  333  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  334  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  335  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  336  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  337  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  338  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  339  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  340  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  341  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  342  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  343  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  344  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  345  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  346  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  347  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  348  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  349  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  52  batch  350  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  351  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  352  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  353  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  354  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  355  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  356  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  357  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  358  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  359  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  360  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  361  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  362  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  363  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  364  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  365  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  366  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  367  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  368  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  369  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  370  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  371  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  372  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  373  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  374  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  375  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  376  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  377  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  378  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  379  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  380  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  381  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  382  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  383  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  384  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  385  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  386  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  387  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  388  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  389  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  390  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  391  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  392  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  393  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  394  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  395  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  396  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  397  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  398  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  399  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  400  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  401  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  402  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  403  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  404  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  405  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  406  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  407  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  408  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  409  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  410  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  411  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  412  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  52  batch  413  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch [53/100], loss:33.1347\n",
      "epoch  53  batch  0  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  1  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  2  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  3  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  4  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  5  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  6  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  7  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  8  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  9  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  10  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  11  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  12  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  13  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  14  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  15  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  16  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  17  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  18  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  19  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  20  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  21  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  22  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  23  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  24  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  25  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  26  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  27  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  28  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  29  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  30  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  31  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  32  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  33  loss  tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  34  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  35  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  36  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  37  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  38  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  39  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  40  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  41  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  42  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  43  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  44  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  45  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  46  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  47  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  48  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  49  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  50  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  51  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  52  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  53  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  54  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  55  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  56  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  57  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  53  batch  58  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  59  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  60  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  61  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  62  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  63  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  64  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  65  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  66  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  67  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  68  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  69  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  70  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  71  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  72  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  73  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  74  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  75  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  76  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  77  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  78  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  79  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  80  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  81  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  82  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  83  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  84  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  85  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  86  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  87  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  88  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  89  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  90  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  91  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  92  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  93  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  94  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  95  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  96  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  97  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  98  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  99  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  100  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  101  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  102  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  103  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  104  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  105  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  106  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  107  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  108  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  109  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  110  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  111  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  112  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  113  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  114  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  115  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  116  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  117  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  118  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  119  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  120  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  121  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  122  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  123  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  124  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  125  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  126  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  127  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  128  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  129  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  130  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  131  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  132  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  133  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  134  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  135  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  136  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  137  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  138  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  139  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  140  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  141  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  142  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  143  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  144  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  145  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  146  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  147  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  148  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  149  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  150  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  151  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  152  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  153  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  154  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  155  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  156  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  157  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  158  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  159  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  160  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  161  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  162  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  163  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  164  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  165  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  166  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  167  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  168  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  169  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  170  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  171  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  172  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  173  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  174  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  175  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  176  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  177  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  178  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  179  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  53  batch  180  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  181  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  182  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  183  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  184  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  185  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  186  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  187  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  188  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  189  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  190  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  191  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  192  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  193  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  194  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  195  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  196  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  197  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  198  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  199  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  200  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  201  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  202  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  203  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  204  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  205  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  206  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  207  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  208  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  209  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  210  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  211  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  212  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  213  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  214  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  215  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  216  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  217  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  218  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  219  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  220  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  221  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  222  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  223  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  224  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  225  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  226  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  227  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  228  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  229  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  230  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  231  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  232  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  233  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  234  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  235  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  236  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  237  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  238  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  239  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  240  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  241  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  242  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  243  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  244  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  245  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  246  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  247  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  248  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  249  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  250  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  251  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  252  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  253  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  254  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  255  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  256  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  257  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  258  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  259  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  260  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  261  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  262  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  263  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  264  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  265  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  266  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  267  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  268  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  269  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  270  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  271  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  272  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  273  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  274  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  275  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  276  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  277  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  278  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  279  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  280  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  281  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  282  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  283  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  284  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  285  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  286  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  287  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  288  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  289  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  290  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  291  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  292  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  293  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  294  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  295  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  296  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  297  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  298  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  299  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  300  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  53  batch  301  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  302  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  303  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  304  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  305  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  306  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  307  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  308  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  309  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  310  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  311  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  312  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  313  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  314  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  315  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  316  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  317  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  318  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  319  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  320  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  321  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  322  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  323  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  324  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  325  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  326  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  327  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  328  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  329  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  330  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  331  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  332  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  333  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  334  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  335  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  336  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  337  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  338  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  339  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  340  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  341  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  342  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  343  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  344  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  345  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  346  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  347  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  348  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  349  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  350  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  351  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  352  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  353  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  354  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  355  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  356  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  357  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  358  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  359  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  360  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  361  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  362  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  363  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  364  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  365  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  366  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  367  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  368  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  369  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  370  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  371  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  372  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  373  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  374  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  375  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  376  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  377  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  378  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  379  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  380  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  381  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  382  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  383  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  384  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  385  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  386  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  387  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  388  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  389  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  390  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  391  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  392  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  393  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  394  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  395  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  396  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  397  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  398  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  399  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  400  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  401  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  402  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  403  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  404  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  405  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  406  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  407  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  408  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  409  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  410  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  411  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  412  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  53  batch  413  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch [54/100], loss:33.1392\n",
      "epoch  54  batch  0  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  1  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  2  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  3  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  4  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  5  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  6  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  7  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  54  batch  8  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  9  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  10  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  11  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  12  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  13  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  14  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  15  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  16  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  17  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  18  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  19  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  20  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  21  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  22  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  23  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  24  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  25  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  26  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  27  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  28  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  29  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  30  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  31  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  32  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  33  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  34  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  35  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  36  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  37  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  38  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  39  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  40  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  41  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  42  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  43  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  44  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  45  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  46  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  47  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  48  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  49  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  50  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  51  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  52  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  53  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  54  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  55  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  56  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  57  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  58  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  59  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  60  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  61  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  62  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  63  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  64  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  65  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  66  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  67  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  68  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  69  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  70  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  71  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  72  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  73  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  74  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  75  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  76  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  77  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  78  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  79  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  80  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  81  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  82  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  83  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  84  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  85  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  86  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  87  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  88  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  89  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  90  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  91  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  92  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  93  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  94  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  95  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  96  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  97  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  98  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  99  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  100  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  101  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  102  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  103  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  104  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  105  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  106  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  107  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  108  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  109  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  110  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  111  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  112  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  113  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  114  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  115  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  116  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  117  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  118  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  119  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  120  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  121  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  122  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  123  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  124  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  125  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  126  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  127  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  128  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  129  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  54  batch  130  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  131  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  132  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  133  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  134  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  135  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  136  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  137  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  138  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  139  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  140  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  141  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  142  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  143  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  144  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  145  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  146  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  147  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  148  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  149  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  150  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  151  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  152  loss  tensor(0.0677, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  153  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  154  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  155  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  156  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  157  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  158  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  159  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  160  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  161  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  162  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  163  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  164  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  165  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  166  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  167  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  168  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  169  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  170  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  171  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  172  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  173  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  174  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  175  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  176  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  177  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  178  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  179  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  180  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  181  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  182  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  183  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  184  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  185  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  186  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  187  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  188  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  189  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  190  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  191  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  192  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  193  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  194  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  195  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  196  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  197  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  198  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  199  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  200  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  201  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  202  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  203  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  204  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  205  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  206  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  207  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  208  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  209  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  210  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  211  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  212  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  213  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  214  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  215  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  216  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  217  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  218  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  219  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  220  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  221  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  222  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  223  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  224  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  225  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  226  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  227  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  228  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  229  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  230  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  231  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  232  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  233  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  234  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  235  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  236  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  237  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  238  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  239  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  240  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  241  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  242  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  243  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  244  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  245  loss  tensor(0.0671, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  246  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  247  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  248  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  249  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  250  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  54  batch  251  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  252  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  253  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  254  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  255  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  256  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  257  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  258  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  259  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  260  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  261  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  262  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  263  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  264  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  265  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  266  loss  tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  267  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  268  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  269  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  270  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  271  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  272  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  273  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  274  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  275  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  276  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  277  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  278  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  279  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  280  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  281  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  282  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  283  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  284  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  285  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  286  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  287  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  288  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  289  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  290  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  291  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  292  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  293  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  294  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  295  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  296  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  297  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  298  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  299  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  300  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  301  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  302  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  303  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  304  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  305  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  306  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  307  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  308  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  309  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  310  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  311  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  312  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  313  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  314  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  315  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  316  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  317  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  318  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  319  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  320  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  321  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  322  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  323  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  324  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  325  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  326  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  327  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  328  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  329  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  330  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  331  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  332  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  333  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  334  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  335  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  336  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  337  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  338  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  339  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  340  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  341  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  342  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  343  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  344  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  345  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  346  loss  tensor(0.0671, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  347  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  348  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  349  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  350  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  351  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  352  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  353  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  354  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  355  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  356  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  357  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  358  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  359  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  360  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  361  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  362  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  363  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  364  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  365  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  366  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  367  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  368  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  369  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  370  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  371  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  54  batch  372  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  373  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  374  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  375  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  376  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  377  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  378  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  379  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  380  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  381  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  382  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  383  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  384  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  385  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  386  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  387  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  388  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  389  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  390  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  391  loss  tensor(0.0668, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  392  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  393  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  394  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  395  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  396  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  397  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  398  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  399  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  400  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  401  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  402  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  403  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  404  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  405  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  406  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  407  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  408  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  409  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  410  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  411  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  412  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  54  batch  413  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch [55/100], loss:33.1411\n",
      "epoch  55  batch  0  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  1  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  2  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  3  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  4  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  5  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  6  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  7  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  8  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  9  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  10  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  11  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  12  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  13  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  14  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  15  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  16  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  17  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  18  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  19  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  20  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  21  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  22  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  23  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  24  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  25  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  26  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  27  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  28  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  29  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  30  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  31  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  32  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  33  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  34  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  35  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  36  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  37  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  38  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  39  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  40  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  41  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  42  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  43  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  44  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  45  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  46  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  47  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  48  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  49  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  50  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  51  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  52  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  53  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  54  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  55  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  56  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  57  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  58  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  59  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  60  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  61  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  62  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  63  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  64  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  65  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  66  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  67  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  68  loss  tensor(0.0963, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  69  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  70  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  71  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  72  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  73  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  74  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  75  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  76  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  77  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  78  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  79  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  55  batch  80  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  81  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  82  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  83  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  84  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  85  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  86  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  87  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  88  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  89  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  90  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  91  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  92  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  93  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  94  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  95  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  96  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  97  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  98  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  99  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  100  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  101  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  102  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  103  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  104  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  105  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  106  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  107  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  108  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  109  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  110  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  111  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  112  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  113  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  114  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  115  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  116  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  117  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  118  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  119  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  120  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  121  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  122  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  123  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  124  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  125  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  126  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  127  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  128  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  129  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  130  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  131  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  132  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  133  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  134  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  135  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  136  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  137  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  138  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  139  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  140  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  141  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  142  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  143  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  144  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  145  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  146  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  147  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  148  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  149  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  150  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  151  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  152  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  153  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  154  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  155  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  156  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  157  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  158  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  159  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  160  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  161  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  162  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  163  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  164  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  165  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  166  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  167  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  168  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  169  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  170  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  171  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  172  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  173  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  174  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  175  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  176  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  177  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  178  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  179  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  180  loss  tensor(0.0670, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  181  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  182  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  183  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  184  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  185  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  186  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  187  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  188  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  189  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  190  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  191  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  192  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  193  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  194  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  195  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  196  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  197  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  198  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  199  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  200  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  55  batch  201  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  202  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  203  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  204  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  205  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  206  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  207  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  208  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  209  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  210  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  211  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  212  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  213  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  214  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  215  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  216  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  217  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  218  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  219  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  220  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  221  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  222  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  223  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  224  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  225  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  226  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  227  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  228  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  229  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  230  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  231  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  232  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  233  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  234  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  235  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  236  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  237  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  238  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  239  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  240  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  241  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  242  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  243  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  244  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  245  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  246  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  247  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  248  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  249  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  250  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  251  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  252  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  253  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  254  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  255  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  256  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  257  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  258  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  259  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  260  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  261  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  262  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  263  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  264  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  265  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  266  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  267  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  268  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  269  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  270  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  271  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  272  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  273  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  274  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  275  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  276  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  277  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  278  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  279  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  280  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  281  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  282  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  283  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  284  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  285  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  286  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  287  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  288  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  289  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  290  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  291  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  292  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  293  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  294  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  295  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  296  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  297  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  298  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  299  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  300  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  301  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  302  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  303  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  304  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  305  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  306  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  307  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  308  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  309  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  310  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  311  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  312  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  313  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  314  loss  tensor(0.0656, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  315  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  316  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  317  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  318  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  319  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  320  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  321  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  55  batch  322  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  323  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  324  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  325  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  326  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  327  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  328  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  329  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  330  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  331  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  332  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  333  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  334  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  335  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  336  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  337  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  338  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  339  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  340  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  341  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  342  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  343  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  344  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  345  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  346  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  347  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  348  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  349  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  350  loss  tensor(0.0667, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  351  loss  tensor(0.0645, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  352  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  353  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  354  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  355  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  356  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  357  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  358  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  359  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  360  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  361  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  362  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  363  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  364  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  365  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  366  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  367  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  368  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  369  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  370  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  371  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  372  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  373  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  374  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  375  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  376  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  377  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  378  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  379  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  380  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  381  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  382  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  383  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  384  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  385  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  386  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  387  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  388  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  389  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  390  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  391  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  392  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  393  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  394  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  395  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  396  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  397  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  398  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  399  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  400  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  401  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  402  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  403  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  404  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  405  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  406  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  407  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  408  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  409  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  410  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  411  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  412  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  55  batch  413  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch [56/100], loss:33.1430\n",
      "epoch  56  batch  0  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  1  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  2  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  3  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  4  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  5  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  6  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  7  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  8  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  9  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  10  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  11  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  12  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  13  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  14  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  15  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  16  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  17  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  18  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  19  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  20  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  21  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  22  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  23  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  24  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  25  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  26  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  27  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  28  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  56  batch  29  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  30  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  31  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  32  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  33  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  34  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  35  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  36  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  37  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  38  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  39  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  40  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  41  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  42  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  43  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  44  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  45  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  46  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  47  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  48  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  49  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  50  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  51  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  52  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  53  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  54  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  55  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  56  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  57  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  58  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  59  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  60  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  61  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  62  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  63  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  64  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  65  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  66  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  67  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  68  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  69  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  70  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  71  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  72  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  73  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  74  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  75  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  76  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  77  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  78  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  79  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  80  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  81  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  82  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  83  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  84  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  85  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  86  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  87  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  88  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  89  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  90  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  91  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  92  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  93  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  94  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  95  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  96  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  97  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  98  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  99  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  100  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  101  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  102  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  103  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  104  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  105  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  106  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  107  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  108  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  109  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  110  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  111  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  112  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  113  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  114  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  115  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  116  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  117  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  118  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  119  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  120  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  121  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  122  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  123  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  124  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  125  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  126  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  127  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  128  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  129  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  130  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  131  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  132  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  133  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  134  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  135  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  136  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  137  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  138  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  139  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  140  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  141  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  142  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  143  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  144  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  145  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  146  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  147  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  148  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  149  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  150  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  56  batch  151  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  152  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  153  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  154  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  155  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  156  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  157  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  158  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  159  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  160  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  161  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  162  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  163  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  164  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  165  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  166  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  167  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  168  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  169  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  170  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  171  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  172  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  173  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  174  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  175  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  176  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  177  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  178  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  179  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  180  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  181  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  182  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  183  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  184  loss  tensor(0.0678, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  185  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  186  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  187  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  188  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  189  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  190  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  191  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  192  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  193  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  194  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  195  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  196  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  197  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  198  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  199  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  200  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  201  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  202  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  203  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  204  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  205  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  206  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  207  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  208  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  209  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  210  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  211  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  212  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  213  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  214  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  215  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  216  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  217  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  218  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  219  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  220  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  221  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  222  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  223  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  224  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  225  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  226  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  227  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  228  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  229  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  230  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  231  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  232  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  233  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  234  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  235  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  236  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  237  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  238  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  239  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  240  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  241  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  242  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  243  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  244  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  245  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  246  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  247  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  248  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  249  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  250  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  251  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  252  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  253  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  254  loss  tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  255  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  256  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  257  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  258  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  259  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  260  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  261  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  262  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  263  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  264  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  265  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  266  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  267  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  268  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  269  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  270  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  271  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  56  batch  272  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  273  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  274  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  275  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  276  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  277  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  278  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  279  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  280  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  281  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  282  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  283  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  284  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  285  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  286  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  287  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  288  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  289  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  290  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  291  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  292  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  293  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  294  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  295  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  296  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  297  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  298  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  299  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  300  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  301  loss  tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  302  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  303  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  304  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  305  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  306  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  307  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  308  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  309  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  310  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  311  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  312  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  313  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  314  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  315  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  316  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  317  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  318  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  319  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  320  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  321  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  322  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  323  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  324  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  325  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  326  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  327  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  328  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  329  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  330  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  331  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  332  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  333  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  334  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  335  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  336  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  337  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  338  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  339  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  340  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  341  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  342  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  343  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  344  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  345  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  346  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  347  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  348  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  349  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  350  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  351  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  352  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  353  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  354  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  355  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  356  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  357  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  358  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  359  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  360  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  361  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  362  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  363  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  364  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  365  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  366  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  367  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  368  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  369  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  370  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  371  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  372  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  373  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  374  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  375  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  376  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  377  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  378  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  379  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  380  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  381  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  382  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  383  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  384  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  385  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  386  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  387  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  388  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  389  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  390  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  391  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  392  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  56  batch  393  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  394  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  395  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  396  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  397  loss  tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  398  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  399  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  400  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  401  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  402  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  403  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  404  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  405  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  406  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  407  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  408  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  409  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  410  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  411  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  412  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  56  batch  413  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch [57/100], loss:33.1417\n",
      "epoch  57  batch  0  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  1  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  2  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  3  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  4  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  5  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  6  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  7  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  8  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  9  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  10  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  11  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  12  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  13  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  14  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  15  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  16  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  17  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  18  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  19  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  20  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  21  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  22  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  23  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  24  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  25  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  26  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  27  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  28  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  29  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  30  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  31  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  32  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  33  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  34  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  35  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  36  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  37  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  38  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  39  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  40  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  41  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  42  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  43  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  44  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  45  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  46  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  47  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  48  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  49  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  50  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  51  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  52  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  53  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  54  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  55  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  56  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  57  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  58  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  59  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  60  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  61  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  62  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  63  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  64  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  65  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  66  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  67  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  68  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  69  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  70  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  71  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  72  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  73  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  74  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  75  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  76  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  77  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  78  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  79  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  80  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  81  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  82  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  83  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  84  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  85  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  86  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  87  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  88  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  89  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  90  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  91  loss  tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  92  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  93  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  94  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  95  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  96  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  97  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  98  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  99  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  100  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  57  batch  101  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  102  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  103  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  104  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  105  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  106  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  107  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  108  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  109  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  110  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  111  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  112  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  113  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  114  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  115  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  116  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  117  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  118  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  119  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  120  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  121  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  122  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  123  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  124  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  125  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  126  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  127  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  128  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  129  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  130  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  131  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  132  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  133  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  134  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  135  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  136  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  137  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  138  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  139  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  140  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  141  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  142  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  143  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  144  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  145  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  146  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  147  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  148  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  149  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  150  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  151  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  152  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  153  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  154  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  155  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  156  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  157  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  158  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  159  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  160  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  161  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  162  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  163  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  164  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  165  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  166  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  167  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  168  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  169  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  170  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  171  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  172  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  173  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  174  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  175  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  176  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  177  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  178  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  179  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  180  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  181  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  182  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  183  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  184  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  185  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  186  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  187  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  188  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  189  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  190  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  191  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  192  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  193  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  194  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  195  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  196  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  197  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  198  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  199  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  200  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  201  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  202  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  203  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  204  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  205  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  206  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  207  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  208  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  209  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  210  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  211  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  212  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  213  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  214  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  215  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  216  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  217  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  218  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  219  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  220  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  221  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  57  batch  222  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  223  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  224  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  225  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  226  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  227  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  228  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  229  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  230  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  231  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  232  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  233  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  234  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  235  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  236  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  237  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  238  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  239  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  240  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  241  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  242  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  243  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  244  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  245  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  246  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  247  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  248  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  249  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  250  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  251  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  252  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  253  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  254  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  255  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  256  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  257  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  258  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  259  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  260  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  261  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  262  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  263  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  264  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  265  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  266  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  267  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  268  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  269  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  270  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  271  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  272  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  273  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  274  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  275  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  276  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  277  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  278  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  279  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  280  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  281  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  282  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  283  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  284  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  285  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  286  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  287  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  288  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  289  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  290  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  291  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  292  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  293  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  294  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  295  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  296  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  297  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  298  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  299  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  300  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  301  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  302  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  303  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  304  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  305  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  306  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  307  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  308  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  309  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  310  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  311  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  312  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  313  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  314  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  315  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  316  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  317  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  318  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  319  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  320  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  321  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  322  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  323  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  324  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  325  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  326  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  327  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  328  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  329  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  330  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  331  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  332  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  333  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  334  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  335  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  336  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  337  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  338  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  339  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  340  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  341  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  342  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  57  batch  343  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  344  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  345  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  346  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  347  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  348  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  349  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  350  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  351  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  352  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  353  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  354  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  355  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  356  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  357  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  358  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  359  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  360  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  361  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  362  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  363  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  364  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  365  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  366  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  367  loss  tensor(0.0956, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  368  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  369  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  370  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  371  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  372  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  373  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  374  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  375  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  376  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  377  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  378  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  379  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  380  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  381  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  382  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  383  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  384  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  385  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  386  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  387  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  388  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  389  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  390  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  391  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  392  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  393  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  394  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  395  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  396  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  397  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  398  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  399  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  400  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  401  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  402  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  403  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  404  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  405  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  406  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  407  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  408  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  409  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  410  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  411  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  412  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  57  batch  413  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch [58/100], loss:33.1430\n",
      "epoch  58  batch  0  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  1  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  2  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  3  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  4  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  5  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  6  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  7  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  8  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  9  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  10  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  11  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  12  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  13  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  14  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  15  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  16  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  17  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  18  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  19  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  20  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  21  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  22  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  23  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  24  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  25  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  26  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  27  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  28  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  29  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  30  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  31  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  32  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  33  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  34  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  35  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  36  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  37  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  38  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  39  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  40  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  41  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  42  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  43  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  44  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  45  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  46  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  47  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  48  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  49  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  58  batch  50  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  51  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  52  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  53  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  54  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  55  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  56  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  57  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  58  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  59  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  60  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  61  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  62  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  63  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  64  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  65  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  66  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  67  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  68  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  69  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  70  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  71  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  72  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  73  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  74  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  75  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  76  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  77  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  78  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  79  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  80  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  81  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  82  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  83  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  84  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  85  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  86  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  87  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  88  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  89  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  90  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  91  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  92  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  93  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  94  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  95  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  96  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  97  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  98  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  99  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  100  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  101  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  102  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  103  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  104  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  105  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  106  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  107  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  108  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  109  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  110  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  111  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  112  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  113  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  114  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  115  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  116  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  117  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  118  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  119  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  120  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  121  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  122  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  123  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  124  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  125  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  126  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  127  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  128  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  129  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  130  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  131  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  132  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  133  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  134  loss  tensor(0.0658, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  135  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  136  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  137  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  138  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  139  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  140  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  141  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  142  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  143  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  144  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  145  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  146  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  147  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  148  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  149  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  150  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  151  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  152  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  153  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  154  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  155  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  156  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  157  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  158  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  159  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  160  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  161  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  162  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  163  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  164  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  165  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  166  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  167  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  168  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  169  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  170  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  171  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  58  batch  172  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  173  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  174  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  175  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  176  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  177  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  178  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  179  loss  tensor(0.0655, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  180  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  181  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  182  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  183  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  184  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  185  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  186  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  187  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  188  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  189  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  190  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  191  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  192  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  193  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  194  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  195  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  196  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  197  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  198  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  199  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  200  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  201  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  202  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  203  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  204  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  205  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  206  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  207  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  208  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  209  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  210  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  211  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  212  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  213  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  214  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  215  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  216  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  217  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  218  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  219  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  220  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  221  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  222  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  223  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  224  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  225  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  226  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  227  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  228  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  229  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  230  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  231  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  232  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  233  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  234  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  235  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  236  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  237  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  238  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  239  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  240  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  241  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  242  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  243  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  244  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  245  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  246  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  247  loss  tensor(0.0650, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  248  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  249  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  250  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  251  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  252  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  253  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  254  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  255  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  256  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  257  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  258  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  259  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  260  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  261  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  262  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  263  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  264  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  265  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  266  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  267  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  268  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  269  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  270  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  271  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  272  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  273  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  274  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  275  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  276  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  277  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  278  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  279  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  280  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  281  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  282  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  283  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  284  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  285  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  286  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  287  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  288  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  289  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  290  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  291  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  292  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  58  batch  293  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  294  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  295  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  296  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  297  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  298  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  299  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  300  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  301  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  302  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  303  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  304  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  305  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  306  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  307  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  308  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  309  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  310  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  311  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  312  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  313  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  314  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  315  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  316  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  317  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  318  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  319  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  320  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  321  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  322  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  323  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  324  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  325  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  326  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  327  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  328  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  329  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  330  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  331  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  332  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  333  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  334  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  335  loss  tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  336  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  337  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  338  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  339  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  340  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  341  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  342  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  343  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  344  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  345  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  346  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  347  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  348  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  349  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  350  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  351  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  352  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  353  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  354  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  355  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  356  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  357  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  358  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  359  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  360  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  361  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  362  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  363  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  364  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  365  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  366  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  367  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  368  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  369  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  370  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  371  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  372  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  373  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  374  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  375  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  376  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  377  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  378  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  379  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  380  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  381  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  382  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  383  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  384  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  385  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  386  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  387  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  388  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  389  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  390  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  391  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  392  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  393  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  394  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  395  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  396  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  397  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  398  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  399  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  400  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  401  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  402  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  403  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  404  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  405  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  406  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  407  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  408  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  409  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  410  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  411  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  412  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  58  batch  413  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch [59/100], loss:33.1386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  59  batch  0  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  1  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  2  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  3  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  4  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  5  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  6  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  7  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  8  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  9  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  10  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  11  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  12  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  13  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  14  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  15  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  16  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  17  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  18  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  19  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  20  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  21  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  22  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  23  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  24  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  25  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  26  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  27  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  28  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  29  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  30  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  31  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  32  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  33  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  34  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  35  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  36  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  37  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  38  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  39  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  40  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  41  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  42  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  43  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  44  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  45  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  46  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  47  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  48  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  49  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  50  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  51  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  52  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  53  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  54  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  55  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  56  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  57  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  58  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  59  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  60  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  61  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  62  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  63  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  64  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  65  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  66  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  67  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  68  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  69  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  70  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  71  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  72  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  73  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  74  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  75  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  76  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  77  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  78  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  79  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  80  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  81  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  82  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  83  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  84  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  85  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  86  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  87  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  88  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  89  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  90  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  91  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  92  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  93  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  94  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  95  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  96  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  97  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  98  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  99  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  100  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  101  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  102  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  103  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  104  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  105  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  106  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  107  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  108  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  109  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  110  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  111  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  112  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  113  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  114  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  115  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  116  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  117  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  118  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  119  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  120  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  121  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  122  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  59  batch  123  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  124  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  125  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  126  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  127  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  128  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  129  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  130  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  131  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  132  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  133  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  134  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  135  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  136  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  137  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  138  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  139  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  140  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  141  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  142  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  143  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  144  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  145  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  146  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  147  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  148  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  149  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  150  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  151  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  152  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  153  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  154  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  155  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  156  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  157  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  158  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  159  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  160  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  161  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  162  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  163  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  164  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  165  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  166  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  167  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  168  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  169  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  170  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  171  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  172  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  173  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  174  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  175  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  176  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  177  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  178  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  179  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  180  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  181  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  182  loss  tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  183  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  184  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  185  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  186  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  187  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  188  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  189  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  190  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  191  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  192  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  193  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  194  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  195  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  196  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  197  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  198  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  199  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  200  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  201  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  202  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  203  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  204  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  205  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  206  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  207  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  208  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  209  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  210  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  211  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  212  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  213  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  214  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  215  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  216  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  217  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  218  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  219  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  220  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  221  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  222  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  223  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  224  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  225  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  226  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  227  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  228  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  229  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  230  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  231  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  232  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  233  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  234  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  235  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  236  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  237  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  238  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  239  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  240  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  241  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  242  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  243  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  59  batch  244  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  245  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  246  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  247  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  248  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  249  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  250  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  251  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  252  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  253  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  254  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  255  loss  tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  256  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  257  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  258  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  259  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  260  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  261  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  262  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  263  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  264  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  265  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  266  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  267  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  268  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  269  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  270  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  271  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  272  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  273  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  274  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  275  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  276  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  277  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  278  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  279  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  280  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  281  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  282  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  283  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  284  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  285  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  286  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  287  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  288  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  289  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  290  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  291  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  292  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  293  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  294  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  295  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  296  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  297  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  298  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  299  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  300  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  301  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  302  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  303  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  304  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  305  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  306  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  307  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  308  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  309  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  310  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  311  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  312  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  313  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  314  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  315  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  316  loss  tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  317  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  318  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  319  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  320  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  321  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  322  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  323  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  324  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  325  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  326  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  327  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  328  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  329  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  330  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  331  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  332  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  333  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  334  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  335  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  336  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  337  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  338  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  339  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  340  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  341  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  342  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  343  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  344  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  345  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  346  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  347  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  348  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  349  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  350  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  351  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  352  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  353  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  354  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  355  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  356  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  357  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  358  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  359  loss  tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  360  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  361  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  362  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  363  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  364  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  59  batch  365  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  366  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  367  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  368  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  369  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  370  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  371  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  372  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  373  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  374  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  375  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  376  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  377  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  378  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  379  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  380  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  381  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  382  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  383  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  384  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  385  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  386  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  387  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  388  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  389  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  390  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  391  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  392  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  393  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  394  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  395  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  396  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  397  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  398  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  399  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  400  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  401  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  402  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  403  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  404  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  405  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  406  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  407  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  408  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  409  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  410  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  411  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  412  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  59  batch  413  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch [60/100], loss:33.1459\n",
      "epoch  60  batch  0  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  1  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  2  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  3  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  4  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  5  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  6  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  7  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  8  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  9  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  10  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  11  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  12  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  13  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  14  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  15  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  16  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  17  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  18  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  19  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  20  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  21  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  22  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  23  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  24  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  25  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  26  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  27  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  28  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  29  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  30  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  31  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  32  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  33  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  34  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  35  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  36  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  37  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  38  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  39  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  40  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  41  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  42  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  43  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  44  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  45  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  46  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  47  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  48  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  49  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  50  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  51  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  52  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  53  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  54  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  55  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  56  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  57  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  58  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  59  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  60  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  61  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  62  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  63  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  64  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  65  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  66  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  67  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  68  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  69  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  70  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  71  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  72  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  60  batch  73  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  74  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  75  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  76  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  77  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  78  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  79  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  80  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  81  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  82  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  83  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  84  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  85  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  86  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  87  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  88  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  89  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  90  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  91  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  92  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  93  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  94  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  95  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  96  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  97  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  98  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  99  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  100  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  101  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  102  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  103  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  104  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  105  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  106  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  107  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  108  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  109  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  110  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  111  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  112  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  113  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  114  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  115  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  116  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  117  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  118  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  119  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  120  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  121  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  122  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  123  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  124  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  125  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  126  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  127  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  128  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  129  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  130  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  131  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  132  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  133  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  134  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  135  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  136  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  137  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  138  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  139  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  140  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  141  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  142  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  143  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  144  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  145  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  146  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  147  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  148  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  149  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  150  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  151  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  152  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  153  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  154  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  155  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  156  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  157  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  158  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  159  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  160  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  161  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  162  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  163  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  164  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  165  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  166  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  167  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  168  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  169  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  170  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  171  loss  tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  172  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  173  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  174  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  175  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  176  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  177  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  178  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  179  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  180  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  181  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  182  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  183  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  184  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  185  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  186  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  187  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  188  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  189  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  190  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  191  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  192  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  193  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  60  batch  194  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  195  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  196  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  197  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  198  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  199  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  200  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  201  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  202  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  203  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  204  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  205  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  206  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  207  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  208  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  209  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  210  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  211  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  212  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  213  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  214  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  215  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  216  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  217  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  218  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  219  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  220  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  221  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  222  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  223  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  224  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  225  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  226  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  227  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  228  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  229  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  230  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  231  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  232  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  233  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  234  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  235  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  236  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  237  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  238  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  239  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  240  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  241  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  242  loss  tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  243  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  244  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  245  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  246  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  247  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  248  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  249  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  250  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  251  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  252  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  253  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  254  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  255  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  256  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  257  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  258  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  259  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  260  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  261  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  262  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  263  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  264  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  265  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  266  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  267  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  268  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  269  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  270  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  271  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  272  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  273  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  274  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  275  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  276  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  277  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  278  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  279  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  280  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  281  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  282  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  283  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  284  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  285  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  286  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  287  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  288  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  289  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  290  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  291  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  292  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  293  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  294  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  295  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  296  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  297  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  298  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  299  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  300  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  301  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  302  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  303  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  304  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  305  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  306  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  307  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  308  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  309  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  310  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  311  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  312  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  313  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  314  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  60  batch  315  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  316  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  317  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  318  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  319  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  320  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  321  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  322  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  323  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  324  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  325  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  326  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  327  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  328  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  329  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  330  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  331  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  332  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  333  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  334  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  335  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  336  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  337  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  338  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  339  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  340  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  341  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  342  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  343  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  344  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  345  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  346  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  347  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  348  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  349  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  350  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  351  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  352  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  353  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  354  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  355  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  356  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  357  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  358  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  359  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  360  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  361  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  362  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  363  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  364  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  365  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  366  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  367  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  368  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  369  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  370  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  371  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  372  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  373  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  374  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  375  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  376  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  377  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  378  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  379  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  380  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  381  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  382  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  383  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  384  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  385  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  386  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  387  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  388  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  389  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  390  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  391  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  392  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  393  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  394  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  395  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  396  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  397  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  398  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  399  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  400  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  401  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  402  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  403  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  404  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  405  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  406  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  407  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  408  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  409  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  410  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  411  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  412  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  60  batch  413  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch [61/100], loss:33.1443\n",
      "epoch  61  batch  0  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  1  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  2  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  3  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  4  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  5  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  6  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  7  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  8  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  9  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  10  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  11  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  12  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  13  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  14  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  15  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  16  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  17  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  18  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  19  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  20  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  21  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  61  batch  22  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  23  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  24  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  25  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  26  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  27  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  28  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  29  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  30  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  31  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  32  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  33  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  34  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  35  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  36  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  37  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  38  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  39  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  40  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  41  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  42  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  43  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  44  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  45  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  46  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  47  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  48  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  49  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  50  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  51  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  52  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  53  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  54  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  55  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  56  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  57  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  58  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  59  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  60  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  61  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  62  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  63  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  64  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  65  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  66  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  67  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  68  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  69  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  70  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  71  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  72  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  73  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  74  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  75  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  76  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  77  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  78  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  79  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  80  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  81  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  82  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  83  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  84  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  85  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  86  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  87  loss  tensor(0.0656, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  88  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  89  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  90  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  91  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  92  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  93  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  94  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  95  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  96  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  97  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  98  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  99  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  100  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  101  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  102  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  103  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  104  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  105  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  106  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  107  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  108  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  109  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  110  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  111  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  112  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  113  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  114  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  115  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  116  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  117  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  118  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  119  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  120  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  121  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  122  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  123  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  124  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  125  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  126  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  127  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  128  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  129  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  130  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  131  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  132  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  133  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  134  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  135  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  136  loss  tensor(0.0659, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  137  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  138  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  139  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  140  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  141  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  142  loss  tensor(0.0679, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  143  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  61  batch  144  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  145  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  146  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  147  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  148  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  149  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  150  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  151  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  152  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  153  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  154  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  155  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  156  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  157  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  158  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  159  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  160  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  161  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  162  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  163  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  164  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  165  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  166  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  167  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  168  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  169  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  170  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  171  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  172  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  173  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  174  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  175  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  176  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  177  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  178  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  179  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  180  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  181  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  182  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  183  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  184  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  185  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  186  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  187  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  188  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  189  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  190  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  191  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  192  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  193  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  194  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  195  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  196  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  197  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  198  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  199  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  200  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  201  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  202  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  203  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  204  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  205  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  206  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  207  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  208  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  209  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  210  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  211  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  212  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  213  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  214  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  215  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  216  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  217  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  218  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  219  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  220  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  221  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  222  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  223  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  224  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  225  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  226  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  227  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  228  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  229  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  230  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  231  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  232  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  233  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  234  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  235  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  236  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  237  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  238  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  239  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  240  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  241  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  242  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  243  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  244  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  245  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  246  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  247  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  248  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  249  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  250  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  251  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  252  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  253  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  254  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  255  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  256  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  257  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  258  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  259  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  260  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  261  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  262  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  263  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  264  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  61  batch  265  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  266  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  267  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  268  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  269  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  270  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  271  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  272  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  273  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  274  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  275  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  276  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  277  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  278  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  279  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  280  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  281  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  282  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  283  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  284  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  285  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  286  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  287  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  288  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  289  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  290  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  291  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  292  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  293  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  294  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  295  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  296  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  297  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  298  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  299  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  300  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  301  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  302  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  303  loss  tensor(0.0678, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  304  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  305  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  306  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  307  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  308  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  309  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  310  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  311  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  312  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  313  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  314  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  315  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  316  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  317  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  318  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  319  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  320  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  321  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  322  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  323  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  324  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  325  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  326  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  327  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  328  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  329  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  330  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  331  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  332  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  333  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  334  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  335  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  336  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  337  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  338  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  339  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  340  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  341  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  342  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  343  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  344  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  345  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  346  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  347  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  348  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  349  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  350  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  351  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  352  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  353  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  354  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  355  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  356  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  357  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  358  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  359  loss  tensor(0.0663, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  360  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  361  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  362  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  363  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  364  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  365  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  366  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  367  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  368  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  369  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  370  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  371  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  372  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  373  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  374  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  375  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  376  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  377  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  378  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  379  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  380  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  381  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  382  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  383  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  384  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  385  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  61  batch  386  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  387  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  388  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  389  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  390  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  391  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  392  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  393  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  394  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  395  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  396  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  397  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  398  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  399  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  400  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  401  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  402  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  403  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  404  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  405  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  406  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  407  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  408  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  409  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  410  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  411  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  412  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  61  batch  413  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch [62/100], loss:33.1386\n",
      "epoch  62  batch  0  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  1  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  2  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  3  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  4  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  5  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  6  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  7  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  8  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  9  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  10  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  11  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  12  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  13  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  14  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  15  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  16  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  17  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  18  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  19  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  20  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  21  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  22  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  23  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  24  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  25  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  26  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  27  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  28  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  29  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  30  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  31  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  32  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  33  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  34  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  35  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  36  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  37  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  38  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  39  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  40  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  41  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  42  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  43  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  44  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  45  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  46  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  47  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  48  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  49  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  50  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  51  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  52  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  53  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  54  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  55  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  56  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  57  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  58  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  59  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  60  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  61  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  62  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  63  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  64  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  65  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  66  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  67  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  68  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  69  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  70  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  71  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  72  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  73  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  74  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  75  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  76  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  77  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  78  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  79  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  80  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  81  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  82  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  83  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  84  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  85  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  86  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  87  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  88  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  89  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  90  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  91  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  92  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  93  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  62  batch  94  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  95  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  96  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  97  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  98  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  99  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  100  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  101  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  102  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  103  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  104  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  105  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  106  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  107  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  108  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  109  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  110  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  111  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  112  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  113  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  114  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  115  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  116  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  117  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  118  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  119  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  120  loss  tensor(0.0968, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  121  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  122  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  123  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  124  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  125  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  126  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  127  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  128  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  129  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  130  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  131  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  132  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  133  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  134  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  135  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  136  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  137  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  138  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  139  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  140  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  141  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  142  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  143  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  144  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  145  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  146  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  147  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  148  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  149  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  150  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  151  loss  tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  152  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  153  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  154  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  155  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  156  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  157  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  158  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  159  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  160  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  161  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  162  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  163  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  164  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  165  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  166  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  167  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  168  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  169  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  170  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  171  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  172  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  173  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  174  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  175  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  176  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  177  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  178  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  179  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  180  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  181  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  182  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  183  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  184  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  185  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  186  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  187  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  188  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  189  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  190  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  191  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  192  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  193  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  194  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  195  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  196  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  197  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  198  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  199  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  200  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  201  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  202  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  203  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  204  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  205  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  206  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  207  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  208  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  209  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  210  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  211  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  212  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  213  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  214  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  62  batch  215  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  216  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  217  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  218  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  219  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  220  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  221  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  222  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  223  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  224  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  225  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  226  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  227  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  228  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  229  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  230  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  231  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  232  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  233  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  234  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  235  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  236  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  237  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  238  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  239  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  240  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  241  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  242  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  243  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  244  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  245  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  246  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  247  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  248  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  249  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  250  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  251  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  252  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  253  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  254  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  255  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  256  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  257  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  258  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  259  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  260  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  261  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  262  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  263  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  264  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  265  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  266  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  267  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  268  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  269  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  270  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  271  loss  tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  272  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  273  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  274  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  275  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  276  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  277  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  278  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  279  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  280  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  281  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  282  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  283  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  284  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  285  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  286  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  287  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  288  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  289  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  290  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  291  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  292  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  293  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  294  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  295  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  296  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  297  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  298  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  299  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  300  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  301  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  302  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  303  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  304  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  305  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  306  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  307  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  308  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  309  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  310  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  311  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  312  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  313  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  314  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  315  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  316  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  317  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  318  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  319  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  320  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  321  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  322  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  323  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  324  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  325  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  326  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  327  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  328  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  329  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  330  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  331  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  332  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  333  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  334  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  335  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  62  batch  336  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  337  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  338  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  339  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  340  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  341  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  342  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  343  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  344  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  345  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  346  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  347  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  348  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  349  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  350  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  351  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  352  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  353  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  354  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  355  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  356  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  357  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  358  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  359  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  360  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  361  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  362  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  363  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  364  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  365  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  366  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  367  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  368  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  369  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  370  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  371  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  372  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  373  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  374  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  375  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  376  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  377  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  378  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  379  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  380  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  381  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  382  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  383  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  384  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  385  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  386  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  387  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  388  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  389  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  390  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  391  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  392  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  393  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  394  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  395  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  396  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  397  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  398  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  399  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  400  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  401  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  402  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  403  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  404  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  405  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  406  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  407  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  408  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  409  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  410  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  411  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  412  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  62  batch  413  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch [63/100], loss:33.1413\n",
      "epoch  63  batch  0  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  1  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  2  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  3  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  4  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  5  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  6  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  7  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  8  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  9  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  10  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  11  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  12  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  13  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  14  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  15  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  16  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  17  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  18  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  19  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  20  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  21  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  22  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  23  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  24  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  25  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  26  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  27  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  28  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  29  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  30  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  31  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  32  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  33  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  34  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  35  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  36  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  37  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  38  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  39  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  40  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  41  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  42  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  63  batch  43  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  44  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  45  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  46  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  47  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  48  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  49  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  50  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  51  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  52  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  53  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  54  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  55  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  56  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  57  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  58  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  59  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  60  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  61  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  62  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  63  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  64  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  65  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  66  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  67  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  68  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  69  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  70  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  71  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  72  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  73  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  74  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  75  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  76  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  77  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  78  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  79  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  80  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  81  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  82  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  83  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  84  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  85  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  86  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  87  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  88  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  89  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  90  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  91  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  92  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  93  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  94  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  95  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  96  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  97  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  98  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  99  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  100  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  101  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  102  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  103  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  104  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  105  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  106  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  107  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  108  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  109  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  110  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  111  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  112  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  113  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  114  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  115  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  116  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  117  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  118  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  119  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  120  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  121  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  122  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  123  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  124  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  125  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  126  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  127  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  128  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  129  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  130  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  131  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  132  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  133  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  134  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  135  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  136  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  137  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  138  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  139  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  140  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  141  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  142  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  143  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  144  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  145  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  146  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  147  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  148  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  149  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  150  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  151  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  152  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  153  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  154  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  155  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  156  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  157  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  158  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  159  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  160  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  161  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  162  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  163  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  164  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  63  batch  165  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  166  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  167  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  168  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  169  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  170  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  171  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  172  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  173  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  174  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  175  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  176  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  177  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  178  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  179  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  180  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  181  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  182  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  183  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  184  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  185  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  186  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  187  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  188  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  189  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  190  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  191  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  192  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  193  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  194  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  195  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  196  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  197  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  198  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  199  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  200  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  201  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  202  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  203  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  204  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  205  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  206  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  207  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  208  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  209  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  210  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  211  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  212  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  213  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  214  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  215  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  216  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  217  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  218  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  219  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  220  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  221  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  222  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  223  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  224  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  225  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  226  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  227  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  228  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  229  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  230  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  231  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  232  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  233  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  234  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  235  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  236  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  237  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  238  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  239  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  240  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  241  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  242  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  243  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  244  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  245  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  246  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  247  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  248  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  249  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  250  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  251  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  252  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  253  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  254  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  255  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  256  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  257  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  258  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  259  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  260  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  261  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  262  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  263  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  264  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  265  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  266  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  267  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  268  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  269  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  270  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  271  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  272  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  273  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  274  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  275  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  276  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  277  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  278  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  279  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  280  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  281  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  282  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  283  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  284  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  285  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  63  batch  286  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  287  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  288  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  289  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  290  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  291  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  292  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  293  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  294  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  295  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  296  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  297  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  298  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  299  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  300  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  301  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  302  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  303  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  304  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  305  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  306  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  307  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  308  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  309  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  310  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  311  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  312  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  313  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  314  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  315  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  316  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  317  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  318  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  319  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  320  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  321  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  322  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  323  loss  tensor(0.0627, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  324  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  325  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  326  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  327  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  328  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  329  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  330  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  331  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  332  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  333  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  334  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  335  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  336  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  337  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  338  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  339  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  340  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  341  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  342  loss  tensor(0.0672, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  343  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  344  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  345  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  346  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  347  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  348  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  349  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  350  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  351  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  352  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  353  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  354  loss  tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  355  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  356  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  357  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  358  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  359  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  360  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  361  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  362  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  363  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  364  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  365  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  366  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  367  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  368  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  369  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  370  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  371  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  372  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  373  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  374  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  375  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  376  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  377  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  378  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  379  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  380  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  381  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  382  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  383  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  384  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  385  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  386  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  387  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  388  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  389  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  390  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  391  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  392  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  393  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  394  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  395  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  396  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  397  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  398  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  399  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  400  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  401  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  402  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  403  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  404  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  405  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  406  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  63  batch  407  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  408  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  409  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  410  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  411  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  412  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  63  batch  413  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch [64/100], loss:33.1406\n",
      "epoch  64  batch  0  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  1  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  2  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  3  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  4  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  5  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  6  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  7  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  8  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  9  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  10  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  11  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  12  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  13  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  14  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  15  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  16  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  17  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  18  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  19  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  20  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  21  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  22  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  23  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  24  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  25  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  26  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  27  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  28  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  29  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  30  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  31  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  32  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  33  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  34  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  35  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  36  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  37  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  38  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  39  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  40  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  41  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  42  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  43  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  44  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  45  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  46  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  47  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  48  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  49  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  50  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  51  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  52  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  53  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  54  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  55  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  56  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  57  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  58  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  59  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  60  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  61  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  62  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  63  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  64  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  65  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  66  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  67  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  68  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  69  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  70  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  71  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  72  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  73  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  74  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  75  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  76  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  77  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  78  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  79  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  80  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  81  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  82  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  83  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  84  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  85  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  86  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  87  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  88  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  89  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  90  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  91  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  92  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  93  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  94  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  95  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  96  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  97  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  98  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  99  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  100  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  101  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  102  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  103  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  104  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  105  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  106  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  107  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  108  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  109  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  110  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  111  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  112  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  113  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  114  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  64  batch  115  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  116  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  117  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  118  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  119  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  120  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  121  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  122  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  123  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  124  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  125  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  126  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  127  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  128  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  129  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  130  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  131  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  132  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  133  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  134  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  135  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  136  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  137  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  138  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  139  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  140  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  141  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  142  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  143  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  144  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  145  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  146  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  147  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  148  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  149  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  150  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  151  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  152  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  153  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  154  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  155  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  156  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  157  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  158  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  159  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  160  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  161  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  162  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  163  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  164  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  165  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  166  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  167  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  168  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  169  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  170  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  171  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  172  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  173  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  174  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  175  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  176  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  177  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  178  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  179  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  180  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  181  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  182  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  183  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  184  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  185  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  186  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  187  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  188  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  189  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  190  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  191  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  192  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  193  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  194  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  195  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  196  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  197  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  198  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  199  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  200  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  201  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  202  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  203  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  204  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  205  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  206  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  207  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  208  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  209  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  210  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  211  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  212  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  213  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  214  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  215  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  216  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  217  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  218  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  219  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  220  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  221  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  222  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  223  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  224  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  225  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  226  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  227  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  228  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  229  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  230  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  231  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  232  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  233  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  234  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  235  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  64  batch  236  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  237  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  238  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  239  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  240  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  241  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  242  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  243  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  244  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  245  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  246  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  247  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  248  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  249  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  250  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  251  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  252  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  253  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  254  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  255  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  256  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  257  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  258  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  259  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  260  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  261  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  262  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  263  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  264  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  265  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  266  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  267  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  268  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  269  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  270  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  271  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  272  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  273  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  274  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  275  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  276  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  277  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  278  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  279  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  280  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  281  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  282  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  283  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  284  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  285  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  286  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  287  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  288  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  289  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  290  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  291  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  292  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  293  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  294  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  295  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  296  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  297  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  298  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  299  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  300  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  301  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  302  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  303  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  304  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  305  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  306  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  307  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  308  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  309  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  310  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  311  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  312  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  313  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  314  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  315  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  316  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  317  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  318  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  319  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  320  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  321  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  322  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  323  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  324  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  325  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  326  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  327  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  328  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  329  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  330  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  331  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  332  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  333  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  334  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  335  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  336  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  337  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  338  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  339  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  340  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  341  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  342  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  343  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  344  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  345  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  346  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  347  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  348  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  349  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  350  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  351  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  352  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  353  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  354  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  355  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  356  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  64  batch  357  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  358  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  359  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  360  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  361  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  362  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  363  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  364  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  365  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  366  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  367  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  368  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  369  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  370  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  371  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  372  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  373  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  374  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  375  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  376  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  377  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  378  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  379  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  380  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  381  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  382  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  383  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  384  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  385  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  386  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  387  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  388  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  389  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  390  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  391  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  392  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  393  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  394  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  395  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  396  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  397  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  398  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  399  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  400  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  401  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  402  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  403  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  404  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  405  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  406  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  407  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  408  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  409  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  410  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  411  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  412  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  64  batch  413  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch [65/100], loss:33.1443\n",
      "epoch  65  batch  0  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  1  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  2  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  3  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  4  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  5  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  6  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  7  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  8  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  9  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  10  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  11  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  12  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  13  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  14  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  15  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  16  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  17  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  18  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  19  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  20  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  21  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  22  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  23  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  24  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  25  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  26  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  27  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  28  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  29  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  30  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  31  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  32  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  33  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  34  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  35  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  36  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  37  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  38  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  39  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  40  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  41  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  42  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  43  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  44  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  45  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  46  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  47  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  48  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  49  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  50  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  51  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  52  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  53  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  54  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  55  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  56  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  57  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  58  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  59  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  60  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  61  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  62  loss  tensor(0.0962, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  63  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  64  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  65  batch  65  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  66  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  67  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  68  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  69  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  70  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  71  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  72  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  73  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  74  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  75  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  76  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  77  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  78  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  79  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  80  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  81  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  82  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  83  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  84  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  85  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  86  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  87  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  88  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  89  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  90  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  91  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  92  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  93  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  94  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  95  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  96  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  97  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  98  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  99  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  100  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  101  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  102  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  103  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  104  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  105  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  106  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  107  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  108  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  109  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  110  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  111  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  112  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  113  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  114  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  115  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  116  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  117  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  118  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  119  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  120  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  121  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  122  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  123  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  124  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  125  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  126  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  127  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  128  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  129  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  130  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  131  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  132  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  133  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  134  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  135  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  136  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  137  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  138  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  139  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  140  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  141  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  142  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  143  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  144  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  145  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  146  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  147  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  148  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  149  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  150  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  151  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  152  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  153  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  154  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  155  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  156  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  157  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  158  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  159  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  160  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  161  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  162  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  163  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  164  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  165  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  166  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  167  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  168  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  169  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  170  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  171  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  172  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  173  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  174  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  175  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  176  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  177  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  178  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  179  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  180  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  181  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  182  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  183  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  184  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  185  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  65  batch  186  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  187  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  188  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  189  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  190  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  191  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  192  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  193  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  194  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  195  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  196  loss  tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  197  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  198  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  199  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  200  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  201  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  202  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  203  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  204  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  205  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  206  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  207  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  208  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  209  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  210  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  211  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  212  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  213  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  214  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  215  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  216  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  217  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  218  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  219  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  220  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  221  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  222  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  223  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  224  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  225  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  226  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  227  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  228  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  229  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  230  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  231  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  232  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  233  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  234  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  235  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  236  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  237  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  238  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  239  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  240  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  241  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  242  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  243  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  244  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  245  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  246  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  247  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  248  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  249  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  250  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  251  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  252  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  253  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  254  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  255  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  256  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  257  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  258  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  259  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  260  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  261  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  262  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  263  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  264  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  265  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  266  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  267  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  268  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  269  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  270  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  271  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  272  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  273  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  274  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  275  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  276  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  277  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  278  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  279  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  280  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  281  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  282  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  283  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  284  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  285  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  286  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  287  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  288  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  289  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  290  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  291  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  292  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  293  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  294  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  295  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  296  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  297  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  298  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  299  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  300  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  301  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  302  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  303  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  304  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  305  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  306  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  65  batch  307  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  308  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  309  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  310  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  311  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  312  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  313  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  314  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  315  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  316  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  317  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  318  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  319  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  320  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  321  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  322  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  323  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  324  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  325  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  326  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  327  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  328  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  329  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  330  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  331  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  332  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  333  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  334  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  335  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  336  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  337  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  338  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  339  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  340  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  341  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  342  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  343  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  344  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  345  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  346  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  347  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  348  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  349  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  350  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  351  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  352  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  353  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  354  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  355  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  356  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  357  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  358  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  359  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  360  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  361  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  362  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  363  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  364  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  365  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  366  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  367  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  368  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  369  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  370  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  371  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  372  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  373  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  374  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  375  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  376  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  377  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  378  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  379  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  380  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  381  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  382  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  383  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  384  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  385  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  386  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  387  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  388  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  389  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  390  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  391  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  392  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  393  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  394  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  395  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  396  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  397  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  398  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  399  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  400  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  401  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  402  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  403  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  404  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  405  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  406  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  407  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  408  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  409  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  410  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  411  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  412  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  65  batch  413  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch [66/100], loss:33.1358\n",
      "epoch  66  batch  0  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  1  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  2  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  3  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  4  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  5  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  6  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  7  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  8  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  9  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  10  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  11  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  12  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  13  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  66  batch  14  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  15  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  16  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  17  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  18  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  19  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  20  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  21  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  22  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  23  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  24  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  25  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  26  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  27  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  28  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  29  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  30  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  31  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  32  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  33  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  34  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  35  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  36  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  37  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  38  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  39  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  40  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  41  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  42  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  43  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  44  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  45  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  46  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  47  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  48  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  49  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  50  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  51  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  52  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  53  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  54  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  55  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  56  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  57  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  58  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  59  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  60  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  61  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  62  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  63  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  64  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  65  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  66  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  67  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  68  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  69  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  70  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  71  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  72  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  73  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  74  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  75  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  76  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  77  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  78  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  79  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  80  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  81  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  82  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  83  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  84  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  85  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  86  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  87  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  88  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  89  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  90  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  91  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  92  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  93  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  94  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  95  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  96  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  97  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  98  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  99  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  100  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  101  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  102  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  103  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  104  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  105  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  106  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  107  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  108  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  109  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  110  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  111  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  112  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  113  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  114  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  115  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  116  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  117  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  118  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  119  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  120  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  121  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  122  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  123  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  124  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  125  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  126  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  127  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  128  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  129  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  130  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  131  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  132  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  133  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  134  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  135  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  66  batch  136  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  137  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  138  loss  tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  139  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  140  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  141  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  142  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  143  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  144  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  145  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  146  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  147  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  148  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  149  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  150  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  151  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  152  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  153  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  154  loss  tensor(0.0640, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  155  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  156  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  157  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  158  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  159  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  160  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  161  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  162  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  163  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  164  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  165  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  166  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  167  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  168  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  169  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  170  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  171  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  172  loss  tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  173  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  174  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  175  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  176  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  177  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  178  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  179  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  180  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  181  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  182  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  183  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  184  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  185  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  186  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  187  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  188  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  189  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  190  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  191  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  192  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  193  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  194  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  195  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  196  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  197  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  198  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  199  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  200  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  201  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  202  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  203  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  204  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  205  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  206  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  207  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  208  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  209  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  210  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  211  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  212  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  213  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  214  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  215  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  216  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  217  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  218  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  219  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  220  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  221  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  222  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  223  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  224  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  225  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  226  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  227  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  228  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  229  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  230  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  231  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  232  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  233  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  234  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  235  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  236  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  237  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  238  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  239  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  240  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  241  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  242  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  243  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  244  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  245  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  246  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  247  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  248  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  249  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  250  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  251  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  252  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  253  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  254  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  255  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  256  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  66  batch  257  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  258  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  259  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  260  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  261  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  262  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  263  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  264  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  265  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  266  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  267  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  268  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  269  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  270  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  271  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  272  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  273  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  274  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  275  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  276  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  277  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  278  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  279  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  280  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  281  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  282  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  283  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  284  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  285  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  286  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  287  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  288  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  289  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  290  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  291  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  292  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  293  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  294  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  295  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  296  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  297  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  298  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  299  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  300  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  301  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  302  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  303  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  304  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  305  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  306  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  307  loss  tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  308  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  309  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  310  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  311  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  312  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  313  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  314  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  315  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  316  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  317  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  318  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  319  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  320  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  321  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  322  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  323  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  324  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  325  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  326  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  327  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  328  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  329  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  330  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  331  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  332  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  333  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  334  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  335  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  336  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  337  loss  tensor(0.0966, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  338  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  339  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  340  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  341  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  342  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  343  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  344  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  345  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  346  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  347  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  348  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  349  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  350  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  351  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  352  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  353  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  354  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  355  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  356  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  357  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  358  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  359  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  360  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  361  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  362  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  363  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  364  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  365  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  366  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  367  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  368  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  369  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  370  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  371  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  372  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  373  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  374  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  375  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  376  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  377  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  66  batch  378  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  379  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  380  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  381  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  382  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  383  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  384  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  385  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  386  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  387  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  388  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  389  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  390  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  391  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  392  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  393  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  394  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  395  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  396  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  397  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  398  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  399  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  400  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  401  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  402  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  403  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  404  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  405  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  406  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  407  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  408  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  409  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  410  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  411  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  412  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  66  batch  413  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch [67/100], loss:33.1405\n",
      "epoch  67  batch  0  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  1  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  2  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  3  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  4  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  5  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  6  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  7  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  8  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  9  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  10  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  11  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  12  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  13  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  14  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  15  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  16  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  17  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  18  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  19  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  20  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  21  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  22  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  23  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  24  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  25  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  26  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  27  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  28  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  29  loss  tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  30  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  31  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  32  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  33  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  34  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  35  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  36  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  37  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  38  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  39  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  40  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  41  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  42  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  43  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  44  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  45  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  46  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  47  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  48  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  49  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  50  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  51  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  52  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  53  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  54  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  55  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  56  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  57  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  58  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  59  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  60  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  61  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  62  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  63  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  64  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  65  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  66  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  67  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  68  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  69  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  70  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  71  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  72  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  73  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  74  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  75  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  76  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  77  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  78  loss  tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  79  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  80  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  81  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  82  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  83  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  84  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  85  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  67  batch  86  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  87  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  88  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  89  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  90  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  91  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  92  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  93  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  94  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  95  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  96  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  97  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  98  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  99  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  100  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  101  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  102  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  103  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  104  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  105  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  106  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  107  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  108  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  109  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  110  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  111  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  112  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  113  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  114  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  115  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  116  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  117  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  118  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  119  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  120  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  121  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  122  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  123  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  124  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  125  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  126  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  127  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  128  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  129  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  130  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  131  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  132  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  133  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  134  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  135  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  136  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  137  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  138  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  139  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  140  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  141  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  142  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  143  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  144  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  145  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  146  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  147  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  148  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  149  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  150  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  151  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  152  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  153  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  154  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  155  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  156  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  157  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  158  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  159  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  160  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  161  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  162  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  163  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  164  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  165  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  166  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  167  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  168  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  169  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  170  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  171  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  172  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  173  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  174  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  175  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  176  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  177  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  178  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  179  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  180  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  181  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  182  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  183  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  184  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  185  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  186  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  187  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  188  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  189  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  190  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  191  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  192  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  193  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  194  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  195  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  196  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  197  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  198  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  199  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  200  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  201  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  202  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  203  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  204  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  205  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  206  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  67  batch  207  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  208  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  209  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  210  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  211  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  212  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  213  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  214  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  215  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  216  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  217  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  218  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  219  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  220  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  221  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  222  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  223  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  224  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  225  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  226  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  227  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  228  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  229  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  230  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  231  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  232  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  233  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  234  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  235  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  236  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  237  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  238  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  239  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  240  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  241  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  242  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  243  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  244  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  245  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  246  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  247  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  248  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  249  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  250  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  251  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  252  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  253  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  254  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  255  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  256  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  257  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  258  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  259  loss  tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  260  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  261  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  262  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  263  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  264  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  265  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  266  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  267  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  268  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  269  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  270  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  271  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  272  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  273  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  274  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  275  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  276  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  277  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  278  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  279  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  280  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  281  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  282  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  283  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  284  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  285  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  286  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  287  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  288  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  289  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  290  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  291  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  292  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  293  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  294  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  295  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  296  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  297  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  298  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  299  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  300  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  301  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  302  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  303  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  304  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  305  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  306  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  307  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  308  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  309  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  310  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  311  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  312  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  313  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  314  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  315  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  316  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  317  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  318  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  319  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  320  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  321  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  322  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  323  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  324  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  325  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  326  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  327  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  67  batch  328  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  329  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  330  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  331  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  332  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  333  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  334  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  335  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  336  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  337  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  338  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  339  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  340  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  341  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  342  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  343  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  344  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  345  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  346  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  347  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  348  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  349  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  350  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  351  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  352  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  353  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  354  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  355  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  356  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  357  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  358  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  359  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  360  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  361  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  362  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  363  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  364  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  365  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  366  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  367  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  368  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  369  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  370  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  371  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  372  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  373  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  374  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  375  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  376  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  377  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  378  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  379  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  380  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  381  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  382  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  383  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  384  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  385  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  386  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  387  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  388  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  389  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  390  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  391  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  392  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  393  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  394  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  395  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  396  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  397  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  398  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  399  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  400  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  401  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  402  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  403  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  404  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  405  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  406  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  407  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  408  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  409  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  410  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  411  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  412  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  67  batch  413  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch [68/100], loss:33.1449\n",
      "epoch  68  batch  0  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  1  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  2  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  3  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  4  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  5  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  6  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  7  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  8  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  9  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  10  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  11  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  12  loss  tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  13  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  14  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  15  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  16  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  17  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  18  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  19  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  20  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  21  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  22  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  23  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  24  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  25  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  26  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  27  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  28  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  29  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  30  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  31  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  32  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  33  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  34  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  68  batch  35  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  36  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  37  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  38  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  39  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  40  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  41  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  42  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  43  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  44  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  45  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  46  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  47  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  48  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  49  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  50  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  51  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  52  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  53  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  54  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  55  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  56  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  57  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  58  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  59  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  60  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  61  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  62  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  63  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  64  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  65  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  66  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  67  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  68  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  69  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  70  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  71  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  72  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  73  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  74  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  75  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  76  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  77  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  78  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  79  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  80  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  81  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  82  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  83  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  84  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  85  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  86  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  87  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  88  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  89  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  90  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  91  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  92  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  93  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  94  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  95  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  96  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  97  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  98  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  99  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  100  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  101  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  102  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  103  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  104  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  105  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  106  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  107  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  108  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  109  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  110  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  111  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  112  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  113  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  114  loss  tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  115  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  116  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  117  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  118  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  119  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  120  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  121  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  122  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  123  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  124  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  125  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  126  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  127  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  128  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  129  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  130  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  131  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  132  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  133  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  134  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  135  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  136  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  137  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  138  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  139  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  140  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  141  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  142  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  143  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  144  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  145  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  146  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  147  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  148  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  149  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  150  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  151  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  152  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  153  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  154  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  155  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  156  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  68  batch  157  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  158  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  159  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  160  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  161  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  162  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  163  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  164  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  165  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  166  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  167  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  168  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  169  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  170  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  171  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  172  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  173  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  174  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  175  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  176  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  177  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  178  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  179  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  180  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  181  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  182  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  183  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  184  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  185  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  186  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  187  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  188  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  189  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  190  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  191  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  192  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  193  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  194  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  195  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  196  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  197  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  198  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  199  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  200  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  201  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  202  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  203  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  204  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  205  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  206  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  207  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  208  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  209  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  210  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  211  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  212  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  213  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  214  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  215  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  216  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  217  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  218  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  219  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  220  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  221  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  222  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  223  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  224  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  225  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  226  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  227  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  228  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  229  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  230  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  231  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  232  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  233  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  234  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  235  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  236  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  237  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  238  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  239  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  240  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  241  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  242  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  243  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  244  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  245  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  246  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  247  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  248  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  249  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  250  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  251  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  252  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  253  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  254  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  255  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  256  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  257  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  258  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  259  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  260  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  261  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  262  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  263  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  264  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  265  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  266  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  267  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  268  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  269  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  270  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  271  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  272  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  273  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  274  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  275  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  276  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  277  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  68  batch  278  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  279  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  280  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  281  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  282  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  283  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  284  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  285  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  286  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  287  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  288  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  289  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  290  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  291  loss  tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  292  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  293  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  294  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  295  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  296  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  297  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  298  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  299  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  300  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  301  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  302  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  303  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  304  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  305  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  306  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  307  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  308  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  309  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  310  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  311  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  312  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  313  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  314  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  315  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  316  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  317  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  318  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  319  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  320  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  321  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  322  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  323  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  324  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  325  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  326  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  327  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  328  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  329  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  330  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  331  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  332  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  333  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  334  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  335  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  336  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  337  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  338  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  339  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  340  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  341  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  342  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  343  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  344  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  345  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  346  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  347  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  348  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  349  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  350  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  351  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  352  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  353  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  354  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  355  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  356  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  357  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  358  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  359  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  360  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  361  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  362  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  363  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  364  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  365  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  366  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  367  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  368  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  369  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  370  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  371  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  372  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  373  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  374  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  375  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  376  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  377  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  378  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  379  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  380  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  381  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  382  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  383  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  384  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  385  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  386  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  387  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  388  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  389  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  390  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  391  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  392  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  393  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  394  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  395  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  396  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  397  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  398  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  68  batch  399  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  400  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  401  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  402  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  403  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  404  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  405  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  406  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  407  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  408  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  409  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  410  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  411  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  412  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  68  batch  413  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch [69/100], loss:33.1379\n",
      "epoch  69  batch  0  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  1  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  2  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  3  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  4  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  5  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  6  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  7  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  8  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  9  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  10  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  11  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  12  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  13  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  14  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  15  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  16  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  17  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  18  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  19  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  20  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  21  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  22  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  23  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  24  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  25  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  26  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  27  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  28  loss  tensor(0.0650, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  29  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  30  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  31  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  32  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  33  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  34  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  35  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  36  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  37  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  38  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  39  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  40  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  41  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  42  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  43  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  44  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  45  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  46  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  47  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  48  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  49  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  50  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  51  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  52  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  53  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  54  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  55  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  56  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  57  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  58  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  59  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  60  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  61  loss  tensor(0.1003, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  62  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  63  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  64  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  65  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  66  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  67  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  68  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  69  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  70  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  71  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  72  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  73  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  74  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  75  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  76  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  77  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  78  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  79  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  80  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  81  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  82  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  83  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  84  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  85  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  86  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  87  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  88  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  89  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  90  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  91  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  92  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  93  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  94  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  95  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  96  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  97  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  98  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  99  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  100  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  101  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  102  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  103  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  104  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  105  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  106  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  69  batch  107  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  108  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  109  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  110  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  111  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  112  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  113  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  114  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  115  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  116  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  117  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  118  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  119  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  120  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  121  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  122  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  123  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  124  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  125  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  126  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  127  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  128  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  129  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  130  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  131  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  132  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  133  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  134  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  135  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  136  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  137  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  138  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  139  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  140  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  141  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  142  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  143  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  144  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  145  loss  tensor(0.0668, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  146  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  147  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  148  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  149  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  150  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  151  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  152  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  153  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  154  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  155  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  156  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  157  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  158  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  159  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  160  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  161  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  162  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  163  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  164  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  165  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  166  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  167  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  168  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  169  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  170  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  171  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  172  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  173  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  174  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  175  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  176  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  177  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  178  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  179  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  180  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  181  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  182  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  183  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  184  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  185  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  186  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  187  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  188  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  189  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  190  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  191  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  192  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  193  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  194  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  195  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  196  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  197  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  198  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  199  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  200  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  201  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  202  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  203  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  204  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  205  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  206  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  207  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  208  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  209  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  210  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  211  loss  tensor(0.0974, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  212  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  213  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  214  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  215  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  216  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  217  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  218  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  219  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  220  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  221  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  222  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  223  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  224  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  225  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  226  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  227  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  69  batch  228  loss  tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  229  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  230  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  231  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  232  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  233  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  234  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  235  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  236  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  237  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  238  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  239  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  240  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  241  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  242  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  243  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  244  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  245  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  246  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  247  loss  tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  248  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  249  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  250  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  251  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  252  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  253  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  254  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  255  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  256  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  257  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  258  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  259  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  260  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  261  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  262  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  263  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  264  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  265  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  266  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  267  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  268  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  269  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  270  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  271  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  272  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  273  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  274  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  275  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  276  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  277  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  278  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  279  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  280  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  281  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  282  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  283  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  284  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  285  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  286  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  287  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  288  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  289  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  290  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  291  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  292  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  293  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  294  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  295  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  296  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  297  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  298  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  299  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  300  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  301  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  302  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  303  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  304  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  305  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  306  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  307  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  308  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  309  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  310  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  311  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  312  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  313  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  314  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  315  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  316  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  317  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  318  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  319  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  320  loss  tensor(0.0675, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  321  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  322  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  323  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  324  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  325  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  326  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  327  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  328  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  329  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  330  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  331  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  332  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  333  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  334  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  335  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  336  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  337  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  338  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  339  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  340  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  341  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  342  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  343  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  344  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  345  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  346  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  347  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  348  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  69  batch  349  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  350  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  351  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  352  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  353  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  354  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  355  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  356  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  357  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  358  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  359  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  360  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  361  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  362  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  363  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  364  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  365  loss  tensor(0.0989, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  366  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  367  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  368  loss  tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  369  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  370  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  371  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  372  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  373  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  374  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  375  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  376  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  377  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  378  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  379  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  380  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  381  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  382  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  383  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  384  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  385  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  386  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  387  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  388  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  389  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  390  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  391  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  392  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  393  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  394  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  395  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  396  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  397  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  398  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  399  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  400  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  401  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  402  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  403  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  404  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  405  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  406  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  407  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  408  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  409  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  410  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  411  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  412  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  69  batch  413  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch [70/100], loss:33.1413\n",
      "epoch  70  batch  0  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  1  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  2  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  3  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  4  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  5  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  6  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  7  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  8  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  9  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  10  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  11  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  12  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  13  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  14  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  15  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  16  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  17  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  18  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  19  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  20  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  21  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  22  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  23  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  24  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  25  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  26  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  27  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  28  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  29  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  30  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  31  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  32  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  33  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  34  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  35  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  36  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  37  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  38  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  39  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  40  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  41  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  42  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  43  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  44  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  45  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  46  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  47  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  48  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  49  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  50  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  51  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  52  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  53  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  54  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  55  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  56  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  70  batch  57  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  58  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  59  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  60  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  61  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  62  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  63  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  64  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  65  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  66  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  67  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  68  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  69  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  70  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  71  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  72  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  73  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  74  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  75  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  76  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  77  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  78  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  79  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  80  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  81  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  82  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  83  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  84  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  85  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  86  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  87  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  88  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  89  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  90  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  91  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  92  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  93  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  94  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  95  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  96  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  97  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  98  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  99  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  100  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  101  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  102  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  103  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  104  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  105  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  106  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  107  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  108  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  109  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  110  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  111  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  112  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  113  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  114  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  115  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  116  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  117  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  118  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  119  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  120  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  121  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  122  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  123  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  124  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  125  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  126  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  127  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  128  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  129  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  130  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  131  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  132  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  133  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  134  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  135  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  136  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  137  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  138  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  139  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  140  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  141  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  142  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  143  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  144  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  145  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  146  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  147  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  148  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  149  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  150  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  151  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  152  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  153  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  154  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  155  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  156  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  157  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  158  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  159  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  160  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  161  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  162  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  163  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  164  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  165  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  166  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  167  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  168  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  169  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  170  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  171  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  172  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  173  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  174  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  175  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  176  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  177  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  178  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  70  batch  179  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  180  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  181  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  182  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  183  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  184  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  185  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  186  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  187  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  188  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  189  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  190  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  191  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  192  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  193  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  194  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  195  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  196  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  197  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  198  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  199  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  200  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  201  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  202  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  203  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  204  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  205  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  206  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  207  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  208  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  209  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  210  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  211  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  212  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  213  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  214  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  215  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  216  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  217  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  218  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  219  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  220  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  221  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  222  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  223  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  224  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  225  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  226  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  227  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  228  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  229  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  230  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  231  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  232  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  233  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  234  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  235  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  236  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  237  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  238  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  239  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  240  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  241  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  242  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  243  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  244  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  245  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  246  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  247  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  248  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  249  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  250  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  251  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  252  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  253  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  254  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  255  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  256  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  257  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  258  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  259  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  260  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  261  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  262  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  263  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  264  loss  tensor(0.0671, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  265  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  266  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  267  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  268  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  269  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  270  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  271  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  272  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  273  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  274  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  275  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  276  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  277  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  278  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  279  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  280  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  281  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  282  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  283  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  284  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  285  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  286  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  287  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  288  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  289  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  290  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  291  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  292  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  293  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  294  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  295  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  296  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  297  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  298  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  299  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  70  batch  300  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  301  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  302  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  303  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  304  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  305  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  306  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  307  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  308  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  309  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  310  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  311  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  312  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  313  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  314  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  315  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  316  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  317  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  318  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  319  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  320  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  321  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  322  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  323  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  324  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  325  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  326  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  327  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  328  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  329  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  330  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  331  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  332  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  333  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  334  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  335  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  336  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  337  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  338  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  339  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  340  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  341  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  342  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  343  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  344  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  345  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  346  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  347  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  348  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  349  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  350  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  351  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  352  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  353  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  354  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  355  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  356  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  357  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  358  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  359  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  360  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  361  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  362  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  363  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  364  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  365  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  366  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  367  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  368  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  369  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  370  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  371  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  372  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  373  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  374  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  375  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  376  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  377  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  378  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  379  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  380  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  381  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  382  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  383  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  384  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  385  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  386  loss  tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  387  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  388  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  389  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  390  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  391  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  392  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  393  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  394  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  395  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  396  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  397  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  398  loss  tensor(0.0675, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  399  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  400  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  401  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  402  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  403  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  404  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  405  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  406  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  407  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  408  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  409  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  410  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  411  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  412  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  70  batch  413  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch [71/100], loss:33.1427\n",
      "epoch  71  batch  0  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  1  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  2  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  3  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  4  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  5  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  6  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  71  batch  7  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  8  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  9  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  10  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  11  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  12  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  13  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  14  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  15  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  16  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  17  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  18  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  19  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  20  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  21  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  22  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  23  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  24  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  25  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  26  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  27  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  28  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  29  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  30  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  31  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  32  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  33  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  34  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  35  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  36  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  37  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  38  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  39  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  40  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  41  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  42  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  43  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  44  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  45  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  46  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  47  loss  tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  48  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  49  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  50  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  51  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  52  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  53  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  54  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  55  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  56  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  57  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  58  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  59  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  60  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  61  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  62  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  63  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  64  loss  tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  65  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  66  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  67  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  68  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  69  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  70  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  71  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  72  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  73  loss  tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  74  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  75  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  76  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  77  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  78  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  79  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  80  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  81  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  82  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  83  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  84  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  85  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  86  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  87  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  88  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  89  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  90  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  91  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  92  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  93  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  94  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  95  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  96  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  97  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  98  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  99  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  100  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  101  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  102  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  103  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  104  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  105  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  106  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  107  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  108  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  109  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  110  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  111  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  112  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  113  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  114  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  115  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  116  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  117  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  118  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  119  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  120  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  121  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  122  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  123  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  124  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  125  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  126  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  127  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  128  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  71  batch  129  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  130  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  131  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  132  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  133  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  134  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  135  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  136  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  137  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  138  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  139  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  140  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  141  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  142  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  143  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  144  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  145  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  146  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  147  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  148  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  149  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  150  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  151  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  152  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  153  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  154  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  155  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  156  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  157  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  158  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  159  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  160  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  161  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  162  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  163  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  164  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  165  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  166  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  167  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  168  loss  tensor(0.0657, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  169  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  170  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  171  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  172  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  173  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  174  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  175  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  176  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  177  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  178  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  179  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  180  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  181  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  182  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  183  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  184  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  185  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  186  loss  tensor(0.0648, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  187  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  188  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  189  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  190  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  191  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  192  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  193  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  194  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  195  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  196  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  197  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  198  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  199  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  200  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  201  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  202  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  203  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  204  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  205  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  206  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  207  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  208  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  209  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  210  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  211  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  212  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  213  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  214  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  215  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  216  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  217  loss  tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  218  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  219  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  220  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  221  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  222  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  223  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  224  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  225  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  226  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  227  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  228  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  229  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  230  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  231  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  232  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  233  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  234  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  235  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  236  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  237  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  238  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  239  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  240  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  241  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  242  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  243  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  244  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  245  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  246  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  247  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  248  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  249  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  71  batch  250  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  251  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  252  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  253  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  254  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  255  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  256  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  257  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  258  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  259  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  260  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  261  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  262  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  263  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  264  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  265  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  266  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  267  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  268  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  269  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  270  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  271  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  272  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  273  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  274  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  275  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  276  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  277  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  278  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  279  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  280  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  281  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  282  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  283  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  284  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  285  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  286  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  287  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  288  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  289  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  290  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  291  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  292  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  293  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  294  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  295  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  296  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  297  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  298  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  299  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  300  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  301  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  302  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  303  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  304  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  305  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  306  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  307  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  308  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  309  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  310  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  311  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  312  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  313  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  314  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  315  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  316  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  317  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  318  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  319  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  320  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  321  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  322  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  323  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  324  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  325  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  326  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  327  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  328  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  329  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  330  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  331  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  332  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  333  loss  tensor(0.0966, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  334  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  335  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  336  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  337  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  338  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  339  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  340  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  341  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  342  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  343  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  344  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  345  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  346  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  347  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  348  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  349  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  350  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  351  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  352  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  353  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  354  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  355  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  356  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  357  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  358  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  359  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  360  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  361  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  362  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  363  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  364  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  365  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  366  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  367  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  368  loss  tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  369  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  370  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  71  batch  371  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  372  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  373  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  374  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  375  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  376  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  377  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  378  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  379  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  380  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  381  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  382  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  383  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  384  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  385  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  386  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  387  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  388  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  389  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  390  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  391  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  392  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  393  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  394  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  395  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  396  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  397  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  398  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  399  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  400  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  401  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  402  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  403  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  404  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  405  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  406  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  407  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  408  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  409  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  410  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  411  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  412  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  71  batch  413  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch [72/100], loss:33.1429\n",
      "epoch  72  batch  0  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  1  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  2  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  3  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  4  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  5  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  6  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  7  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  8  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  9  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  10  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  11  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  12  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  13  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  14  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  15  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  16  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  17  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  18  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  19  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  20  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  21  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  22  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  23  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  24  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  25  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  26  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  27  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  28  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  29  loss  tensor(0.0661, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  30  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  31  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  32  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  33  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  34  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  35  loss  tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  36  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  37  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  38  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  39  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  40  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  41  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  42  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  43  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  44  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  45  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  46  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  47  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  48  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  49  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  50  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  51  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  52  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  53  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  54  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  55  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  56  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  57  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  58  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  59  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  60  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  61  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  62  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  63  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  64  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  65  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  66  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  67  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  68  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  69  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  70  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  71  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  72  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  73  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  74  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  75  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  76  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  77  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  78  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  72  batch  79  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  80  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  81  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  82  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  83  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  84  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  85  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  86  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  87  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  88  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  89  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  90  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  91  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  92  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  93  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  94  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  95  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  96  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  97  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  98  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  99  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  100  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  101  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  102  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  103  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  104  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  105  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  106  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  107  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  108  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  109  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  110  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  111  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  112  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  113  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  114  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  115  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  116  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  117  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  118  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  119  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  120  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  121  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  122  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  123  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  124  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  125  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  126  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  127  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  128  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  129  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  130  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  131  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  132  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  133  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  134  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  135  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  136  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  137  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  138  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  139  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  140  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  141  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  142  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  143  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  144  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  145  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  146  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  147  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  148  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  149  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  150  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  151  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  152  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  153  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  154  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  155  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  156  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  157  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  158  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  159  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  160  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  161  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  162  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  163  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  164  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  165  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  166  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  167  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  168  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  169  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  170  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  171  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  172  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  173  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  174  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  175  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  176  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  177  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  178  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  179  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  180  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  181  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  182  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  183  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  184  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  185  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  186  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  187  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  188  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  189  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  190  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  191  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  192  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  193  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  194  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  195  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  196  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  197  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  198  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  199  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  72  batch  200  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  201  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  202  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  203  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  204  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  205  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  206  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  207  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  208  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  209  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  210  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  211  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  212  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  213  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  214  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  215  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  216  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  217  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  218  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  219  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  220  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  221  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  222  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  223  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  224  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  225  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  226  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  227  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  228  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  229  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  230  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  231  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  232  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  233  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  234  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  235  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  236  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  237  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  238  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  239  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  240  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  241  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  242  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  243  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  244  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  245  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  246  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  247  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  248  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  249  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  250  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  251  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  252  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  253  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  254  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  255  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  256  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  257  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  258  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  259  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  260  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  261  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  262  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  263  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  264  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  265  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  266  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  267  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  268  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  269  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  270  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  271  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  272  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  273  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  274  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  275  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  276  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  277  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  278  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  279  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  280  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  281  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  282  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  283  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  284  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  285  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  286  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  287  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  288  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  289  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  290  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  291  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  292  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  293  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  294  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  295  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  296  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  297  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  298  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  299  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  300  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  301  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  302  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  303  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  304  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  305  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  306  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  307  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  308  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  309  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  310  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  311  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  312  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  313  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  314  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  315  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  316  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  317  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  318  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  319  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  320  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  72  batch  321  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  322  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  323  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  324  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  325  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  326  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  327  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  328  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  329  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  330  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  331  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  332  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  333  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  334  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  335  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  336  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  337  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  338  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  339  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  340  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  341  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  342  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  343  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  344  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  345  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  346  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  347  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  348  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  349  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  350  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  351  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  352  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  353  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  354  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  355  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  356  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  357  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  358  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  359  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  360  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  361  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  362  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  363  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  364  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  365  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  366  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  367  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  368  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  369  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  370  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  371  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  372  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  373  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  374  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  375  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  376  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  377  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  378  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  379  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  380  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  381  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  382  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  383  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  384  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  385  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  386  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  387  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  388  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  389  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  390  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  391  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  392  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  393  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  394  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  395  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  396  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  397  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  398  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  399  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  400  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  401  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  402  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  403  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  404  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  405  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  406  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  407  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  408  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  409  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  410  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  411  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  412  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  72  batch  413  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch [73/100], loss:33.1464\n",
      "epoch  73  batch  0  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  1  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  2  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  3  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  4  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  5  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  6  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  7  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  8  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  9  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  10  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  11  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  12  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  13  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  14  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  15  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  16  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  17  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  18  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  19  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  20  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  21  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  22  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  23  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  24  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  25  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  26  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  27  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  73  batch  28  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  29  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  30  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  31  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  32  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  33  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  34  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  35  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  36  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  37  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  38  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  39  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  40  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  41  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  42  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  43  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  44  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  45  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  46  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  47  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  48  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  49  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  50  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  51  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  52  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  53  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  54  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  55  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  56  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  57  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  58  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  59  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  60  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  61  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  62  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  63  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  64  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  65  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  66  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  67  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  68  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  69  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  70  loss  tensor(0.0693, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  71  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  72  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  73  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  74  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  75  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  76  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  77  loss  tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  78  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  79  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  80  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  81  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  82  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  83  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  84  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  85  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  86  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  87  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  88  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  89  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  90  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  91  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  92  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  93  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  94  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  95  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  96  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  97  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  98  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  99  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  100  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  101  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  102  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  103  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  104  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  105  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  106  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  107  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  108  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  109  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  110  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  111  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  112  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  113  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  114  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  115  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  116  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  117  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  118  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  119  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  120  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  121  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  122  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  123  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  124  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  125  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  126  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  127  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  128  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  129  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  130  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  131  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  132  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  133  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  134  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  135  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  136  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  137  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  138  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  139  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  140  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  141  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  142  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  143  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  144  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  145  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  146  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  147  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  148  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  149  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  73  batch  150  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  151  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  152  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  153  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  154  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  155  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  156  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  157  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  158  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  159  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  160  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  161  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  162  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  163  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  164  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  165  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  166  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  167  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  168  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  169  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  170  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  171  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  172  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  173  loss  tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  174  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  175  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  176  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  177  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  178  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  179  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  180  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  181  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  182  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  183  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  184  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  185  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  186  loss  tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  187  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  188  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  189  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  190  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  191  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  192  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  193  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  194  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  195  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  196  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  197  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  198  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  199  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  200  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  201  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  202  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  203  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  204  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  205  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  206  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  207  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  208  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  209  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  210  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  211  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  212  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  213  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  214  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  215  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  216  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  217  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  218  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  219  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  220  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  221  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  222  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  223  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  224  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  225  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  226  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  227  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  228  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  229  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  230  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  231  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  232  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  233  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  234  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  235  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  236  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  237  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  238  loss  tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  239  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  240  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  241  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  242  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  243  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  244  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  245  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  246  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  247  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  248  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  249  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  250  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  251  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  252  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  253  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  254  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  255  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  256  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  257  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  258  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  259  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  260  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  261  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  262  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  263  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  264  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  265  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  266  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  267  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  268  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  269  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  270  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  73  batch  271  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  272  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  273  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  274  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  275  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  276  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  277  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  278  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  279  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  280  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  281  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  282  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  283  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  284  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  285  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  286  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  287  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  288  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  289  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  290  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  291  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  292  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  293  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  294  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  295  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  296  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  297  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  298  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  299  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  300  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  301  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  302  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  303  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  304  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  305  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  306  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  307  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  308  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  309  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  310  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  311  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  312  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  313  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  314  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  315  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  316  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  317  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  318  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  319  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  320  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  321  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  322  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  323  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  324  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  325  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  326  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  327  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  328  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  329  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  330  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  331  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  332  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  333  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  334  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  335  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  336  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  337  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  338  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  339  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  340  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  341  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  342  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  343  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  344  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  345  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  346  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  347  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  348  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  349  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  350  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  351  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  352  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  353  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  354  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  355  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  356  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  357  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  358  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  359  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  360  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  361  loss  tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  362  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  363  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  364  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  365  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  366  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  367  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  368  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  369  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  370  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  371  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  372  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  373  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  374  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  375  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  376  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  377  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  378  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  379  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  380  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  381  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  382  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  383  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  384  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  385  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  386  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  387  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  388  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  389  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  390  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  391  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  73  batch  392  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  393  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  394  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  395  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  396  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  397  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  398  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  399  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  400  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  401  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  402  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  403  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  404  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  405  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  406  loss  tensor(0.0671, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  407  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  408  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  409  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  410  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  411  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  412  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  73  batch  413  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch [74/100], loss:33.1437\n",
      "epoch  74  batch  0  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  1  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  2  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  3  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  4  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  5  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  6  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  7  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  8  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  9  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  10  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  11  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  12  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  13  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  14  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  15  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  16  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  17  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  18  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  19  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  20  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  21  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  22  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  23  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  24  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  25  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  26  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  27  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  28  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  29  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  30  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  31  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  32  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  33  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  34  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  35  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  36  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  37  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  38  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  39  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  40  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  41  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  42  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  43  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  44  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  45  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  46  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  47  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  48  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  49  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  50  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  51  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  52  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  53  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  54  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  55  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  56  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  57  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  58  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  59  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  60  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  61  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  62  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  63  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  64  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  65  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  66  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  67  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  68  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  69  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  70  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  71  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  72  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  73  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  74  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  75  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  76  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  77  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  78  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  79  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  80  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  81  loss  tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  82  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  83  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  84  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  85  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  86  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  87  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  88  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  89  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  90  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  91  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  92  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  93  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  94  loss  tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  95  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  96  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  97  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  98  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  99  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  74  batch  100  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  101  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  102  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  103  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  104  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  105  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  106  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  107  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  108  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  109  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  110  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  111  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  112  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  113  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  114  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  115  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  116  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  117  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  118  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  119  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  120  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  121  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  122  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  123  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  124  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  125  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  126  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  127  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  128  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  129  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  130  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  131  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  132  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  133  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  134  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  135  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  136  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  137  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  138  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  139  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  140  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  141  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  142  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  143  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  144  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  145  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  146  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  147  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  148  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  149  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  150  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  151  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  152  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  153  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  154  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  155  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  156  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  157  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  158  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  159  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  160  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  161  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  162  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  163  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  164  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  165  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  166  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  167  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  168  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  169  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  170  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  171  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  172  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  173  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  174  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  175  loss  tensor(0.0660, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  176  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  177  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  178  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  179  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  180  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  181  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  182  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  183  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  184  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  185  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  186  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  187  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  188  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  189  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  190  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  191  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  192  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  193  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  194  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  195  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  196  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  197  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  198  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  199  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  200  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  201  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  202  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  203  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  204  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  205  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  206  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  207  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  208  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  209  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  210  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  211  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  212  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  213  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  214  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  215  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  216  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  217  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  218  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  219  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  220  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  74  batch  221  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  222  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  223  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  224  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  225  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  226  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  227  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  228  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  229  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  230  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  231  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  232  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  233  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  234  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  235  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  236  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  237  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  238  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  239  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  240  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  241  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  242  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  243  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  244  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  245  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  246  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  247  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  248  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  249  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  250  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  251  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  252  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  253  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  254  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  255  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  256  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  257  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  258  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  259  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  260  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  261  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  262  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  263  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  264  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  265  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  266  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  267  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  268  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  269  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  270  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  271  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  272  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  273  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  274  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  275  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  276  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  277  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  278  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  279  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  280  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  281  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  282  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  283  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  284  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  285  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  286  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  287  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  288  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  289  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  290  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  291  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  292  loss  tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  293  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  294  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  295  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  296  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  297  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  298  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  299  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  300  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  301  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  302  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  303  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  304  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  305  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  306  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  307  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  308  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  309  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  310  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  311  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  312  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  313  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  314  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  315  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  316  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  317  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  318  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  319  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  320  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  321  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  322  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  323  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  324  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  325  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  326  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  327  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  328  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  329  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  330  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  331  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  332  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  333  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  334  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  335  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  336  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  337  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  338  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  339  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  340  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  341  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  74  batch  342  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  343  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  344  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  345  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  346  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  347  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  348  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  349  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  350  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  351  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  352  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  353  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  354  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  355  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  356  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  357  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  358  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  359  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  360  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  361  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  362  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  363  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  364  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  365  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  366  loss  tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  367  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  368  loss  tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  369  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  370  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  371  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  372  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  373  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  374  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  375  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  376  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  377  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  378  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  379  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  380  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  381  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  382  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  383  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  384  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  385  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  386  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  387  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  388  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  389  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  390  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  391  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  392  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  393  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  394  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  395  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  396  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  397  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  398  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  399  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  400  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  401  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  402  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  403  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  404  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  405  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  406  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  407  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  408  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  409  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  410  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  411  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  412  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  74  batch  413  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch [75/100], loss:33.1452\n",
      "epoch  75  batch  0  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  1  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  2  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  3  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  4  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  5  loss  tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  6  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  7  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  8  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  9  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  10  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  11  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  12  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  13  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  14  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  15  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  16  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  17  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  18  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  19  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  20  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  21  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  22  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  23  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  24  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  25  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  26  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  27  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  28  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  29  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  30  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  31  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  32  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  33  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  34  loss  tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  35  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  36  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  37  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  38  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  39  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  40  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  41  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  42  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  43  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  44  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  45  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  46  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  47  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  48  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  75  batch  49  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  50  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  51  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  52  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  53  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  54  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  55  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  56  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  57  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  58  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  59  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  60  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  61  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  62  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  63  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  64  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  65  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  66  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  67  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  68  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  69  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  70  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  71  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  72  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  73  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  74  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  75  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  76  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  77  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  78  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  79  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  80  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  81  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  82  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  83  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  84  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  85  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  86  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  87  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  88  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  89  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  90  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  91  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  92  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  93  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  94  loss  tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  95  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  96  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  97  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  98  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  99  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  100  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  101  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  102  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  103  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  104  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  105  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  106  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  107  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  108  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  109  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  110  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  111  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  112  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  113  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  114  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  115  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  116  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  117  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  118  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  119  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  120  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  121  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  122  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  123  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  124  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  125  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  126  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  127  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  128  loss  tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  129  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  130  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  131  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  132  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  133  loss  tensor(0.0966, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  134  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  135  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  136  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  137  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  138  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  139  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  140  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  141  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  142  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  143  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  144  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  145  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  146  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  147  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  148  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  149  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  150  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  151  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  152  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  153  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  154  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  155  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  156  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  157  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  158  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  159  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  160  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  161  loss  tensor(0.0693, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  162  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  163  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  164  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  165  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  166  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  167  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  168  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  169  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  170  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  75  batch  171  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  172  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  173  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  174  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  175  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  176  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  177  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  178  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  179  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  180  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  181  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  182  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  183  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  184  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  185  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  186  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  187  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  188  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  189  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  190  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  191  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  192  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  193  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  194  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  195  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  196  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  197  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  198  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  199  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  200  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  201  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  202  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  203  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  204  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  205  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  206  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  207  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  208  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  209  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  210  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  211  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  212  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  213  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  214  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  215  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  216  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  217  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  218  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  219  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  220  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  221  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  222  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  223  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  224  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  225  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  226  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  227  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  228  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  229  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  230  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  231  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  232  loss  tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  233  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  234  loss  tensor(0.0668, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  235  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  236  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  237  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  238  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  239  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  240  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  241  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  242  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  243  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  244  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  245  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  246  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  247  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  248  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  249  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  250  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  251  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  252  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  253  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  254  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  255  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  256  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  257  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  258  loss  tensor(0.0707, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  259  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  260  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  261  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  262  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  263  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  264  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  265  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  266  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  267  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  268  loss  tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  269  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  270  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  271  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  272  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  273  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  274  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  275  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  276  loss  tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  277  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  278  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  279  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  280  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  281  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  282  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  283  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  284  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  285  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  286  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  287  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  288  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  289  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  290  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  291  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  75  batch  292  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  293  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  294  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  295  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  296  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  297  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  298  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  299  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  300  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  301  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  302  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  303  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  304  loss  tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  305  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  306  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  307  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  308  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  309  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  310  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  311  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  312  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  313  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  314  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  315  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  316  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  317  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  318  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  319  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  320  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  321  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  322  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  323  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  324  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  325  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  326  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  327  loss  tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  328  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  329  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  330  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  331  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  332  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  333  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  334  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  335  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  336  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  337  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  338  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  339  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  340  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  341  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  342  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  343  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  344  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  345  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  346  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  347  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  348  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  349  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  350  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  351  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  352  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  353  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  354  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  355  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  356  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  357  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  358  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  359  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  360  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  361  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  362  loss  tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  363  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  364  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  365  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  366  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  367  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  368  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  369  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  370  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  371  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  372  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  373  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  374  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  375  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  376  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  377  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  378  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  379  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  380  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  381  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  382  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  383  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  384  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  385  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  386  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  387  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  388  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  389  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  390  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  391  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  392  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  393  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  394  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  395  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  396  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  397  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  398  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  399  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  400  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  401  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  402  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  403  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  404  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  405  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  406  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  407  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  408  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  409  loss  tensor(0.0654, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  410  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  411  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  75  batch  412  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  75  batch  413  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch [76/100], loss:33.1444\n",
      "epoch  76  batch  0  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  1  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  2  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  3  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  4  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  5  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  6  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  7  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  8  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  9  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  10  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  11  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  12  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  13  loss  tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  14  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  15  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  16  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  17  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  18  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  19  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  20  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  21  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  22  loss  tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  23  loss  tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  24  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  25  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  26  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  27  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  28  loss  tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  29  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  30  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  31  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  32  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  33  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  34  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  35  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  36  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  37  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  38  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  39  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  40  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  41  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  42  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  43  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  44  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  45  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  46  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  47  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  48  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  49  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  50  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  51  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  52  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  53  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  54  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  55  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  56  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  57  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  58  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  59  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  60  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  61  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  62  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  63  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  64  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  65  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  66  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  67  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  68  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  69  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  70  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  71  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  72  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  73  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  74  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  75  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  76  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  77  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  78  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  79  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  80  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  81  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  82  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  83  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  84  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  85  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  86  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  87  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  88  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  89  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  90  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  91  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  92  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  93  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  94  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  95  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  96  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  97  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  98  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  99  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  100  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  101  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  102  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  103  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  104  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  105  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  106  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  107  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  108  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  109  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  110  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  111  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  112  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  113  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  114  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  115  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  116  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  117  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  118  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  119  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  120  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  76  batch  121  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  122  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  123  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  124  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  125  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  126  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  127  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  128  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  129  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  130  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  131  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  132  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  133  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  134  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  135  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  136  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  137  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  138  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  139  loss  tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  140  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  141  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  142  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  143  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  144  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  145  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  146  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  147  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  148  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  149  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  150  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  151  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  152  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  153  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  154  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  155  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  156  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  157  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  158  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  159  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  160  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  161  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  162  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  163  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  164  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  165  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  166  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  167  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  168  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  169  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  170  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  171  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  172  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  173  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  174  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  175  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  176  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  177  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  178  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  179  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  180  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  181  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  182  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  183  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  184  loss  tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  185  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  186  loss  tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  187  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  188  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  189  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  190  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  191  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  192  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  193  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  194  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  195  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  196  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  197  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  198  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  199  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  200  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  201  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  202  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  203  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  204  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  205  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  206  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  207  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  208  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  209  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  210  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  211  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  212  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  213  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  214  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  215  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  216  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  217  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  218  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  219  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  220  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  221  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  222  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  223  loss  tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  224  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  225  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  226  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  227  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  228  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  229  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  230  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  231  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  232  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  233  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  234  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  235  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  236  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  237  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  238  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  239  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  240  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  241  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  76  batch  242  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  243  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  244  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  245  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  246  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  247  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  248  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  249  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  250  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  251  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  252  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  253  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  254  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  255  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  256  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  257  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  258  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  259  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  260  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  261  loss  tensor(0.0667, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  262  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  263  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  264  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  265  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  266  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  267  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  268  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  269  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  270  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  271  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  272  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  273  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  274  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  275  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  276  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  277  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  278  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  279  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  280  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  281  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  282  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  283  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  284  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  285  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  286  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  287  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  288  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  289  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  290  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  291  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  292  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  293  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  294  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  295  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  296  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  297  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  298  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  299  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  300  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  301  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  302  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  303  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  304  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  305  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  306  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  307  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  308  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  309  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  310  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  311  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  312  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  313  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  314  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  315  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  316  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  317  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  318  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  319  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  320  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  321  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  322  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  323  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  324  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  325  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  326  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  327  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  328  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  329  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  330  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  331  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  332  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  333  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  334  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  335  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  336  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  337  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  338  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  339  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  340  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  341  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  342  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  343  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  344  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  345  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  346  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  347  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  348  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  349  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  350  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  351  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  352  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  353  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  354  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  355  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  356  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  357  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  358  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  359  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  360  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  361  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  362  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  76  batch  363  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  364  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  365  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  366  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  367  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  368  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  369  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  370  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  371  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  372  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  373  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  374  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  375  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  376  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  377  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  378  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  379  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  380  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  381  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  382  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  383  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  384  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  385  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  386  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  387  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  388  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  389  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  390  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  391  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  392  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  393  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  394  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  395  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  396  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  397  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  398  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  399  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  400  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  401  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  402  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  403  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  404  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  405  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  406  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  407  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  408  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  409  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  410  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  411  loss  tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  412  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  76  batch  413  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch [77/100], loss:33.1467\n",
      "epoch  77  batch  0  loss  tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  1  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  2  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  3  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  4  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  5  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  6  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  7  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  8  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  9  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  10  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  11  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  12  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  13  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  14  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  15  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  16  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  17  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  18  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  19  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  20  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  21  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  22  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  23  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  24  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  25  loss  tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  26  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  27  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  28  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  29  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  30  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  31  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  32  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  33  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  34  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  35  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  36  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  37  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  38  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  39  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  40  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  41  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  42  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  43  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  44  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  45  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  46  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  47  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  48  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  49  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  50  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  51  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  52  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  53  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  54  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  55  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  56  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  57  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  58  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  59  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  60  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  61  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  62  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  63  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  64  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  65  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  66  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  67  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  68  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  69  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  70  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  77  batch  71  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  72  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  73  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  74  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  75  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  76  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  77  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  78  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  79  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  80  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  81  loss  tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  82  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  83  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  84  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  85  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  86  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  87  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  88  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  89  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  90  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  91  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  92  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  93  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  94  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  95  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  96  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  97  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  98  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  99  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  100  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  101  loss  tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  102  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  103  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  104  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  105  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  106  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  107  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  108  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  109  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  110  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  111  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  112  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  113  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  114  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  115  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  116  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  117  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  118  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  119  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  120  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  121  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  122  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  123  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  124  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  125  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  126  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  127  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  128  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  129  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  130  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  131  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  132  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  133  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  134  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  135  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  136  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  137  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  138  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  139  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  140  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  141  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  142  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  143  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  144  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  145  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  146  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  147  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  148  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  149  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  150  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  151  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  152  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  153  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  154  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  155  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  156  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  157  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  158  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  159  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  160  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  161  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  162  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  163  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  164  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  165  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  166  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  167  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  168  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  169  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  170  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  171  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  172  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  173  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  174  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  175  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  176  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  177  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  178  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  179  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  180  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  181  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  182  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  183  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  184  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  185  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  186  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  187  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  188  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  189  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  190  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  191  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  77  batch  192  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  193  loss  tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  194  loss  tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  195  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  196  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  197  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  198  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  199  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  200  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  201  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  202  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  203  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  204  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  205  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  206  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  207  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  208  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  209  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  210  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  211  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  212  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  213  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  214  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  215  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  216  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  217  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  218  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  219  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  220  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  221  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  222  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  223  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  224  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  225  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  226  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  227  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  228  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  229  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  230  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  231  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  232  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  233  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  234  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  235  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  236  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  237  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  238  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  239  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  240  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  241  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  242  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  243  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  244  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  245  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  246  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  247  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  248  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  249  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  250  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  251  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  252  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  253  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  254  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  255  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  256  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  257  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  258  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  259  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  260  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  261  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  262  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  263  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  264  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  265  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  266  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  267  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  268  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  269  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  270  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  271  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  272  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  273  loss  tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  274  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  275  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  276  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  277  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  278  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  279  loss  tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  280  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  281  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  282  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  283  loss  tensor(0.1002, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  284  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  285  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  286  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  287  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  288  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  289  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  290  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  291  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  292  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  293  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  294  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  295  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  296  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  297  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  298  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  299  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  300  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  301  loss  tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  302  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  303  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  304  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  305  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  306  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  307  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  308  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  309  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  310  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  311  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  312  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  77  batch  313  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  314  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  315  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  316  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  317  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  318  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  319  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  320  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  321  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  322  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  323  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  324  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  325  loss  tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  326  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  327  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  328  loss  tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  329  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  330  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  331  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  332  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  333  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  334  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  335  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  336  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  337  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  338  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  339  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  340  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  341  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  342  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  343  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  344  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  345  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  346  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  347  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  348  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  349  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  350  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  351  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  352  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  353  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  354  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  355  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  356  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  357  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  358  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  359  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  360  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  361  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  362  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  363  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  364  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  365  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  366  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  367  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  368  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  369  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  370  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  371  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  372  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  373  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  374  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  375  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  376  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  377  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  378  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  379  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  380  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  381  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  382  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  383  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  384  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  385  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  386  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  387  loss  tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  388  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  389  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  390  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  391  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  392  loss  tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  393  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  394  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  395  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  396  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  397  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  398  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  399  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  400  loss  tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  401  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  402  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  403  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  404  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  405  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  406  loss  tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  407  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  408  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  409  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  410  loss  tensor(0.0911, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  411  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  412  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  77  batch  413  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch [78/100], loss:33.1427\n",
      "epoch  78  batch  0  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  1  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  2  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  3  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  4  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  5  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  6  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  7  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  8  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  9  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  10  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  11  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  12  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  13  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  14  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  15  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  16  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  17  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  18  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  19  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  78  batch  20  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  21  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  22  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  23  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  24  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  25  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  26  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  27  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  28  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  29  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  30  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  31  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  32  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  33  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  34  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  35  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  36  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  37  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  38  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  39  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  40  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  41  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  42  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  43  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  44  loss  tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  45  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  46  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  47  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  48  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  49  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  50  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  51  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  52  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  53  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  54  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  55  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  56  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  57  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  58  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  59  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  60  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  61  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  62  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  63  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  64  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  65  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  66  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  67  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  68  loss  tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  69  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  70  loss  tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  71  loss  tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  72  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  73  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  74  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  75  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  76  loss  tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  77  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  78  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  79  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  80  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  81  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  82  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  83  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  84  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  85  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  86  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  87  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  88  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  89  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  90  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  91  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  92  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  93  loss  tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  94  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  95  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  96  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  97  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  98  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  99  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  100  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  101  loss  tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  102  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  103  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  104  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  105  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  106  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  107  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  108  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  109  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  110  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  111  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  112  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  113  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  114  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  115  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  116  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  117  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  118  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  119  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  120  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  121  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  122  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  123  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  124  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  125  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  126  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  127  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  128  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  129  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  130  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  131  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  132  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  133  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  134  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  135  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  136  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  137  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  138  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  139  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  140  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  141  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  78  batch  142  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  143  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  144  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  145  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  146  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  147  loss  tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  148  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  149  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  150  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  151  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  152  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  153  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  154  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  155  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  156  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  157  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  158  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  159  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  160  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  161  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  162  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  163  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  164  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  165  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  166  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  167  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  168  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  169  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  170  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  171  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  172  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  173  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  174  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  175  loss  tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  176  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  177  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  178  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  179  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  180  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  181  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  182  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  183  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  184  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  185  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  186  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  187  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  188  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  189  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  190  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  191  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  192  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  193  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  194  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  195  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  196  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  197  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  198  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  199  loss  tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  200  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  201  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  202  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  203  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  204  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  205  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  206  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  207  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  208  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  209  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  210  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  211  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  212  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  213  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  214  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  215  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  216  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  217  loss  tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  218  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  219  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  220  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  221  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  222  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  223  loss  tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  224  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  225  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  226  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  227  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  228  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  229  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  230  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  231  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  232  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  233  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  234  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  235  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  236  loss  tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  237  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  238  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  239  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  240  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  241  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  242  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  243  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  244  loss  tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  245  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  246  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  247  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  248  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  249  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  250  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  251  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  252  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  253  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  254  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  255  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  256  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  257  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  258  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  259  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  260  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  261  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  262  loss  tensor(0.0732, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  78  batch  263  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  264  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  265  loss  tensor(0.0969, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  266  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  267  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  268  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  269  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  270  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  271  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  272  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  273  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  274  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  275  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  276  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  277  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  278  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  279  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  280  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  281  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  282  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  283  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  284  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  285  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  286  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  287  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  288  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  289  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  290  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  291  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  292  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  293  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  294  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  295  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  296  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  297  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  298  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  299  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  300  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  301  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  302  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  303  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  304  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  305  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  306  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  307  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  308  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  309  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  310  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  311  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  312  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  313  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  314  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  315  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  316  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  317  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  318  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  319  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  320  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  321  loss  tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  322  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  323  loss  tensor(0.0662, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  324  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  325  loss  tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  326  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  327  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  328  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  329  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  330  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  331  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  332  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  333  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  334  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  335  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  336  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  337  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  338  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  339  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  340  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  341  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  342  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  343  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  344  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  345  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  346  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  347  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  348  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  349  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  350  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  351  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  352  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  353  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  354  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  355  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  356  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  357  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  358  loss  tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  359  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  360  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  361  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  362  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  363  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  364  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  365  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  366  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  367  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  368  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  369  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  370  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  371  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  372  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  373  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  374  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  375  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  376  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  377  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  378  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  379  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  380  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  381  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  382  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  383  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  78  batch  384  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  385  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  386  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  387  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  388  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  389  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  390  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  391  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  392  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  393  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  394  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  395  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  396  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  397  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  398  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  399  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  400  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  401  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  402  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  403  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  404  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  405  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  406  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  407  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  408  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  409  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  410  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  411  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  412  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  78  batch  413  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch [79/100], loss:33.1330\n",
      "epoch  79  batch  0  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  1  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  2  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  3  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  4  loss  tensor(0.0715, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  5  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  6  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  7  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  8  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  9  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  10  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  11  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  12  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  13  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  14  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  15  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  16  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  17  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  18  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  19  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  20  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  21  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  22  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  23  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  24  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  25  loss  tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  26  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  27  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  28  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  29  loss  tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  30  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  31  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  32  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  33  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  34  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  35  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  36  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  37  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  38  loss  tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  39  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  40  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  41  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  42  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  43  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  44  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  45  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  46  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  47  loss  tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  48  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  49  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  50  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  51  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  52  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  53  loss  tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  54  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  55  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  56  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  57  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  58  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  59  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  60  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  61  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  62  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  63  loss  tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  64  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  65  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  66  loss  tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  67  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  68  loss  tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  69  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  70  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  71  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  72  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  73  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  74  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  75  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  76  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  77  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  78  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  79  loss  tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  80  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  81  loss  tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  82  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  83  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  84  loss  tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  85  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  86  loss  tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  87  loss  tensor(0.0851, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  88  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  89  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  90  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  91  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  79  batch  92  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  93  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  94  loss  tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  95  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  96  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  97  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  98  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  99  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  100  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  101  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  102  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  103  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  104  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  105  loss  tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  106  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  107  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  108  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  109  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  110  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  111  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  112  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  113  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  114  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  115  loss  tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  116  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  117  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  118  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  119  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  120  loss  tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  121  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  122  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  123  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  124  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  125  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  126  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  127  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  128  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  129  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  130  loss  tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  131  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  132  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  133  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  134  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  135  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  136  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  137  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  138  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  139  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  140  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  141  loss  tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  142  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  143  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  144  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  145  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  146  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  147  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  148  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  149  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  150  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  151  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  152  loss  tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  153  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  154  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  155  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  156  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  157  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  158  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  159  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  160  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  161  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  162  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  163  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  164  loss  tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  165  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  166  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  167  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  168  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  169  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  170  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  171  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  172  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  173  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  174  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  175  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  176  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  177  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  178  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  179  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  180  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  181  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  182  loss  tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  183  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  184  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  185  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  186  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  187  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  188  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  189  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  190  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  191  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  192  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  193  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  194  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  195  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  196  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  197  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  198  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  199  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  200  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  201  loss  tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  202  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  203  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  204  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  205  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  206  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  207  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  208  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  209  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  210  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  211  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  212  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  79  batch  213  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  214  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  215  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  216  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  217  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  218  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  219  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  220  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  221  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  222  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  223  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  224  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  225  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  226  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  227  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  228  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  229  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  230  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  231  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  232  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  233  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  234  loss  tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  235  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  236  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  237  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  238  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  239  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  240  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  241  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  242  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  243  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  244  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  245  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  246  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  247  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  248  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  249  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  250  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  251  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  252  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  253  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  254  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  255  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  256  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  257  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  258  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  259  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  260  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  261  loss  tensor(0.0760, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  262  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  263  loss  tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  264  loss  tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  265  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  266  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  267  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  268  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  269  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  270  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  271  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  272  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  273  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  274  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  275  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  276  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  277  loss  tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  278  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  279  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  280  loss  tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  281  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  282  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  283  loss  tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  284  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  285  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  286  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  287  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  288  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  289  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  290  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  291  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  292  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  293  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  294  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  295  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  296  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  297  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  298  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  299  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  300  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  301  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  302  loss  tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  303  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  304  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  305  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  306  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  307  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  308  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  309  loss  tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  310  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  311  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  312  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  313  loss  tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  314  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  315  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  316  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  317  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  318  loss  tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  319  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  320  loss  tensor(0.0694, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  321  loss  tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  322  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  323  loss  tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  324  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  325  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  326  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  327  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  328  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  329  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  330  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  331  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  332  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  333  loss  tensor(0.0685, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  79  batch  334  loss  tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  335  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  336  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  337  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  338  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  339  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  340  loss  tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  341  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  342  loss  tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  343  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  344  loss  tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  345  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  346  loss  tensor(0.0820, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  347  loss  tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  348  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  349  loss  tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  350  loss  tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  351  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  352  loss  tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  353  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  354  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  355  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  356  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  357  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  358  loss  tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  359  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  360  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  361  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  362  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  363  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  364  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  365  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  366  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  367  loss  tensor(0.0693, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  368  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  369  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  370  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  371  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  372  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  373  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  374  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  375  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  376  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  377  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  378  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  379  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  380  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  381  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  382  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  383  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  384  loss  tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  385  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  386  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  387  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  388  loss  tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  389  loss  tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  390  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  391  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  392  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  393  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  394  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  395  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  396  loss  tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  397  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  398  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  399  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  400  loss  tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  401  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  402  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  403  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  404  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  405  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  406  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  407  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  408  loss  tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  409  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  410  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  411  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  412  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  79  batch  413  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch [80/100], loss:33.1358\n",
      "epoch  80  batch  0  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  1  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  2  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  3  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  4  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  5  loss  tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  6  loss  tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  7  loss  tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  8  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  9  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  10  loss  tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  11  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  12  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  13  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  14  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  15  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  16  loss  tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  17  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  18  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  19  loss  tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  20  loss  tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  21  loss  tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  22  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  23  loss  tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  24  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  25  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  26  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  27  loss  tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  28  loss  tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  29  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  30  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  31  loss  tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  32  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  33  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  34  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  35  loss  tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  36  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  37  loss  tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  38  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  39  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  40  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  80  batch  41  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  42  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  43  loss  tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  44  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  45  loss  tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  46  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  47  loss  tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  48  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  49  loss  tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  50  loss  tensor(0.0751, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  51  loss  tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  52  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  53  loss  tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  54  loss  tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  55  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  56  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  57  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  58  loss  tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  59  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  60  loss  tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  61  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  62  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  63  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  64  loss  tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  65  loss  tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  66  loss  tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  67  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  68  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  69  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  70  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  71  loss  tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  72  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  73  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  74  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  75  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  76  loss  tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  77  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  78  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  79  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  80  loss  tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  81  loss  tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  82  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  83  loss  tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  84  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  85  loss  tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  86  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  87  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  88  loss  tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  89  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  90  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  91  loss  tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  92  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  93  loss  tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  94  loss  tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  95  loss  tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  96  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  97  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  98  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  99  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  100  loss  tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  101  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  102  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  103  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  104  loss  tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  105  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  106  loss  tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  107  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  108  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  109  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  110  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  111  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  112  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  113  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  114  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  115  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  116  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  117  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  118  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  119  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  120  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  121  loss  tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  122  loss  tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  123  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  124  loss  tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  125  loss  tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  126  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  127  loss  tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  128  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  129  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  130  loss  tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  131  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  132  loss  tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  133  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  134  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  135  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  136  loss  tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  137  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  138  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  139  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  140  loss  tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  141  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  142  loss  tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  143  loss  tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  144  loss  tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  145  loss  tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  146  loss  tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  147  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  148  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  149  loss  tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  150  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  151  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  152  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  153  loss  tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  154  loss  tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  155  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  156  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  157  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  158  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  159  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  160  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  161  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  162  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  80  batch  163  loss  tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  164  loss  tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  165  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  166  loss  tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  167  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  168  loss  tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  169  loss  tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  170  loss  tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  171  loss  tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  172  loss  tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  173  loss  tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  174  loss  tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  175  loss  tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  176  loss  tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  177  loss  tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  178  loss  tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  179  loss  tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  180  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  181  loss  tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  182  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  183  loss  tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  184  loss  tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  185  loss  tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  186  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  187  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  188  loss  tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  189  loss  tensor(0.0901, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  190  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  191  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  192  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  193  loss  tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  194  loss  tensor(0.0771, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  195  loss  tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  196  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  197  loss  tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  198  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  199  loss  tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  200  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  201  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  202  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  203  loss  tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  204  loss  tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  205  loss  tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  206  loss  tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  207  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  208  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  209  loss  tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  210  loss  tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  211  loss  tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  212  loss  tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  213  loss  tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  214  loss  tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  215  loss  tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  216  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  217  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  218  loss  tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  219  loss  tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  220  loss  tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  221  loss  tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  222  loss  tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  223  loss  tensor(0.0799, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  224  loss  tensor(0.0860, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  225  loss  tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  226  loss  tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  227  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  228  loss  tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  229  loss  tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  230  loss  tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  231  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  232  loss  tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  233  loss  tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  234  loss  tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  235  loss  tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  236  loss  tensor(0.0670, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  237  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  238  loss  tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  239  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  240  loss  tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  241  loss  tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  242  loss  tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  243  loss  tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  244  loss  tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  245  loss  tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  246  loss  tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  247  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  248  loss  tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  249  loss  tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  250  loss  tensor(0.0920, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  251  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  252  loss  tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  253  loss  tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  254  loss  tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  255  loss  tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  256  loss  tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  257  loss  tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  258  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  259  loss  tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  260  loss  tensor(0.0838, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  261  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  262  loss  tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  263  loss  tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  264  loss  tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  265  loss  tensor(0.0825, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  266  loss  tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  267  loss  tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  268  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  269  loss  tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  270  loss  tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  271  loss  tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  272  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  273  loss  tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  274  loss  tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  275  loss  tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  276  loss  tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  277  loss  tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  278  loss  tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  279  loss  tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  280  loss  tensor(0.0756, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  281  loss  tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  282  loss  tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  283  loss  tensor(0.0734, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  80  batch  284  loss  tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  285  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  286  loss  tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  287  loss  tensor(0.0740, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  288  loss  tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  289  loss  tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  290  loss  tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "epoch  80  batch  291  loss  tensor(0.0822, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    i=0\n",
    "    for img,y in dataloader:\n",
    "        # forward\n",
    "\n",
    "        param_f = model.encoded_images(img)\n",
    "        mu_f, logvar_f = param_f.split(param_f.size(1)//2, 1)\n",
    "        std_f = torch.exp(0.5 * logvar_f)\n",
    "        z = torch.randn_like(mu_f) * std_f + mu_f\n",
    "        \n",
    "        kl = - 0.5 * (1 + logvar_f - mu_f.pow(2) - logvar_f.exp()) \n",
    "        kl_loss = kl.sum() / img.size(0)\n",
    "        \n",
    "        output = model.decoded_images(z)\n",
    "        loss = loss_function(output,img)\n",
    "        loss += kl_loss\n",
    "        \n",
    "        \n",
    "        # backward\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total_loss += loss.data\n",
    "        print(\"epoch \", epoch,\" batch \",i,\" loss \",loss)\n",
    "        i = i+1\n",
    "    # logs\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch+1, 100, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35665e3-b244-48ed-b0f9-ea0b521df93e",
   "metadata": {},
   "source": [
    "##  Step 7\n",
    "\n",
    "Take a random image from the dataset and plot it together with new samples generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2ed64-4c61-4323-800e-e031bffedf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Take a random image from the dataset\n",
    "random_image, _ = random.choice(dataloader.dataset)\n",
    "\n",
    "# Plot the original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(random_image.permute(1, 2, 0))\n",
    "\n",
    "# Generate new samples using the trained VAE\n",
    "with torch.no_grad():\n",
    "    random_image = random_image.unsqueeze(0)  # Add batch dimension\n",
    "    output_vae = model.forward(random_image)\n",
    "\n",
    "# Plot the generated samples\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Generated Samples')\n",
    "plt.imshow(output_vae.squeeze().permute(1, 2, 0).clamp(0, 1))\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6905caa-e8b5-4b35-a14a-e39b7ed70371",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
